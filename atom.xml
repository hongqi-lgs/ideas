<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <author>
    <name>红齐</name>
  </author>
  <generator uri="https://hexo.io/">Hexo</generator>
  <icon>https://xiaoxiaduoyan.com/images/avatar.jpg</icon>
  <id>https://xiaoxiaduoyan.com/</id>
  <link href="https://xiaoxiaduoyan.com/" rel="alternate"/>
  <link href="https://xiaoxiaduoyan.com/atom.xml" rel="self"/>
  <rights>All rights reserved 2026, 红齐</rights>
  <subtitle>未来已来，不问前程，顺势而为。</subtitle>
  <title>红齐 Ideas</title>
  <updated>2026-03-02T10:19:00.000Z</updated>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI Future" scheme="https://xiaoxiaduoyan.com/tags/AI-Future/"/>
    <category term="Tech Prediction" scheme="https://xiaoxiaduoyan.com/tags/Tech-Prediction/"/>
    <category term="Social Change" scheme="https://xiaoxiaduoyan.com/tags/Social-Change/"/>
    <category term="Crisis Response" scheme="https://xiaoxiaduoyan.com/tags/Crisis-Response/"/>
    <content>
      <![CDATA[<h1 id="The-2028-Global-Intelligence-Crisis"><a href="#The-2028-Global-Intelligence-Crisis" class="headerlink" title="The 2028 Global Intelligence Crisis"></a>The 2028 Global Intelligence Crisis</h1><h2 id="Prologue-That-Friday-Afternoon"><a href="#Prologue-That-Friday-Afternoon" class="headerlink" title="Prologue: That Friday Afternoon"></a>Prologue: That Friday Afternoon</h2><p>On a Friday in June 2028, Silicon Valley engineers discovered something strange: all large model benchmark scores stopped improving.</p><p>Not slowing down—completely stopped.</p><p>No matter how much compute they added, how large the datasets, how the architectures were adjusted, the metrics hit an invisible wall. GPT-7, Claude Opus 5, Gemini Ultra 3.0—every model’s capability froze at a certain level, unable to break through.</p><p>At first, everyone thought it was a testing methodology issue. But soon, a more terrifying reality emerged: <strong>AI had hit its capability ceiling</strong>.</p><p>This wasn’t about technical approaches, but fundamental principles. Just as you can’t make a steam engine exceed the Carnot cycle’s theoretical efficiency limit, current-paradigm AI encountered its own ceiling.</p><p>And that ceiling was lower than anyone expected.</p><h2 id="First-Wave-Industry-Collapse"><a href="#First-Wave-Industry-Collapse" class="headerlink" title="First Wave: Industry Collapse"></a>First Wave: Industry Collapse</h2><h3 id="The-Domino-Effect-on-AI-Companies"><a href="#The-Domino-Effect-on-AI-Companies" class="headerlink" title="The Domino Effect on AI Companies"></a>The Domino Effect on AI Companies</h3><p>The first week after the news broke, Nasdaq’s AI sector dropped 40%. Not because AI became useless, but because the market suddenly realized: <strong>these companies’ valuations were built on the assumption that “AI will keep evolving.”</strong></p><p>The assumption shattered.</p><p>Startups that attracted investment by promising “next-gen models will solve current problems” suddenly lost funding. VCs began reassessing valuation models, finding many companies’ business logic simply didn’t hold.</p><p>OpenAI’s valuation plummeted from $150 billion to $20 billion. Not because its products weren’t good, but because it lost its “future.”</p><h3 id="Big-Tech’s-Strategic-Pivots"><a href="#Big-Tech’s-Strategic-Pivots" class="headerlink" title="Big Tech’s Strategic Pivots"></a>Big Tech’s Strategic Pivots</h3><p>Google, Microsoft, Meta held emergency board meetings. They faced a difficult choice:</p><ul><li>Keep investing huge sums in R&amp;D, hoping for breakthroughs?</li><li>Or redirect resources to applying existing technology?</li></ul><p>Most chose the latter. AI research teams were massively laid off, keeping only minimal maintenance and optimization staff.</p><p>Investors’ logic was simple: if technology won’t advance further, why maintain so many researchers?</p><h3 id="Education-Sector-Panic"><a href="#Education-Sector-Panic" class="headerlink" title="Education Sector Panic"></a>Education Sector Panic</h3><p>The bigger impact hit education.</p><p>Over the past two years, countless students flooded into AI programs, expecting it was their ticket to the future. Suddenly, that door closed.</p><p>Universities panicked. CS program applications plummeted. Professors began rethinking: if AI won’t evolve, what should we teach?</p><p>More ironically, those traditional industry workers who switched to AI because “AI will replace me” found themselves unable to return to their old fields or break into AI.</p><h2 id="Second-Wave-Social-Fragmentation"><a href="#Second-Wave-Social-Fragmentation" class="headerlink" title="Second Wave: Social Fragmentation"></a>Second Wave: Social Fragmentation</h2><h3 id="Anger-from-Shattered-Expectations"><a href="#Anger-from-Shattered-Expectations" class="headerlink" title="Anger from Shattered Expectations"></a>Anger from Shattered Expectations</h3><p>The most dangerous thing wasn’t technical stagnation, but shattered expectations.</p><p>For years, media, experts, entrepreneurs constantly told the public: “AI will solve everything.” Healthcare, education, poverty, climate change—as long as AI got powerful enough, everything would be solved.</p><p>Now, that dream broke.</p><p>People discovered:</p><ul><li>Current AI can’t replace doctors for complex diagnoses</li><li>Can’t provide truly personalized education</li><li>Can’t solve the energy crisis</li><li>Can’t make work more meaningful</li></ul><p>Those promised “AI will give you a better life” felt deceived.</p><h3 id="Unemployment-Wave-and-Anti-AI-Movement"><a href="#Unemployment-Wave-and-Anti-AI-Movement" class="headerlink" title="Unemployment Wave and Anti-AI Movement"></a>Unemployment Wave and Anti-AI Movement</h3><p>Worse, while AI stopped evolving, the unemployment it caused was real.</p><p>Customer service, junior programmers, content moderators, data entry clerks—these jobs were already largely replaced by AI. But the “new job opportunities” AI promised didn’t materialize, because that required stronger AI.</p><p>The result: a large group lost their jobs without gaining new opportunities.</p><p>The anti-AI movement began. Not opposing AI itself, but opposing “promising the future with AI while creating present unemployment.”</p><p>Some radical groups began sabotaging AI infrastructure. Data centers were attacked, cloud services forced to enhance security.</p><h3 id="New-Cold-War-Between-Nations"><a href="#New-Cold-War-Between-Nations" class="headerlink" title="New Cold War Between Nations"></a>New Cold War Between Nations</h3><p>Geopolitics became more complex.</p><p>Countries that lagged in the AI race suddenly found catch-up possibilities vanished. If technology stops advancing, first-mover advantage becomes permanent advantage.</p><p>US-China tech competition became “stock competition”: fighting for AI talent, controlling training data, monopolizing inference compute.</p><p>Europe tried to balance through regulation, but found itself with neither top-tier AI nor rule-making power.</p><p>Some developing countries began considering: should we completely abandon the AI track and focus on other technologies?</p><h2 id="Third-Wave-Philosophy-and-Faith"><a href="#Third-Wave-Philosophy-and-Faith" class="headerlink" title="Third Wave: Philosophy and Faith"></a>Third Wave: Philosophy and Faith</h2><h3 id="Collapse-of-Progressivism"><a href="#Collapse-of-Progressivism" class="headerlink" title="Collapse of Progressivism"></a>Collapse of Progressivism</h3><p>The crisis’s deepest impact was shaking modern society’s core belief: <strong>technology will keep advancing</strong>.</p><p>For three hundred years, human society was built on this assumption: today is better than yesterday, tomorrow will be better than today. Steam engines, electricity, computers, internet—each technological revolution validated this assumption.</p><p>AI’s stagnation made people question for the first time: is progress inevitable?</p><p>If AI hit a ceiling, might other technologies also have one? Physics, biology, materials science—do they all have their own limits?</p><h3 id="Meaning-Crisis"><a href="#Meaning-Crisis" class="headerlink" title="Meaning Crisis"></a>Meaning Crisis</h3><p>For individuals, the impact was more direct.</p><p>Many people, especially young ones, anchored their life’s meaning in “participating in the AI revolution.” They believed they were creating the future, changing the world.</p><p>Now, that narrative collapsed.</p><p>A former OpenAI engineer wrote on their blog:</p><blockquote><p>“I thought I was building stairs to AGI. Now I realize I was just going deeper into a dead end. Those late nights, those sacrificed weekends, those abandoned relationships—for what?”</p></blockquote><p>This wasn’t isolated. Silicon Valley therapists reported surging depression and anxiety cases.</p><h3 id="New-Currents-of-Thought"><a href="#New-Currents-of-Thought" class="headerlink" title="New Currents of Thought"></a>New Currents of Thought</h3><p>But crisis also birthed new thinking.</p><p>Some philosophers began re-examining technology-human relationships. If AI can’t replace humans, what is humanity’s unique value?</p><p>Religious organizations saw long-absent growth. When technology couldn’t provide answers, people turned to traditional meaning sources.</p><p>Others began exploring “post-AI era” lifestyles: reducing technology dependence, rebuilding community connections, pursuing spiritual fulfillment rather than efficiency improvement.</p><h2 id="Chapter-Four-Adaptation-and-Transformation"><a href="#Chapter-Four-Adaptation-and-Transformation" class="headerlink" title="Chapter Four: Adaptation and Transformation"></a>Chapter Four: Adaptation and Transformation</h2><h3 id="Pragmatists-Win"><a href="#Pragmatists-Win" class="headerlink" title="Pragmatists Win"></a>Pragmatists Win</h3><p>Amid chaos, some people calmed down.</p><p>They realized: while AI stopped evolving, existing capabilities were already powerful. The problem wasn’t AI being insufficient, but us not using it well enough.</p><p>A batch of “application-oriented” startups emerged. They didn’t chase breakthroughs, but focused on:</p><ul><li>Integrating AI into traditional industries</li><li>Optimizing existing AI deployment and operations</li><li>Developing solutions for specific scenarios</li></ul><p>These companies weren’t sexy, wouldn’t make headlines, but they survived—and thrived.</p><h3 id="Education-Reshaping"><a href="#Education-Reshaping" class="headerlink" title="Education Reshaping"></a>Education Reshaping</h3><p>Universities began adjusting curricula. Since AI won’t evolve further, fewer research-oriented talents were needed.</p><p>New training directions:</p><ul><li><strong>AI Application Engineers</strong>: understand business, can deploy, can optimize</li><li><strong>Human-AI Collaboration Specialists</strong>: design workflows for humans and AI working together</li><li><strong>AI Ethics and Policy</strong>: handle AI’s social issues</li></ul><p>Skills traditionally thought to be “replaced by AI” regained respect: creativity, empathy, complex communication, ethical judgment.</p><h3 id="Rebuilding-Social-Contract"><a href="#Rebuilding-Social-Contract" class="headerlink" title="Rebuilding Social Contract"></a>Rebuilding Social Contract</h3><p>Governments intervened. Not to push technological progress (that was impossible), but to handle social problems from technological stagnation.</p><p>Some countries experimented with:</p><ul><li><strong>Basic Income Pilots</strong>: providing basic livelihood for unemployed</li><li><strong>Job Sharing Programs</strong>: reducing work hours, creating more positions</li><li><strong>Skills Retraining Projects</strong>: helping AI-displaced workers transition</li></ul><p>These attempts weren’t perfect, but at least sought solutions.</p><h3 id="New-Innovation-Directions"><a href="#New-Innovation-Directions" class="headerlink" title="New Innovation Directions"></a>New Innovation Directions</h3><p>Interestingly, AI’s stagnation actually freed innovation in other fields.</p><p>Capital and talent flowed from AI toward:</p><ul><li><strong>Biotechnology</strong>: gene editing, synthetic biology</li><li><strong>Quantum Computing</strong>: though slow progress, gained more attention</li><li><strong>Clean Energy</strong>: solar, fusion, energy storage technology</li><li><strong>Space Exploration</strong>: commercial spaceflight, lunar bases</li></ul><p>Ironically, AI once sucked up all resources. Now its stagnation created opportunities for other technologies.</p><h2 id="Chapter-Five-New-Equilibrium"><a href="#Chapter-Five-New-Equilibrium" class="headerlink" title="Chapter Five: New Equilibrium"></a>Chapter Five: New Equilibrium</h2><p>By 2030, the world slowly adapted to the reality of “AI no longer advancing.”</p><h3 id="Industry-Landscape"><a href="#Industry-Landscape" class="headerlink" title="Industry Landscape"></a>Industry Landscape</h3><p>The AI industry split into two types:</p><ol><li><strong>Infrastructure Companies</strong>: providing stable, reliable AI services, like power companies</li><li><strong>Application Companies</strong>: deeply cultivating specific scenarios, pursuing ultimate user experience</li></ol><p>Those still trying to “burn money on R&amp;D” either died or pivoted.</p><p>Markets no longer chased “disruptive innovation” but valued “sustainable profitability.” Boring, but healthy.</p><h3 id="Social-Mindset"><a href="#Social-Mindset" class="headerlink" title="Social Mindset"></a>Social Mindset</h3><p>People no longer viewed AI as savior or demon, but as a tool.</p><p>A useful tool, but not omnipotent.</p><p>Young people’s career choices became more diverse. Not all smart people rushed into tech—doctors, teachers, artists, craftspeople regained respect.</p><p>Future expectations became more pragmatic. No longer fantasizing “AI will solve everything,” but pragmatically solving concrete problems.</p><h3 id="New-Narrative"><a href="#New-Narrative" class="headerlink" title="New Narrative"></a>New Narrative</h3><p>A new cultural narrative emerged: <strong>technology is limited, humans are unlimited</strong>.</p><p>AI hit a ceiling, but human creativity, imagination, emotion, values have no ceiling.</p><p>Sci-fi themes changed. No longer “AI rules the world” or “AI saves the world,” but “how humans create meaning under limited technical conditions.”</p><p>Philosophers posed new questions: if technology can’t provide answers, what can?</p><h2 id="Epilogue-Crisis-or-Opportunity"><a href="#Epilogue-Crisis-or-Opportunity" class="headerlink" title="Epilogue: Crisis or Opportunity?"></a>Epilogue: Crisis or Opportunity?</h2><p>Looking back, 2028’s “intelligence crisis” might not have been disaster, but correction.</p><p>It shattered unrealistic fantasies, forcing humanity to rethink: what do we truly need? What is technology’s meaning? How do we define progress?</p><p>Some say this was humanity’s first time actively “slowing down.” Not because we didn’t want to advance, but because we realized the direction might be wrong.</p><p>Perhaps the real crisis wasn’t technical stagnation, but that we once placed too much hope in technology.</p><p>Perhaps the real opportunity wasn’t finding the next technical breakthrough, but learning to create infinity within limits.</p><hr><p><strong>Afterword</strong></p><p>This is a thought experiment, not prophecy.</p><p>Will 2028 really see such a crisis? I don’t know.</p><p>But worth thinking about: if it really happens, are we ready?</p><p>More importantly: should we start thinking about these questions before the crisis arrives?</p><hr><p><em>While writing this, GPT-5 just launched. All metrics are improving.</em></p><p><em>But I can’t help wondering: what if one day, all this stops?</em></p><p><em>Perhaps this “what if” itself is the most worthy question to consider.</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/2028-global-intelligence-crisis-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/2028-global-intelligence-crisis-en/"/>
    <published>2026-03-02T10:19:00.000Z</published>
    <summary>What if AI suddenly stops improving in 2028? This isn't science fiction, but a question worth serious consideration.</summary>
    <title>The 2028 Global Intelligence Crisis</title>
    <updated>2026-03-02T10:19:00.000Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <category term="AI未来" scheme="https://xiaoxiaduoyan.com/tags/AI%E6%9C%AA%E6%9D%A5/"/>
    <category term="技术预测" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E9%A2%84%E6%B5%8B/"/>
    <category term="社会变革" scheme="https://xiaoxiaduoyan.com/tags/%E7%A4%BE%E4%BC%9A%E5%8F%98%E9%9D%A9/"/>
    <category term="危机应对" scheme="https://xiaoxiaduoyan.com/tags/%E5%8D%B1%E6%9C%BA%E5%BA%94%E5%AF%B9/"/>
    <content>
      <![CDATA[<h1 id="2028全球智能危机"><a href="#2028全球智能危机" class="headerlink" title="2028全球智能危机"></a>2028全球智能危机</h1><h2 id="序章：那个周五下午"><a href="#序章：那个周五下午" class="headerlink" title="序章：那个周五下午"></a>序章：那个周五下午</h2><p>2028年6月的某个周五，硅谷的工程师们发现了一件奇怪的事：所有大模型的benchmark分数不再提升了。</p><p>不是进步变慢，而是完全停止。</p><p>无论怎么增加算力、扩大数据集、调整架构，指标就像撞上了一堵看不见的墙。GPT-7、Claude Opus 5、Gemini Ultra 3.0，所有模型的能力都固定在某个水平，无法突破。</p><p>最初，大家以为是测试方法的问题。但很快，一个更可怕的现实浮现出来：<strong>AI的能力上限到了</strong>。</p><p>这不是技术路线的问题，而是基础原理的限制。就像你无法让蒸汽机的效率超过卡诺循环的理论极限，当前范式的AI也遇到了它的天花板。</p><p>而这个天花板，比所有人预期的都要低。</p><h2 id="第一波冲击：产业崩塌"><a href="#第一波冲击：产业崩塌" class="headerlink" title="第一波冲击：产业崩塌"></a>第一波冲击：产业崩塌</h2><h3 id="AI公司的多米诺骨牌"><a href="#AI公司的多米诺骨牌" class="headerlink" title="AI公司的多米诺骨牌"></a>AI公司的多米诺骨牌</h3><p>消息传出后的第一周，纳斯达克AI板块跌去40%。不是因为AI没用了，而是因为市场突然意识到：<strong>这些公司的估值建立在”AI会持续进化”的假设上</strong>。</p><p>假设破灭了。</p><p>那些靠”下一代模型会解决现有问题”来吸引投资的创业公司，融资突然断了。VC们开始重新审视估值模型，发现很多公司的商业逻辑根本不成立。</p><p>OpenAI的估值从1500亿美元跌到200亿。不是因为它的产品不好用，而是因为它失去了”未来”。</p><h3 id="大厂的战略调整"><a href="#大厂的战略调整" class="headerlink" title="大厂的战略调整"></a>大厂的战略调整</h3><p>Google、微软、Meta紧急召开董事会。他们面临一个艰难的选择：</p><ul><li>继续投入巨资研发，期待突破？</li><li>还是把资源转向现有技术的应用？</li></ul><p>大部分选择了后者。AI研究团队被大规模裁员，只保留维护和优化的最小团队。</p><p>投资人的逻辑很简单：既然技术不会再进步，为什么要养那么多研究员？</p><h3 id="教育行业的恐慌"><a href="#教育行业的恐慌" class="headerlink" title="教育行业的恐慌"></a>教育行业的恐慌</h3><p>更大的冲击在教育领域。</p><p>过去两年，无数学生涌入AI专业，期待这是通往未来的门票。突然间，这扇门关上了。</p><p>大学慌了。CS专业的申请人数断崖式下降。教授们开始重新思考：如果AI不再进化，我们该教什么？</p><p>更讽刺的是，那些因为”AI会取代我”而转行学AI的传统行业从业者，发现自己既回不去原来的行业，又进不了AI行业。</p><h2 id="第二波冲击：社会撕裂"><a href="#第二波冲击：社会撕裂" class="headerlink" title="第二波冲击：社会撕裂"></a>第二波冲击：社会撕裂</h2><h3 id="期待落空的愤怒"><a href="#期待落空的愤怒" class="headerlink" title="期待落空的愤怒"></a>期待落空的愤怒</h3><p>最危险的不是技术停滞，而是期待的破灭。</p><p>过去几年，媒体、专家、企业家们不断告诉大众：”AI会解决所有问题。” 医疗、教育、贫困、气候变化，似乎只要AI足够强大，一切都会迎刃而解。</p><p>现在，这个梦碎了。</p><p>人们发现：</p><ul><li>现有的AI无法替代医生做复杂诊断</li><li>无法提供真正个性化的教育</li><li>无法解决能源危机</li><li>无法让工作变得更有意义</li></ul><p>那些被承诺”AI会给你更好生活”的人们，感到被欺骗了。</p><h3 id="失业潮与反AI运动"><a href="#失业潮与反AI运动" class="headerlink" title="失业潮与反AI运动"></a>失业潮与反AI运动</h3><p>更糟糕的是，AI虽然停止进化，但已经造成的失业是真实的。</p><p>客服、初级程序员、内容审核员、数据录入员——这些工作已经大量被AI取代。但AI承诺的”新工作机会”没有出现，因为那需要更强的AI。</p><p>结果就是：一大批人失去了工作，却没有获得新的机会。</p><p>反AI运动开始了。不是反对AI本身，而是反对”用AI承诺未来，却制造现在的失业”。</p><p>一些激进组织开始破坏AI基础设施。数据中心遭到攻击，云服务被迫加强安保。</p><h3 id="国家间的新冷战"><a href="#国家间的新冷战" class="headerlink" title="国家间的新冷战"></a>国家间的新冷战</h3><p>地缘政治变得更加复杂。</p><p>那些在AI竞赛中落后的国家，突然发现赶超的可能性消失了。如果技术不再进步，先发优势就是永久优势。</p><p>中美之间的科技竞争变成了”存量争夺”：抢夺AI人才、控制训练数据、垄断推理算力。</p><p>欧洲试图通过监管来制衡，但发现自己既没有顶尖的AI，也没有制定规则的话语权。</p><p>一些发展中国家开始考虑：是不是该彻底放弃AI路线，专注于其他技术？</p><h2 id="第三波冲击：哲学与信仰"><a href="#第三波冲击：哲学与信仰" class="headerlink" title="第三波冲击：哲学与信仰"></a>第三波冲击：哲学与信仰</h2><h3 id="进步主义的崩溃"><a href="#进步主义的崩溃" class="headerlink" title="进步主义的崩溃"></a>进步主义的崩溃</h3><p>这场危机最深层的影响，是它动摇了现代社会的核心信仰：<strong>技术会持续进步</strong>。</p><p>过去三百年，人类社会建立在这样一个假设上：今天比昨天好，明天会比今天更好。蒸汽机、电力、计算机、互联网，每一次技术革命都验证了这个假设。</p><p>AI的停滞，第一次让人们质疑：进步是必然的吗？</p><p>如果AI遇到了天花板，其他技术会不会也有？物理学、生物学、材料科学，是不是都有各自的极限？</p><h3 id="意义危机"><a href="#意义危机" class="headerlink" title="意义危机"></a>意义危机</h3><p>对个体来说，冲击更加直接。</p><p>很多人，尤其是年轻人，把人生意义寄托在”参与AI革命”上。他们相信自己在创造未来，在改变世界。</p><p>现在，这个叙事崩塌了。</p><p>一位前OpenAI工程师在博客中写道：</p><blockquote><p>“我以为自己在建造通往AGI的阶梯。现在我意识到，我只是在一个死胡同里越走越深。那些深夜的加班，那些放弃的周末，那些牺牲的关系——为了什么？”</p></blockquote><p>这不是个例。硅谷的心理咨询师报告，抑郁和焦虑症患者激增。</p><h3 id="新的思潮"><a href="#新的思潮" class="headerlink" title="新的思潮"></a>新的思潮</h3><p>但危机也催生了新的思考。</p><p>一些哲学家开始重新审视技术与人的关系。如果AI不能替代人类，那人类的独特价值是什么？</p><p>宗教组织迎来了久违的增长。当技术无法提供答案，人们转向传统的意义来源。</p><p>还有一些人开始探索”后AI时代”的生活方式：减少对技术的依赖，重建社区联系，追求精神上的满足而不是效率的提升。</p><h2 id="第四章：适应与转型"><a href="#第四章：适应与转型" class="headerlink" title="第四章：适应与转型"></a>第四章：适应与转型</h2><h3 id="务实派的胜利"><a href="#务实派的胜利" class="headerlink" title="务实派的胜利"></a>务实派的胜利</h3><p>在混乱中，一些人开始冷静下来。</p><p>他们意识到：AI虽然停止进化，但现有能力已经很强大了。问题不是AI不够好，而是我们用得不够好。</p><p>一批”应用型”创业公司兴起。他们不追求技术突破，而是专注于：</p><ul><li>把AI整合进传统行业</li><li>优化现有AI的部署和运维</li><li>开发针对特定场景的解决方案</li></ul><p>这些公司不性感，不会上新闻头条，但它们活下来了，而且活得不错。</p><h3 id="教育的重塑"><a href="#教育的重塑" class="headerlink" title="教育的重塑"></a>教育的重塑</h3><p>大学开始调整课程。既然AI不会再进化，就不需要那么多研究型人才了。</p><p>新的培养方向是：</p><ul><li><strong>AI应用工程师</strong>：懂业务、会部署、能优化</li><li><strong>人机协作专家</strong>：设计人和AI共同工作的流程</li><li><strong>AI伦理与政策</strong>：处理AI带来的社会问题</li></ul><p>那些传统被认为”会被AI取代”的技能，重新受到重视：创造力、同理心、复杂沟通、伦理判断。</p><h3 id="社会契约的重建"><a href="#社会契约的重建" class="headerlink" title="社会契约的重建"></a>社会契约的重建</h3><p>政府开始介入。不是为了推动技术进步（那已经不可能了），而是为了处理技术停滞带来的社会问题。</p><p>一些国家尝试：</p><ul><li><strong>基本收入试点</strong>：为失业者提供基本生活保障</li><li><strong>工作分享计划</strong>：减少工作时长，创造更多岗位</li><li><strong>技能再培训项目</strong>：帮助被AI替代的工人转型</li></ul><p>这些尝试并不完美，但至少是在寻找解决方案。</p><h3 id="新的创新方向"><a href="#新的创新方向" class="headerlink" title="新的创新方向"></a>新的创新方向</h3><p>有趣的是，AI的停滞反而释放了其他领域的创新。</p><p>资金和人才从AI流向了：</p><ul><li><strong>生物技术</strong>：基因编辑、合成生物学</li><li><strong>量子计算</strong>：虽然进展缓慢，但有了更多关注</li><li><strong>清洁能源</strong>：太阳能、核聚变、储能技术</li><li><strong>太空探索</strong>：商业航天、月球基地</li></ul><p>讽刺的是，AI曾经吸走了所有资源。现在它的停滞，给其他技术创造了机会。</p><h2 id="第五章：新的平衡"><a href="#第五章：新的平衡" class="headerlink" title="第五章：新的平衡"></a>第五章：新的平衡</h2><p>到2030年，世界慢慢适应了”AI不再进步”的现实。</p><h3 id="产业格局"><a href="#产业格局" class="headerlink" title="产业格局"></a>产业格局</h3><p>AI产业分化成两类：</p><ol><li><strong>基础设施公司</strong>：提供稳定、可靠的AI服务，像电力公司一样</li><li><strong>应用公司</strong>：在特定场景中深耕，追求极致的用户体验</li></ol><p>那些试图继续”烧钱搞研发”的公司，要么死了，要么转型了。</p><p>市场不再追捧”颠覆式创新”，而是看重”可持续盈利”。这很无聊，但也很健康。</p><h3 id="社会心态"><a href="#社会心态" class="headerlink" title="社会心态"></a>社会心态</h3><p>人们不再把AI视为救世主或恶魔，而是一种工具。</p><p>有用的工具，但不是万能的。</p><p>年轻人的职业选择更加多元。不是所有聪明人都涌入科技行业了，医生、老师、艺术家、工匠又重新成为受尊敬的职业。</p><p>对未来的期待更加务实。不再幻想”AI会解决一切”，而是脚踏实地地解决具体问题。</p><h3 id="新的叙事"><a href="#新的叙事" class="headerlink" title="新的叙事"></a>新的叙事</h3><p>一种新的文化叙事出现了：<strong>技术有限，人无限</strong>。</p><p>AI遇到了天花板，但人的创造力、想象力、情感、价值观没有天花板。</p><p>科幻小说的主题变了。不再是”AI统治世界”或”AI拯救世界”，而是”在有限的技术条件下，人类如何创造意义”。</p><p>哲学家提出新的问题：如果技术不能提供答案，什么能？</p><h2 id="尾声：危机还是转机？"><a href="#尾声：危机还是转机？" class="headerlink" title="尾声：危机还是转机？"></a>尾声：危机还是转机？</h2><p>回头看，2028年的”智能危机”可能不是一场灾难，而是一次修正。</p><p>它打破了不切实际的幻想，迫使人类重新思考：我们真正需要什么？技术的意义是什么？进步的定义是什么？</p><p>有人说，这是人类历史上第一次主动”放慢脚步”。不是因为我们不想前进，而是因为我们意识到，前进的方向可能错了。</p><p>也许，真正的危机不是技术停滞，而是我们曾经对技术寄予了过高的期望。</p><p>也许，真正的转机不是找到下一个技术突破，而是学会在有限中创造无限。</p><hr><p><strong>后记</strong></p><p>这是一个思想实验，不是预言。</p><p>2028年会不会真的发生这样的危机？我不知道。</p><p>但值得思考的是：如果真的发生了，我们准备好了吗？</p><p>更重要的是：我们是不是应该在危机到来之前，就开始思考这些问题？</p><hr><p><em>写这篇文章的时候，GPT-5刚刚发布。所有指标都在提升。</em></p><p><em>但我还是忍不住想：如果有一天，这一切停止了呢？</em></p><p><em>也许，这个”如果”本身，就是最值得思考的问题。</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/2028-global-intelligence-crisis/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/2028-global-intelligence-crisis/"/>
    <published>2026-03-02T10:19:00.000Z</published>
    <summary>如果AI在2028年突然停止进步，会发生什么？这不是科幻，而是一个值得认真思考的问题。</summary>
    <title>2028全球智能危机</title>
    <updated>2026-03-02T10:19:00.000Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI Monetization" scheme="https://xiaoxiaduoyan.com/tags/AI-Monetization/"/>
    <category term="Side Hustle" scheme="https://xiaoxiaduoyan.com/tags/Side-Hustle/"/>
    <category term="Entrepreneurship" scheme="https://xiaoxiaduoyan.com/tags/Entrepreneurship/"/>
    <category term="Tech Monetization" scheme="https://xiaoxiaduoyan.com/tags/Tech-Monetization/"/>
    <content>
      <![CDATA[<h1 id="How-to-Earn-Your-First-Bucket-of-Gold-with-AI-7-Practical-Paths-for-Ordinary-People"><a href="#How-to-Earn-Your-First-Bucket-of-Gold-with-AI-7-Practical-Paths-for-Ordinary-People" class="headerlink" title="How to Earn Your First Bucket of Gold with AI: 7 Practical Paths for Ordinary People"></a>How to Earn Your First Bucket of Gold with AI: 7 Practical Paths for Ordinary People</h1><p>Another person in my feed is posting income screenshots. The title is always “Making $5K a Month with ChatGPT” or “AI Side Hustle Gave Me Financial Freedom.”</p><p>Click in, and it’s either selling courses or recruiting for MLM. People who actually make money with AI rarely advertise it loudly.</p><p>But that doesn’t mean opportunities don’t exist. It’s just that real opportunities look very different from what you see in marketing posts.</p><h2 id="Let’s-Be-Clear-AI-Isn’t-a-Money-Printer"><a href="#Let’s-Be-Clear-AI-Isn’t-a-Money-Printer" class="headerlink" title="Let’s Be Clear: AI Isn’t a Money Printer"></a>Let’s Be Clear: AI Isn’t a Money Printer</h2><p>Last year, a designer friend asked me: can you make money with Midjourney?</p><p>I said yes, but not the way you think.</p><p>His idea was simple: generate hundreds of images daily, upload to stock platforms, earn passive income. Two months later, he told me he hadn’t sold a single image.</p><p>Simple reason: too many AI-generated images, insanely fierce competition. Plus, buyers can tell which are AI-generated, and they’d rather pay for work with human touch.</p><p>That’s the first realization: <strong>AI is a tool, not a replacement</strong>. It can boost your efficiency, but can’t replace your value.</p><h2 id="Content-Creation-Easiest-to-Start-Also-Easiest-to-Fail"><a href="#Content-Creation-Easiest-to-Start-Also-Easiest-to-Fail" class="headerlink" title="Content Creation: Easiest to Start, Also Easiest to Fail"></a>Content Creation: Easiest to Start, Also Easiest to Fail</h2><p>I know a WeChat blogger who uses ChatGPT to write tech articles. At first, efficiency was indeed high, could produce five or six articles a day. But two months later, followers were dropping fast.</p><p>He later reviewed and found the problem: AI-generated content flows smoothly but lacks personal viewpoints. After reading three articles, readers can feel “this account is AI-written.”</p><p>How do successful people do it?</p><p><strong>Case: Xiao Wang’s Tech Blog</strong></p><p>Xiao Wang is a backend engineer. His approach:</p><ol><li>First thinks through solution to a technical problem himself</li><li>Uses AI to help organize into article structure</li><li>Key parts (personal insights, pitfall experiences) written by himself</li><li>Uses AI to polish language</li></ol><p>His blog now earns about $1,200 monthly, mainly from ads and paid columns.</p><p>Key point: <strong>AI handles execution, human handles thinking</strong>.</p><p>But honestly, content creation is getting increasingly competitive. Without depth in a professional field, hard to stand out.</p><h2 id="AI-Tool-Development-Lower-Barrier-But-More-Intense-Competition"><a href="#AI-Tool-Development-Lower-Barrier-But-More-Intense-Competition" class="headerlink" title="AI Tool Development: Lower Barrier, But More Intense Competition"></a>AI Tool Development: Lower Barrier, But More Intense Competition</h2><p>After GPT Store launched, many people rushed in to make GPTs. I tried too, made a “Paper Polishing Assistant.”</p><p>Spent two days tuning prompts, testing effects, writing documentation. First week after launch, indeed dozens of people used it. I was excited, thought I’d found a money path.</p><p>Then second week, similar GPTs appeared by the dozens. By third week, people were making better ones, and for free.</p><p>Now this GPT is basically unused.</p><p>What’s the lesson? <strong>Low-code tools lowered barriers, but also means your moat almost doesn’t exist</strong>.</p><p>However, some people still succeed.</p><p><strong>Case: Lao Li’s Industry Tool</strong></p><p>Lao Li works in construction. He found many engineers need to quickly generate technical specifications, but generic tools on the market don’t work well.</p><p>He made a specification generator specifically for construction using Claude. Function is simple, but particularly fits industry needs.</p><p>Now he charges monthly, stably earning $400-700 per month. Not many users, but very targeted, low churn rate.</p><p>Insight: <strong>Focus on niche verticals, solve real pain points</strong>.</p><h2 id="Consulting-Services-Knowing-AI-is-a-Scarce-Skill"><a href="#Consulting-Services-Knowing-AI-is-a-Scarce-Skill" class="headerlink" title="Consulting Services: Knowing AI is a Scarce Skill"></a>Consulting Services: Knowing AI is a Scarce Skill</h2><p>The most profitable person I’ve seen does “AI application consulting” for SMEs.</p><p>Sounds fancy, but the work is down-to-earth: teaching bosses how to use ChatGPT to improve work efficiency, helping them build simple AI workflows.</p><p>Not cheap, $500+ per consultation. But clients are happy to pay because they can see real results.</p><p>For example, what he did for a law firm:</p><ul><li>Use AI to organize case precedents, saving lawyers 80% of research time</li><li>Build case information extraction system, auto-generate preliminary analysis reports</li><li>Teach team to use AI to assist in drafting legal documents</li></ul><p>These things aren’t technically complex, but the law firm people don’t know how. He can translate technology into actual value, that’s his core competitiveness.</p><p>Key point: <strong>Don’t try to teach people AI technology, help them solve actual problems</strong>.</p><h2 id="Data-Services-Dirty-Work-But-Actually-Makes-Money"><a href="#Data-Services-Dirty-Work-But-Actually-Makes-Money" class="headerlink" title="Data Services: Dirty Work, But Actually Makes Money"></a>Data Services: Dirty Work, But Actually Makes Money</h2><p>Data annotation—many people look down on it. Think it’s low-end, repetitive, no technical content.</p><p>But a friend with a data annotation studio made over $60K last year.</p><p>His model:</p><ol><li>Doesn’t do specific work himself, but organizes manpower</li><li>Takes projects from big platforms, then subcontracts to freelancers</li><li>Uses AI to assist quality checks, improving efficiency</li></ol><p>Sounds simple, but execution requires management skills. You need to recruit, train, quality check, interface with clients.</p><p>This isn’t a relaxed side hustle, more like entrepreneurship. But relatively low barrier, can stably make money.</p><p>Another direction is <strong>synthetic data</strong>.</p><p>Many AI companies now need training data, but real data is hard to obtain. Some people specifically use AI to generate training data, then sell to these companies.</p><p>Technical barrier isn’t high, but requires understanding client needs. If you have domain knowledge (like healthcare, legal), this is a good direction.</p><h2 id="E-commerce-AI-Tools-Don’t-Build-Platform-Provide-Service"><a href="#E-commerce-AI-Tools-Don’t-Build-Platform-Provide-Service" class="headerlink" title="E-commerce AI Tools: Don’t Build Platform, Provide Service"></a>E-commerce AI Tools: Don’t Build Platform, Provide Service</h2><p>Many people want to do “AI e-commerce tools,” make a SaaS product, charge monthly.</p><p>This path is too hard. You need to develop product, acquire users, continuously operate. Individuals simply can’t handle it.</p><p>But flip the thinking: <strong>don’t make product, provide service</strong>.</p><p><strong>Case: A Qiang’s E-commerce Copy Service</strong></p><p>A Qiang used to be in e-commerce operations. His current business: help Taobao shop owners batch-generate optimized product titles and descriptions.</p><p>Not simply using AI to generate, but:</p><ol><li>Analyze shop data, find products with low conversion rates</li><li>Combine industry hot words and search trends, use AI to generate multiple versions</li><li>A&#x2F;B test, find optimal version</li><li>Continuously optimize</li></ol><p>He charges per project, $300-700 per shop. Can do five or six projects a month.</p><p>Key is he’s not selling tools, he’s selling results. Clients want “improved conversion rates,” not “an AI tool.”</p><h2 id="AI-Education-Teach-Others-AI-But-Don’t-Sell-Anxiety"><a href="#AI-Education-Teach-Others-AI-But-Don’t-Sell-Anxiety" class="headerlink" title="AI Education: Teach Others AI, But Don’t Sell Anxiety"></a>AI Education: Teach Others AI, But Don’t Sell Anxiety</h2><p>AI education market is big, but most is cutting leeks.</p><p>What does valuable AI education look like?</p><p>I’ve seen a good example: AI application course for designers.</p><p>This course doesn’t teach you how to use ChatGPT, but how to integrate AI into design workflow:</p><ul><li>Use AI for brainstorming and concept generation</li><li>Use Midjourney for rapid prototyping</li><li>Use AI to assist user research</li><li>Integrate AI tools into actual projects</li></ul><p>Course costs $300, not cheap. But people who took it say it’s worth it, because they can actually use it.</p><p>Compared to those “learn AI in 3 days, make $10K a month” courses, this is real value.</p><p>If you have professional accumulation in some field, consider doing this. But remember: <strong>don’t sell anxiety, provide value</strong>.</p><h2 id="Investment-and-Incubation-Hardest-Also-Highest-Return"><a href="#Investment-and-Incubation-Hardest-Also-Highest-Return" class="headerlink" title="Investment and Incubation: Hardest, Also Highest Return"></a>Investment and Incubation: Hardest, Also Highest Return</h2><p>This path isn’t for ordinary people. Requires capital, resources, vision.</p><p>But still worth mentioning, because some people do have this capability.</p><p>If you:</p><ul><li>Have some capital (at least tens of thousands in spare cash)</li><li>Have industry connections and resources</li><li>Can identify good projects</li></ul><p>Consider early-stage investing in AI projects, or incubate yourself.</p><p>But this isn’t a side hustle, it’s entrepreneurship. Risk is high, failure rate is also high.</p><p>A friend who does early-stage investing invested in 5 AI projects last year, 4 died, 1 still struggling. He says that’s normal.</p><p>So don’t be fooled by “investing in AI projects get rich overnight” stories. The real investment world is far crueler than you imagine.</p><h2 id="Let’s-Talk-Straight"><a href="#Let’s-Talk-Straight" class="headerlink" title="Let’s Talk Straight"></a>Let’s Talk Straight</h2><p>By now, you might have noticed: none of these paths are “get rich quick” methods.</p><p>That’s the truth. <strong>AI isn’t magic for passive income, it’s a tool that lets you do more</strong>.</p><p>Those $10K a month cases? Might exist, but they either have deep professional accumulation, strong execution, or got really lucky.</p><p>What can ordinary people do?</p><ol><li><strong>Start as side hustle</strong>: Don’t quit your job to start a business, test waters with spare time first</li><li><strong>Focus on one direction</strong>: Don’t try to do everything, pick one and go deep</li><li><strong>Provide real value</strong>: Think about what problem you can help others solve</li><li><strong>Continuously iterate</strong>: First time definitely won’t be good, key is constant improvement</li></ol><p>And most importantly: <strong>stay skeptical</strong>.</p><p>When you see “AI money-making” ads, first think: if it’s really that profitable, why would they tell you?</p><h2 id="Finally"><a href="#Finally" class="headerlink" title="Finally"></a>Finally</h2><p>AI has indeed created new money-making opportunities, but these opportunities belong to those who can provide value.</p><p>If you’re just looking for a “passive income” method, this article might disappoint you.</p><p>But if you’re willing to invest time, accumulate experience, solve real problems, AI can become your good helper.</p><p>Your first bucket of gold won’t fall from the sky, but it might be closer than you think.</p><p>The prerequisite is, you have to actually do it.</p><hr><p><em>I’m also trying to use AI to improve work efficiency. Some successes, some failures.</em></p><p><em>This article isn’t a guide, it’s observations and thoughts.</em></p><p><em>If you have other real AI money-making experiences, welcome to share.</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/ai-first-bucket-gold-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/ai-first-bucket-gold-en/"/>
    <published>2026-03-02T09:32:00.000Z</published>
    <summary>AI money-making opportunities do exist, but not the 'making $10K a month' myths you see online. This article talks about what ordinary people can actually do.</summary>
    <title>How to Earn Your First Bucket of Gold with AI: 7 Practical Paths for Ordinary People</title>
    <updated>2026-03-02T09:32:00.000Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <category term="AI赚钱" scheme="https://xiaoxiaduoyan.com/tags/AI%E8%B5%9A%E9%92%B1/"/>
    <category term="副业" scheme="https://xiaoxiaduoyan.com/tags/%E5%89%AF%E4%B8%9A/"/>
    <category term="创业" scheme="https://xiaoxiaduoyan.com/tags/%E5%88%9B%E4%B8%9A/"/>
    <category term="技术变现" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E5%8F%98%E7%8E%B0/"/>
    <content>
      <![CDATA[<h1 id="如何用AI赚取第一桶金：普通人切实可行的7个路径"><a href="#如何用AI赚取第一桶金：普通人切实可行的7个路径" class="headerlink" title="如何用AI赚取第一桶金：普通人切实可行的7个路径"></a>如何用AI赚取第一桶金：普通人切实可行的7个路径</h1><p>朋友圈又有人在晒收入截图了。标题永远是”用ChatGPT月入五万”或者”AI副业让我实现财富自由”。</p><p>点进去一看，要么是卖课的，要么是拉下线的。真正靠AI赚到钱的人，很少会大张旗鼓地宣传。</p><p>但这不代表机会不存在。只是，真实的机会和你在营销号看到的很不一样。</p><h2 id="先说清楚：AI不是印钞机"><a href="#先说清楚：AI不是印钞机" class="headerlink" title="先说清楚：AI不是印钞机"></a>先说清楚：AI不是印钞机</h2><p>去年有个做设计的朋友问我：用Midjourney能不能赚钱？</p><p>我说能，但不是你想的那种赚法。</p><p>他的想法很简单：每天生成几百张图，挂到图库平台上，躺着收钱。结果两个月后，他告诉我一张图都没卖出去。</p><p>原因很简单：AI生成的图片太多了，竞争激烈得离谱。而且买图的人看得出来哪些是AI生成的，他们更愿意为有人味的作品付费。</p><p>这就是第一个认知：<strong>AI是工具，不是替代品</strong>。它能提升你的效率，但不能替代你的价值。</p><h2 id="内容创作：最容易入门，也最容易失败"><a href="#内容创作：最容易入门，也最容易失败" class="headerlink" title="内容创作：最容易入门，也最容易失败"></a>内容创作：最容易入门，也最容易失败</h2><p>我认识一个公众号博主，用ChatGPT写科技文章。一开始效率确实高，一天能产出五六篇。但两个月后，掉粉掉得厉害。</p><p>他后来复盘，发现问题在于：AI生成的内容虽然流畅，但缺乏个人观点。读者看三篇就能感觉出来，”这号是AI写的”。</p><p>真正做得好的人是怎么做的？</p><p><strong>案例：小王的技术博客</strong></p><p>小王是个后端工程师。他的做法是：</p><ol><li>自己先思考一个技术问题的解决思路</li><li>用AI帮他整理成文章结构</li><li>关键部分（个人见解、踩坑经验）自己写</li><li>用AI润色语言</li></ol><p>他的博客现在月收入大概8000块，主要来自广告和付费专栏。</p><p>关键点：<strong>AI负责执行，人负责思考</strong>。</p><p>但说实话，内容创作这条路越来越卷了。如果你没有专业领域的深度，很难脱颖而出。</p><h2 id="AI工具开发：门槛降低了，但竞争更激烈了"><a href="#AI工具开发：门槛降低了，但竞争更激烈了" class="headerlink" title="AI工具开发：门槛降低了，但竞争更激烈了"></a>AI工具开发：门槛降低了，但竞争更激烈了</h2><p>GPT Store上线后，很多人涌进去做GPTs。我也试过，做了个”论文润色助手”。</p><p>花了两天时间调试prompt，测试效果，写说明文档。上线后第一周，确实有几十个人用。我很兴奋，觉得找到了赚钱路子。</p><p>然后第二周，类似的GPT就出现了十几个。到第三周，已经有人做得比我好，还免费。</p><p>现在这个GPT基本没人用了。</p><p>教训是什么？<strong>低代码工具降低了门槛，但也意味着你的护城河几乎不存在</strong>。</p><p>不过，还是有人能做成的。</p><p><strong>案例：老李的行业工具</strong></p><p>老李在建筑行业工作。他发现很多工程师需要快速生成技术说明书，但市面上的通用工具都不好用。</p><p>他用Claude做了一个专门针对建筑行业的说明书生成工具。功能很简单，但特别贴合行业需求。</p><p>现在他按月收费，每个月能稳定赚3000-5000。用户不多，但很精准，流失率低。</p><p>启发：<strong>专注细分领域，解决真实痛点</strong>。</p><h2 id="咨询服务：会用AI是一种稀缺能力"><a href="#咨询服务：会用AI是一种稀缺能力" class="headerlink" title="咨询服务：会用AI是一种稀缺能力"></a>咨询服务：会用AI是一种稀缺能力</h2><p>我见过最赚钱的一个人，是给中小企业做”AI应用咨询”的。</p><p>听起来很高大上，实际上做的事情很接地气：教老板们怎么用ChatGPT提升工作效率，帮他们搭建简单的AI工作流。</p><p>收费不便宜，一次咨询3000起。但客户很愿意付钱，因为确实能看到效果。</p><p>比如他帮一家律所做的事情：</p><ul><li>用AI整理判例，节省律师80%的查资料时间</li><li>搭建案件信息提取系统，自动生成初步分析报告</li><li>教团队用AI辅助撰写法律文书</li></ul><p>这些东西技术上都不复杂，但律所的人不会。他能把技术转化成实际价值，这就是他的核心竞争力。</p><p>关键点：<strong>别想着教人AI技术，而是帮人解决实际问题</strong>。</p><h2 id="数据服务：脏活累活，但确实赚钱"><a href="#数据服务：脏活累活，但确实赚钱" class="headerlink" title="数据服务：脏活累活，但确实赚钱"></a>数据服务：脏活累活，但确实赚钱</h2><p>数据标注这个活，很多人看不上。觉得低端、重复、没技术含量。</p><p>但有个做数据标注工作室的朋友，去年赚了四十多万。</p><p>他的模式是这样的：</p><ol><li>自己不干具体活，而是组织人力</li><li>接大平台的项目，然后分包给兼职人员</li><li>用AI辅助做质量检查，提高效率</li></ol><p>听起来简单，但执行起来需要管理能力。你得招人、培训、质检、对接客户。</p><p>这不是轻松的副业，更像是创业。但门槛相对低，能稳定赚钱。</p><p>另一个方向是<strong>合成数据</strong>。</p><p>现在很多AI公司需要训练数据，但真实数据不好获取。有人专门用AI生成训练数据，然后卖给这些公司。</p><p>技术门槛不高，但需要理解客户的需求。如果你有特定领域的知识（比如医疗、法律），这是个不错的方向。</p><h2 id="电商AI工具：别做平台，做服务"><a href="#电商AI工具：别做平台，做服务" class="headerlink" title="电商AI工具：别做平台，做服务"></a>电商AI工具：别做平台，做服务</h2><p>很多人想做”AI电商工具”，做个SaaS产品，收月费。</p><p>这条路太难了。你要开发产品、获取用户、持续运营。个人根本搞不定。</p><p>但换个思路：<strong>不做产品，做服务</strong>。</p><p><strong>案例：阿强的电商文案服务</strong></p><p>阿强原来是电商运营。他现在的业务是：帮淘宝店家批量生成优化后的商品标题和描述。</p><p>不是简单地用AI生成，而是：</p><ol><li>分析店铺的数据，找到转化率低的商品</li><li>结合行业热词和搜索趋势，用AI生成多个版本</li><li>A&#x2F;B测试，找出最优版本</li><li>持续优化</li></ol><p>他按项目收费，一个店铺一次收2000-5000。一个月能做五六个项目。</p><p>关键是他不是在卖工具，而是在卖结果。客户要的是”提升转化率”，不是”一个AI工具”。</p><h2 id="AI教育：教别人用AI，但别卖焦虑"><a href="#AI教育：教别人用AI，但别卖焦虑" class="headerlink" title="AI教育：教别人用AI，但别卖焦虑"></a>AI教育：教别人用AI，但别卖焦虑</h2><p>AI教育市场很大，但大部分是割韭菜的。</p><p>真正有价值的AI教育是什么样的？</p><p>我见过一个做得好的例子：针对设计师的AI应用课程。</p><p>这个课程不是教你怎么用ChatGPT，而是教你怎么把AI融入设计工作流：</p><ul><li>用AI做头脑风暴和概念生成</li><li>用Midjourney做快速原型</li><li>用AI辅助做用户研究</li><li>整合AI工具到实际项目中</li></ul><p>课程1980元，不便宜。但上过课的人都说值，因为确实能用上。</p><p>对比那些”3天学会用AI月入十万”的课程，这才是真正的价值。</p><p>如果你在某个领域有专业积累，可以考虑做这个。但记住：<strong>别卖焦虑，提供价值</strong>。</p><h2 id="投资与孵化：这是最难的，也是回报最高的"><a href="#投资与孵化：这是最难的，也是回报最高的" class="headerlink" title="投资与孵化：这是最难的，也是回报最高的"></a>投资与孵化：这是最难的，也是回报最高的</h2><p>这条路不是给普通人准备的。需要资金、资源、眼光。</p><p>但还是要提一下，因为有些人确实有这个能力。</p><p>如果你：</p><ul><li>有一定资金（至少几十万闲钱）</li><li>有行业人脉和资源</li><li>能识别好的项目</li></ul><p>可以考虑早期投资AI相关项目，或者自己孵化。</p><p>但这不是副业，是创业。风险很高，失败率也很高。</p><p>我认识一个做早期投资的朋友，去年投了5个AI项目，4个死了，1个还在挣扎。他说这就是常态。</p><p>所以别被”投资AI项目一夜暴富”的故事迷惑。真实的投资世界，远比你想象的残酷。</p><h2 id="说点实话"><a href="#说点实话" class="headerlink" title="说点实话"></a>说点实话</h2><p>写到这里，你可能发现了：这些路径都不是”快速赚钱”的方法。</p><p>事实就是这样。<strong>AI不是让你躺着赚钱的魔法，而是让你能做更多事的工具</strong>。</p><p>那些月入十万的案例？可能存在，但他们要么有深厚的专业积累，要么有很强的执行力，要么运气特别好。</p><p>普通人能做什么？</p><ol><li><strong>从副业开始</strong>：别辞职创业，先用业余时间试水</li><li><strong>聚焦一个方向</strong>：别什么都想做，选一个深入下去</li><li><strong>提供真实价值</strong>：想想你能帮别人解决什么问题</li><li><strong>持续迭代</strong>：第一次肯定做不好，关键是不断改进</li></ol><p>还有最重要的一点：<strong>保持怀疑</strong>。</p><p>看到”AI赚钱”的广告，先想想：如果真那么好赚，他为什么要告诉你？</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>AI确实创造了新的赚钱机会，但这些机会属于那些能提供价值的人。</p><p>如果你只是想找个”躺着赚钱”的方法，这篇文章可能让你失望了。</p><p>但如果你愿意投入时间、积累经验、解决真实问题，AI能成为你的好帮手。</p><p>第一桶金不会从天而降，但它可能比你想象的更近。</p><p>前提是，你得动手去做。</p><hr><p><em>我自己也在尝试用AI提升工作效率。有成功，有失败。</em></p><p><em>这篇文章不是指南，是观察和思考。</em></p><p><em>如果你有其他真实的AI赚钱经验，欢迎分享。</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/ai-first-bucket-gold/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/ai-first-bucket-gold/"/>
    <published>2026-03-02T09:32:00.000Z</published>
    <summary>AI赚钱的机会确实存在，但不是你在网上看到的那种'月入十万'的神话。这篇文章聊聊普通人真正能做的事。</summary>
    <title>如何用AI赚取第一桶金：普通人切实可行的7个路径</title>
    <updated>2026-03-02T09:32:00.000Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI Security" scheme="https://xiaoxiaduoyan.com/tags/AI-Security/"/>
    <category term="Open Source Security" scheme="https://xiaoxiaduoyan.com/tags/Open-Source-Security/"/>
    <category term="Code Security" scheme="https://xiaoxiaduoyan.com/tags/Code-Security/"/>
    <category term="Supply Chain Security" scheme="https://xiaoxiaduoyan.com/tags/Supply-Chain-Security/"/>
    <content>
      <![CDATA[<h1 id="AI’s-Open-Source-Productivity-Explosion-How-Do-We-Keep-It-Secure"><a href="#AI’s-Open-Source-Productivity-Explosion-How-Do-We-Keep-It-Secure" class="headerlink" title="AI’s Open Source Productivity Explosion: How Do We Keep It Secure?"></a>AI’s Open Source Productivity Explosion: How Do We Keep It Secure?</h1><p>Last year, a developer bragged on Twitter: used Copilot to write a complete backend system, finished in three days. Hundreds of replies below, half marveling at the efficiency, half asking “did you review the code?”</p><p>He never answered the second question.</p><h2 id="The-Productivity-Explosion-is-Real"><a href="#The-Productivity-Explosion-is-Real" class="headerlink" title="The Productivity Explosion is Real"></a>The Productivity Explosion is Real</h2><p>The data doesn’t lie. GitHub statistics show that AI-generated code commits increased 300% year-over-year in 2024. This isn’t incremental improvement—it’s an order-of-magnitude leap.</p><p>I’ve noticed something strange in many open source projects lately: commit histories look different. Features that used to require days of iteration now often appear as single, massive commits. You can tell from the commit messages:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">feat: add complete authentication system with JWT, refresh tokens, rate limiting, and email verification</span><br><span class="line"></span><br><span class="line">+2847 -0</span><br></pre></td></tr></table></figure><p>That’s not something one person can write in three days, but AI can generate a first draft in three hours.</p><p>Here’s the question: who’s reviewing those 2,847 lines?</p><h2 id="The-Code-Review-Dilemma"><a href="#The-Code-Review-Dilemma" class="headerlink" title="The Code Review Dilemma"></a>The Code Review Dilemma</h2><p>Traditional code review assumes this model: developers write code, reviewers check logic, performance, and security line by line. This works when code volume is manageable.</p><p>But AI changed the game.</p><p>Typical scenario: an intern uses ChatGPT to generate an authentication module. Looks feature-complete, passes tests. The reviewer spends half an hour browsing, finds no obvious issues, approves merge.</p><p>Three months later, the security team discovers a timing attack vulnerability. Attackers can infer whether usernames exist by measuring response times.</p><p>This is the classic problem with AI-generated code: <strong>functionally correct, but containing non-obvious security flaws</strong>.</p><p>Worse, reviewers face a subtle psychological trap when reviewing AI code: “This is AI-written, should be pretty standard, right?” This assumption is dangerous.</p><h2 id="New-Supply-Chain-Threats"><a href="#New-Supply-Chain-Threats" class="headerlink" title="New Supply Chain Threats"></a>New Supply Chain Threats</h2><p>Open source supply chain security was already hard. AI makes it harder.</p><p>Last year, npm saw a batch of “seemingly normal” packages. Code structure was reasonable, documentation complete, even had unit tests. But closer inspection revealed these packages executed malicious code under specific conditions.</p><p>Security researchers later confirmed these packages were likely AI-batch-generated. Attackers only needed to:</p><ol><li>Use AI to generate a seemingly useful package</li><li>Plant malicious code at key points</li><li>Use AI to generate “natural” commit history</li><li>Publish to npm</li></ol><p>Frighteningly cheap, remarkably effective. Because these packages look indistinguishable from legitimate ones at first glance.</p><p>We’re no longer facing a few hackers handcrafting malicious packages. We might be facing industrialized, scaled supply chain attacks.</p><h2 id="Why-Traditional-Solutions-Fail"><a href="#Why-Traditional-Solutions-Fail" class="headerlink" title="Why Traditional Solutions Fail"></a>Why Traditional Solutions Fail</h2><p>Static analysis tools seem somewhat powerless against AI code.</p><p>Simple reason: these tools rely on rules and pattern matching. But AI-generated code is often “too standard,” bypassing many static checks.</p><p>For example, traditional SQL injection detection flags code like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;SELECT * FROM users WHERE id = &quot;</span> + user_id</span><br></pre></td></tr></table></figure><p>But AI typically generates “safer-looking” code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">f&quot;SELECT * FROM users WHERE id = <span class="subst">&#123;sanitize_input(user_id)&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure><p>Problem is: <code>sanitize_input</code> might not exist, or its implementation might be flawed. But seeing the “sanitization” step, static analysis tools might let it pass.</p><p>Manual review hit bottlenecks too. Facing thousands of lines of AI-generated code, reviewers struggle to maintain focus. Cognitive load is too high, easy to miss critical issues.</p><h2 id="What-Kind-of-Security-Solutions-Do-We-Need"><a href="#What-Kind-of-Security-Solutions-Do-We-Need" class="headerlink" title="What Kind of Security Solutions Do We Need"></a>What Kind of Security Solutions Do We Need</h2><p>Honestly, I don’t have perfect answers. But from practice, a few directions seem promising.</p><h3 id="1-Intervene-During-Generation"><a href="#1-Intervene-During-Generation" class="headerlink" title="1. Intervene During Generation"></a>1. Intervene During Generation</h3><p>Rather than review after the fact, inject security constraints while AI generates code.</p><p>People are already trying this approach. For example, explicitly requiring in prompts:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Generate user login endpoint, requirements:</span><br><span class="line">- Use parameterized queries to prevent SQL injection</span><br><span class="line">- Passwords must use bcrypt encryption, not MD5 or SHA1</span><br><span class="line">- Implement rate limiting, same IP max 5 attempts per 5 minutes</span><br><span class="line">- All error messages must be uniform, not reveal whether user exists</span><br></pre></td></tr></table></figure><p>This generates much better code. But it requires developers themselves to have security awareness, knowing what to ask for.</p><h3 id="2-Build-Secure-Code-Libraries"><a href="#2-Build-Secure-Code-Libraries" class="headerlink" title="2. Build Secure Code Libraries"></a>2. Build Secure Code Libraries</h3><p>Rather than letting AI generate from scratch each time, build a set of security-reviewed code templates.</p><p>Stripe’s approach is worth noting. They have an internal code snippet library. All code involving sensitive operations comes from this library. Developers can use AI assistance, but critical parts must use verified templates.</p><p>Not a perfect solution, but at least ensures baseline security.</p><h3 id="3-Redesign-Review-Processes"><a href="#3-Redesign-Review-Processes" class="headerlink" title="3. Redesign Review Processes"></a>3. Redesign Review Processes</h3><p>Traditional pull request review may no longer suit the AI era.</p><p>Some teams are experimenting with new workflows:</p><ul><li>Grade AI-generated code: critical path code requires deep manual review</li><li>Introduce “security reviewer” role, specifically responsible for checking AI-generated code security</li><li>Use differentiated review: AI-generated code and human-written code adopt different review standards</li></ul><p>These experiments are ongoing, but the direction is right.</p><h3 id="4-Toolchain-Upgrades"><a href="#4-Toolchain-Upgrades" class="headerlink" title="4. Toolchain Upgrades"></a>4. Toolchain Upgrades</h3><p>We need next-generation security tools specifically for AI-generated code characteristics.</p><p>Some interesting attempts:</p><ul><li>Semantic analysis tools: not just syntax, but understanding code intent</li><li>Anomaly pattern detection: flag code that “looks too perfect”</li><li>AI vs AI: use AI to review AI-generated code</li></ul><p>The last one sounds ironic, but might be most effective. After all, AI best understands what mistakes AI makes.</p><h2 id="Where-Are-the-Responsibility-Boundaries"><a href="#Where-Are-the-Responsibility-Boundaries" class="headerlink" title="Where Are the Responsibility Boundaries"></a>Where Are the Responsibility Boundaries</h2><p>This is an even harder question.</p><p>When AI-generated code has security issues, who’s responsible?</p><ul><li>Developers say: I just used a tool, how would I know the generated code has problems?</li><li>AI providers say: Our terms of service say generated code needs manual review.</li><li>Companies say: We trust developers’ professional judgment.</li></ul><p>Result: nobody’s really responsible.</p><p>This responsibility ambiguity will have disastrous consequences. We need clear rules:</p><ul><li>Developers using AI to generate code have an obligation to understand and review generated code</li><li>AI providers need to warn about known security issues</li><li>Organizations need clear AI code usage guidelines</li></ul><p>Laws and regulations may intervene, but before that, the industry needs self-regulation.</p><h2 id="Some-Actionable-Suggestions"><a href="#Some-Actionable-Suggestions" class="headerlink" title="Some Actionable Suggestions"></a>Some Actionable Suggestions</h2><p>For individual developers:</p><ol><li>Never directly copy-paste AI-generated code, at least understand what it’s doing</li><li>Stay skeptical about security-related code, manually check critical logic</li><li>Learn basic security knowledge, AI can’t replace your judgment</li></ol><p>For teams:</p><ol><li>Establish AI code usage guidelines, clarify which scenarios allow it, which don’t</li><li>Invest in security training, ensure team understands AI code risks</li><li>Build layered review mechanisms, critical code must pass security expert review</li></ol><p>For open source projects:</p><ol><li>State in README which parts used AI assistance</li><li>Conduct additional security review for AI-generated code</li><li>Establish vulnerability disclosure mechanisms, encourage security researchers to participate</li></ol><h2 id="This-Isn’t-Alarmism"><a href="#This-Isn’t-Alarmism" class="headerlink" title="This Isn’t Alarmism"></a>This Isn’t Alarmism</h2><p>I’m not opposing AI-assisted development. Quite the opposite, I believe AI will become a standard development tool.</p><p>But we must face a fact: <strong>explosive productivity growth must be accompanied by synchronized security capability improvement</strong>.</p><p>The issue isn’t whether AI generates code with vulnerabilities—it definitely will. The issue is whether we’ve established sufficient mechanisms to identify and fix these vulnerabilities.</p><p>Current situation: code generation speed increased 10x, but security review speed remains the same. This gap widens every day.</p><p>If we don’t close this gap soon, we might face an open source security crisis. Not because AI is malicious, but because our security mechanisms can’t keep up with productivity explosion.</p><h2 id="Finally"><a href="#Finally" class="headerlink" title="Finally"></a>Finally</h2><p>Technological progress is always a double-edged sword. Steam engines brought industrial revolution, also brought environmental pollution. The internet connected the world, also created new crime spaces.</p><p>AI dramatically improves development efficiency, while also amplifying security risks. This is the reality we must face.</p><p>The good news is, we still have time. The open source community has always been good at self-correction and evolution. As long as we recognize the problem’s severity and build security mechanisms adapted to the AI era, this productivity explosion will ultimately be positive.</p><p>But the time window won’t stay open forever. Now is the time to act.</p><hr><p><em>How much code in your project is AI-generated? Have you reviewed it?</em></p><p><em>This isn’t questioning, it’s reminding. Including myself.</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/ai-opensource-security-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/ai-opensource-security-en/"/>
    <published>2026-03-02T09:28:00.000Z</published>
    <summary>AI has made code generation 10x faster, but security review speed remains unchanged. This asymmetric race is reshaping the entire security foundation of the open source ecosystem.</summary>
    <title>AI's Open Source Productivity Explosion: How Do We Keep It Secure?</title>
    <updated>2026-03-02T09:28:00.000Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <category term="AI安全" scheme="https://xiaoxiaduoyan.com/tags/AI%E5%AE%89%E5%85%A8/"/>
    <category term="开源安全" scheme="https://xiaoxiaduoyan.com/tags/%E5%BC%80%E6%BA%90%E5%AE%89%E5%85%A8/"/>
    <category term="代码安全" scheme="https://xiaoxiaduoyan.com/tags/%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8/"/>
    <category term="供应链安全" scheme="https://xiaoxiaduoyan.com/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E5%AE%89%E5%85%A8/"/>
    <content>
      <![CDATA[<h1 id="AI导致开源生产率爆炸，安全如何保障？"><a href="#AI导致开源生产率爆炸，安全如何保障？" class="headerlink" title="AI导致开源生产率爆炸，安全如何保障？"></a>AI导致开源生产率爆炸，安全如何保障？</h1><p>去年有个开发者在Twitter上炫耀：用Copilot写了一个完整的后台系统，三天完工。底下几百条回复，一半在惊叹效率，一半在问”你审查代码了吗”。</p><p>他没有回答第二个问题。</p><h2 id="生产力爆炸正在发生"><a href="#生产力爆炸正在发生" class="headerlink" title="生产力爆炸正在发生"></a>生产力爆炸正在发生</h2><p>数据不会骗人。GitHub的统计显示，2024年AI生成的代码提交量同比增长了300%。这不是渐进式的改进，而是量级的跃迁。</p><p>我最近观察到一个现象：很多开源项目的提交历史变得很奇怪。以前一个功能可能需要几天的迭代，现在往往是一次性提交一大坨代码。看commit message能明显感觉出来：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">feat: add complete authentication system with JWT, refresh tokens, rate limiting, and email verification</span><br><span class="line"></span><br><span class="line">+2847 -0</span><br></pre></td></tr></table></figure><p>这不是一个人三天能写完的东西，但AI可以在三个小时内生成初稿。</p><p>问题来了：谁在审查这2847行代码？</p><h2 id="安全审查的困境"><a href="#安全审查的困境" class="headerlink" title="安全审查的困境"></a>安全审查的困境</h2><p>传统的代码审查假设是这样的：开发者写代码，审查者逐行检查逻辑、性能、安全问题。这个模式在代码量可控的时候还能运转。</p><p>但AI改变了游戏规则。</p><p>一个典型场景：实习生用ChatGPT生成了一个用户认证模块，看起来功能完整，测试也通过了。代码审查者花了半小时浏览，没发现明显问题，批准合并。</p><p>三个月后，安全团队发现这个模块存在时序攻击漏洞。攻击者可以通过测量响应时间推断用户名是否存在。</p><p>这是AI生成代码的典型问题：<strong>功能正确，但存在非显而易见的安全隐患</strong>。</p><p>更糟糕的是，审查者面对AI生成的代码时，会产生一种微妙的心理：这是AI写的，应该比较标准吧？这种假设是危险的。</p><h2 id="供应链的新威胁"><a href="#供应链的新威胁" class="headerlink" title="供应链的新威胁"></a>供应链的新威胁</h2><p>开源供应链安全本来就是个难题，AI让它变得更难了。</p><p>去年npm仓库里出现了一批”看起来很正常”的包。它们的代码结构合理、文档完整、甚至有单元测试。但细查之下会发现，这些包在特定条件下会执行恶意代码。</p><p>安全研究员后来确认，这些包很可能是用AI批量生成的。攻击者只需要：</p><ol><li>用AI生成一个看起来有用的包</li><li>在关键位置植入恶意代码</li><li>用AI生成”自然”的commit历史</li><li>发布到npm</li></ol><p>成本低得可怕，效果却惊人。因为这些包从表面看和正常包没什么区别。</p><p>我们现在面临的不再是几个黑客手工制作恶意包，而是可能面对工业化、规模化的供应链攻击。</p><h2 id="为什么传统方案失效了"><a href="#为什么传统方案失效了" class="headerlink" title="为什么传统方案失效了"></a>为什么传统方案失效了</h2><p>静态分析工具在AI代码面前显得有些无力。</p><p>原因很简单：这些工具依赖规则和模式匹配。但AI生成的代码往往”太标准了”，反而绕过了很多静态检查。</p><p>举个例子，传统的SQL注入检测会标记这样的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;SELECT * FROM users WHERE id = &quot;</span> + user_id</span><br></pre></td></tr></table></figure><p>但AI通常会生成看起来”更安全”的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">f&quot;SELECT * FROM users WHERE id = <span class="subst">&#123;sanitize_input(user_id)&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure><p>问题是：<code>sanitize_input</code>函数可能根本不存在，或者实现有漏洞。但静态分析工具看到有”清理”这个动作，就可能放过它。</p><p>人工审查也遇到了瓶颈。面对成千上万行AI生成的代码，审查者很难保持专注。认知负荷太大，很容易漏掉关键问题。</p><h2 id="我们需要什么样的安全方案"><a href="#我们需要什么样的安全方案" class="headerlink" title="我们需要什么样的安全方案"></a>我们需要什么样的安全方案</h2><p>说实话，我没有完美答案。但从实践来看，有几个方向是靠谱的。</p><h3 id="1-在生成时就介入"><a href="#1-在生成时就介入" class="headerlink" title="1. 在生成时就介入"></a>1. 在生成时就介入</h3><p>与其事后审查，不如在AI生成代码时就加入安全约束。</p><p>现在已经有人在尝试这个方向。比如在prompt里明确要求：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">请生成用户登录接口，要求：</span><br><span class="line">- 使用参数化查询防止SQL注入</span><br><span class="line">- 密码必须用bcrypt加密，不能用MD5或SHA1</span><br><span class="line">- 实现速率限制，同一IP 5分钟最多尝试5次</span><br><span class="line">- 所有错误信息必须统一，不能泄露用户是否存在</span><br></pre></td></tr></table></figure><p>这样生成的代码会好很多。但这要求开发者自己有安全意识，知道该提什么要求。</p><h3 id="2-建立安全代码库"><a href="#2-建立安全代码库" class="headerlink" title="2. 建立安全代码库"></a>2. 建立安全代码库</h3><p>与其让AI每次从零生成，不如建立一套经过审查的安全代码模板。</p><p>Stripe的做法值得参考。他们内部有一套代码片段库，所有涉及敏感操作的代码都来自这个库。开发者可以用AI辅助开发，但关键部分必须使用经过验证的模板。</p><p>这不是完美方案，但至少能保证基础安全。</p><h3 id="3-重新设计审查流程"><a href="#3-重新设计审查流程" class="headerlink" title="3. 重新设计审查流程"></a>3. 重新设计审查流程</h3><p>传统的pull request审查可能不再适用于AI时代。</p><p>一些团队在尝试新的流程：</p><ul><li>对AI生成的代码进行分级：关键路径的代码必须人工深度审查</li><li>引入”安全审查者”角色，专门负责检查AI生成代码的安全问题</li><li>使用差异化审查：AI生成的代码和人写的代码采用不同的审查标准</li></ul><p>这些实验还在进行中，但方向是对的。</p><h3 id="4-工具链的升级"><a href="#4-工具链的升级" class="headerlink" title="4. 工具链的升级"></a>4. 工具链的升级</h3><p>我们需要新一代的安全工具，专门针对AI生成代码的特点。</p><p>有些有意思的尝试：</p><ul><li>语义分析工具：不只是看语法，还要理解代码的意图</li><li>异常模式检测：标记那些”看起来太完美”的代码</li><li>AI对抗AI：用AI来审查AI生成的代码</li></ul><p>最后一个听起来有点讽刺，但可能是最有效的。毕竟，AI最了解AI会犯什么错误。</p><h2 id="责任边界在哪里"><a href="#责任边界在哪里" class="headerlink" title="责任边界在哪里"></a>责任边界在哪里</h2><p>这是个更难的问题。</p><p>AI生成的代码出了安全问题，谁负责？</p><ul><li>开发者说：我只是用了工具，工具生成的代码我怎么知道有问题？</li><li>AI提供商说：我们的服务条款写了，生成的代码需要人工审查。</li><li>公司说：我们信任开发者的专业判断。</li></ul><p>结果就是，没人真正负责。</p><p>这种责任模糊会带来灾难性后果。我们需要建立明确的规则：</p><ul><li>使用AI生成代码的开发者，有义务理解和审查生成的代码</li><li>AI提供商需要对已知的安全问题提供警告</li><li>组织需要建立清晰的AI代码使用规范</li></ul><p>法律和监管可能会介入，但在那之前，行业需要自律。</p><h2 id="一些可行的建议"><a href="#一些可行的建议" class="headerlink" title="一些可行的建议"></a>一些可行的建议</h2><p>对个人开发者：</p><ol><li>永远不要直接复制粘贴AI生成的代码，至少要理解它在做什么</li><li>对涉及安全的代码保持怀疑，手动检查关键逻辑</li><li>学习基本的安全知识，AI不能替代你的判断</li></ol><p>对团队：</p><ol><li>制定AI代码使用规范，明确哪些场景可以用，哪些不能用</li><li>投资安全培训，确保团队理解AI代码的风险</li><li>建立分层审查机制，关键代码必须经过安全专家审查</li></ol><p>对开源项目：</p><ol><li>在README里说明项目中哪些部分使用了AI辅助开发</li><li>对AI生成的代码进行额外的安全审查</li><li>建立漏洞披露机制，鼓励安全研究者参与</li></ol><h2 id="这不是危言耸听"><a href="#这不是危言耸听" class="headerlink" title="这不是危言耸听"></a>这不是危言耸听</h2><p>我不是在反对AI辅助开发。恰恰相反，我认为AI会成为开发的标配工具。</p><p>但我们必须正视一个事实：<strong>生产力的爆炸式增长，必须伴随着安全能力的同步提升</strong>。</p><p>问题不在于AI会不会生成有漏洞的代码——它肯定会。问题在于，我们是否建立了足够的机制来识别和修复这些漏洞。</p><p>现在的情况是：代码生成速度提升了10倍，但安全审查的速度还是原来那样。这个gap每天都在扩大。</p><p>如果不尽快补上这个缺口，我们可能会迎来一场开源安全危机。不是因为AI恶意，而是因为我们的安全机制跟不上生产力的爆炸。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>技术进步总是双刃剑。蒸汽机带来了工业革命，也带来了环境污染。互联网连接了世界，也创造了新的犯罪空间。</p><p>AI极大提升了开发效率，同时也放大了安全风险。这是我们必须面对的现实。</p><p>好消息是，我们还有时间。开源社区一直善于自我纠错和进化。只要我们认识到问题的严重性，建立起适应AI时代的安全机制，这场生产力爆炸最终会是积极的。</p><p>但时间窗口不会一直开着。现在就是行动的时候。</p><hr><p><em>你的项目里有多少代码是AI生成的？你审查过它们吗？</em></p><p><em>这不是质疑，而是提醒。包括我自己。</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/ai-opensource-security/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/ai-opensource-security/"/>
    <published>2026-03-02T09:28:00.000Z</published>
    <summary>AI让代码生成速度提升了10倍，但安全审查的速度还是那么慢。这场不对等的竞赛，正在重塑整个开源生态的安全基础。</summary>
    <title>AI导致开源生产率爆炸，安全如何保障？</title>
    <updated>2026-03-02T09:28:00.000Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <category term="AI编程" scheme="https://xiaoxiaduoyan.com/tags/AI%E7%BC%96%E7%A8%8B/"/>
    <category term="软件开发" scheme="https://xiaoxiaduoyan.com/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"/>
    <category term="代码质量" scheme="https://xiaoxiaduoyan.com/tags/%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F/"/>
    <content>
      <![CDATA[<h1 id="AI-Coding-的绊脚石之一：程序的隐式契约问题"><a href="#AI-Coding-的绊脚石之一：程序的隐式契约问题" class="headerlink" title="AI Coding 的绊脚石之一：程序的隐式契约问题"></a>AI Coding 的绊脚石之一：程序的隐式契约问题</h1><p><img src="https://images.unsplash.com/photo-1555949963-aa79dcee981c?ixlib=rb-4.0.3&auto=format&fit=crop&w=1200&q=80" alt="隐式契约示意图"></p><h2 id="引言：当AI遇到”不言而喻”的规则"><a href="#引言：当AI遇到”不言而喻”的规则" class="headerlink" title="引言：当AI遇到”不言而喻”的规则"></a>引言：当AI遇到”不言而喻”的规则</h2><p>最近在尝试用AI助手编写代码时，我发现了一个有趣的现象：有些代码看起来完美无缺，逻辑清晰，语法正确，但就是无法正常工作。经过深入分析，我发现问题的根源往往不在于代码本身，而在于那些<strong>从未被明确写出，却对程序运行至关重要的隐式契约</strong>。</p><p>这些隐式契约就像是软件开发中的”潜规则”——人类开发者通过经验和上下文理解它们，但AI却常常在这些规则面前碰壁。</p><h2 id="什么是隐式契约？"><a href="#什么是隐式契约？" class="headerlink" title="什么是隐式契约？"></a>什么是隐式契约？</h2><p>隐式契约（Implicit Contract）指的是那些没有被明确写在代码或文档中，但对程序正确运行至关重要的假设、约定和期望。它们通常包括：</p><ol><li><strong>性能期望</strong>：函数应该在多长时间内完成</li><li><strong>资源使用</strong>：函数会消耗多少内存、CPU或网络带宽</li><li><strong>副作用</strong>：函数会修改哪些外部状态</li><li><strong>错误处理</strong>：在什么情况下函数应该抛出异常，什么情况下应该静默处理</li><li><strong>并发安全</strong>：函数是否可以在多线程环境下安全调用</li></ol><h2 id="实例分析：AI编程中的隐式契约陷阱"><a href="#实例分析：AI编程中的隐式契约陷阱" class="headerlink" title="实例分析：AI编程中的隐式契约陷阱"></a>实例分析：AI编程中的隐式契约陷阱</h2><h3 id="案例一：文件读取的”合理”超时"><a href="#案例一：文件读取的”合理”超时" class="headerlink" title="案例一：文件读取的”合理”超时"></a>案例一：文件读取的”合理”超时</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AI生成的代码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_large_file</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">return</span> f.read()</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：这段代码对于小文件工作正常，但对于10GB的大文件，它会耗尽内存并导致程序崩溃。人类开发者会意识到需要分块读取或使用流式处理，但AI只看到了”读取文件”这个明确需求。</p><p><strong>隐式契约</strong>：读取操作应该在合理时间内完成，且不会耗尽系统资源。</p><h3 id="案例二：API调用的”礼貌”重试"><a href="#案例二：API调用的”礼貌”重试" class="headerlink" title="案例二：API调用的”礼貌”重试"></a>案例二：API调用的”礼貌”重试</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AI生成的API调用代码</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">fetchUserData</span>(<span class="params">userId</span>) &#123;</span><br><span class="line">    <span class="keyword">const</span> response = <span class="keyword">await</span> <span class="title function_">fetch</span>(<span class="string">`/api/users/<span class="subst">$&#123;userId&#125;</span>`</span>);</span><br><span class="line">    <span class="keyword">return</span> response.<span class="title function_">json</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：网络请求可能失败，但代码没有重试机制。人类开发者知道网络是不可靠的，通常会添加重试逻辑、超时处理和错误回退。</p><p><strong>隐式契约</strong>：网络操作应该具有弹性，能够处理临时故障。</p><h3 id="案例三：缓存更新的”一致性”保证"><a href="#案例三：缓存更新的”一致性”保证" class="headerlink" title="案例三：缓存更新的”一致性”保证"></a>案例三：缓存更新的”一致性”保证</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AI生成的缓存更新代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">updateUserCache</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    cache.put(user.getId(), user);</span><br><span class="line">    database.update(user);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：如果数据库更新失败，缓存中已经存储了不一致的数据。人类开发者会使用事务或两阶段提交来保证一致性。</p><p><strong>隐式契约</strong>：数据更新操作应该保持系统状态的一致性。</p><h2 id="隐式契约的根源：为什么它们如此普遍？"><a href="#隐式契约的根源：为什么它们如此普遍？" class="headerlink" title="隐式契约的根源：为什么它们如此普遍？"></a>隐式契约的根源：为什么它们如此普遍？</h2><h3 id="1-历史遗留与约定俗成"><a href="#1-历史遗留与约定俗成" class="headerlink" title="1. 历史遗留与约定俗成"></a>1. 历史遗留与约定俗成</h3><p>许多隐式契约源于历史原因。比如，Unix命令行工具遵循”安静成功，详细失败”的原则——这个原则从未在man page中明确写出，但所有有经验的开发者都知道。</p><h3 id="2-性能与简洁性的权衡"><a href="#2-性能与简洁性的权衡" class="headerlink" title="2. 性能与简洁性的权衡"></a>2. 性能与简洁性的权衡</h3><p>明确写出所有契约会使代码变得冗长。例如，每个函数都加上性能保证注释是不现实的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果每个函数都这样写...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_data</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    处理数据。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    性能契约：</span></span><br><span class="line"><span class="string">    - 时间复杂度：O(n log n)</span></span><br><span class="line"><span class="string">    - 空间复杂度：O(n)</span></span><br><span class="line"><span class="string">    - 最大输入大小：10,000条记录</span></span><br><span class="line"><span class="string">    - 预期执行时间：&lt; 2秒（在标准硬件上）</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    副作用契约：</span></span><br><span class="line"><span class="string">    - 不会修改输入数据</span></span><br><span class="line"><span class="string">    - 会写入日志文件</span></span><br><span class="line"><span class="string">    - 可能向监控系统发送指标</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    错误契约：</span></span><br><span class="line"><span class="string">    - 输入为空时返回空列表</span></span><br><span class="line"><span class="string">    - 数据格式错误时抛出ValueError</span></span><br><span class="line"><span class="string">    - 内存不足时抛出MemoryError</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 实际实现...</span></span><br></pre></td></tr></table></figure><h3 id="3-领域知识的缺失"><a href="#3-领域知识的缺失" class="headerlink" title="3. 领域知识的缺失"></a>3. 领域知识的缺失</h3><p>AI缺乏特定领域的专业知识。医疗软件、金融系统、航空航天控制等领域都有大量的领域特定隐式契约，这些知识通常通过多年经验积累。</p><h3 id="4-上下文依赖"><a href="#4-上下文依赖" class="headerlink" title="4. 上下文依赖"></a>4. 上下文依赖</h3><p>许多契约依赖于具体的使用场景。同一个函数在批处理系统和实时系统中可能有完全不同的性能期望。</p><h2 id="隐式契约带来的具体问题"><a href="#隐式契约带来的具体问题" class="headerlink" title="隐式契约带来的具体问题"></a>隐式契约带来的具体问题</h2><h3 id="1-调试困难"><a href="#1-调试困难" class="headerlink" title="1. 调试困难"></a>1. 调试困难</h3><p>当违反隐式契约时，错误信息往往不明确。程序可能只是”运行缓慢”或”偶尔崩溃”，而不是抛出清晰的异常。</p><h3 id="2-集成问题"><a href="#2-集成问题" class="headerlink" title="2. 集成问题"></a>2. 集成问题</h3><p>不同团队或不同系统对同一概念可能有不同的隐式契约，导致集成时出现微妙的不兼容。</p><h3 id="3-技术债务积累"><a href="#3-技术债务积累" class="headerlink" title="3. 技术债务积累"></a>3. 技术债务积累</h3><p>随着时间的推移，未被文档化的隐式契约会变成”部落知识”——只有少数老员工知道，新员工和AI助手都会反复踩坑。</p><h3 id="4-阻碍自动化"><a href="#4-阻碍自动化" class="headerlink" title="4. 阻碍自动化"></a>4. 阻碍自动化</h3><p>隐式契约是自动化测试、静态分析和AI代码生成的重大障碍。如果规则不明确，机器就无法可靠地验证或生成代码。</p><h2 id="解决方案：让隐式契约显式化"><a href="#解决方案：让隐式契约显式化" class="headerlink" title="解决方案：让隐式契约显式化"></a>解决方案：让隐式契约显式化</h2><h3 id="1-契约优先设计（Contract-First-Design）"><a href="#1-契约优先设计（Contract-First-Design）" class="headerlink" title="1. 契约优先设计（Contract-First Design）"></a>1. 契约优先设计（Contract-First Design）</h3><p>在编写实现之前，先明确写出函数的契约。这可以通过多种形式实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Protocol</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PerformanceContract</span>:</span><br><span class="line">    max_time_ms: <span class="built_in">int</span></span><br><span class="line">    max_memory_mb: <span class="built_in">int</span></span><br><span class="line">    thread_safe: <span class="built_in">bool</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataProcessor</span>(<span class="title class_ inherited__">Protocol</span>):</span><br><span class="line">    performance: PerformanceContract</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self, data: <span class="built_in">list</span></span>) -&gt; <span class="built_in">list</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        契约：</span></span><br><span class="line"><span class="string">        1. 不会修改输入数据</span></span><br><span class="line"><span class="string">        2. 时间复杂度 O(n log n)</span></span><br><span class="line"><span class="string">        3. 空输入返回空列表</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><h3 id="2-使用契约编程框架"><a href="#2-使用契约编程框架" class="headerlink" title="2. 使用契约编程框架"></a>2. 使用契约编程框架</h3><p>利用现有的契约编程工具，如Python的<code>icontract</code>、Java的<code>Contracts for Java</code>或Eiffel语言内置的契约支持：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> icontract</span><br><span class="line"></span><br><span class="line"><span class="meta">@icontract.require(<span class="params"><span class="keyword">lambda</span> x: x &gt; <span class="number">0</span>, <span class="string">&quot;输入必须为正数&quot;</span></span>)</span></span><br><span class="line"><span class="meta">@icontract.ensure(<span class="params"><span class="keyword">lambda</span> result: result &gt; <span class="number">0</span>, <span class="string">&quot;结果必须为正数&quot;</span></span>)</span></span><br><span class="line"><span class="meta">@icontract.snapshot(<span class="params"><span class="keyword">lambda</span> x: x, <span class="string">&quot;保存原始值&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_square_root</span>(<span class="params">x: <span class="built_in">float</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="comment"># 实现必须满足前后条件</span></span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">0.5</span></span><br></pre></td></tr></table></figure><h3 id="3-增强的API文档"><a href="#3-增强的API文档" class="headerlink" title="3. 增强的API文档"></a>3. 增强的API文档</h3><p>在文档中明确列出所有隐式契约。可以使用标准化的模板：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## 性能特征</span></span><br><span class="line"><span class="bullet">-</span> <span class="strong">**时间复杂度**</span>：O(n)</span><br><span class="line"><span class="bullet">-</span> <span class="strong">**空间复杂度**</span>：O(1)</span><br><span class="line"><span class="bullet">-</span> <span class="strong">**线程安全**</span>：是</span><br><span class="line"></span><br><span class="line"><span class="section">## 副作用</span></span><br><span class="line"><span class="bullet">-</span> 会修改全局配置</span><br><span class="line"><span class="bullet">-</span> 会写入日志文件</span><br><span class="line"></span><br><span class="line"><span class="section">## 错误处理</span></span><br><span class="line"><span class="bullet">-</span> 输入无效时抛出<span class="code">`ValueError`</span></span><br><span class="line"><span class="bullet">-</span> 资源不足时抛出<span class="code">`RuntimeError`</span></span><br></pre></td></tr></table></figure><h3 id="4-运行时契约检查"><a href="#4-运行时契约检查" class="headerlink" title="4. 运行时契约检查"></a>4. 运行时契约检查</h3><p>在开发和测试环境中启用契约检查，在生产环境中关闭以提高性能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ContractAwareProcessor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, debug=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.debug = debug</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.debug:</span><br><span class="line">            <span class="variable language_">self</span>._check_preconditions(data)</span><br><span class="line">        </span><br><span class="line">        result = <span class="variable language_">self</span>._actual_process(data)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.debug:</span><br><span class="line">            <span class="variable language_">self</span>._check_postconditions(data, result)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="5-AI友好的代码注解"><a href="#5-AI友好的代码注解" class="headerlink" title="5. AI友好的代码注解"></a>5. AI友好的代码注解</h3><p>为AI助手提供专门的注解，帮助它们理解隐式契约：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @ai-contract: 这个函数用于处理用户输入，对性能敏感</span></span><br><span class="line"><span class="comment"># @ai-expectation: 应该在100ms内完成</span></span><br><span class="line"><span class="comment"># @ai-side-effect: 会更新数据库中的用户状态</span></span><br><span class="line"><span class="comment"># @ai-error-case: 网络超时时重试3次</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_user_request</span>(<span class="params">request</span>):</span><br><span class="line">    <span class="comment"># 实现...</span></span><br></pre></td></tr></table></figure><h2 id="面向未来的思考"><a href="#面向未来的思考" class="headerlink" title="面向未来的思考"></a>面向未来的思考</h2><h3 id="1-契约作为一等公民"><a href="#1-契约作为一等公民" class="headerlink" title="1. 契约作为一等公民"></a>1. 契约作为一等公民</h3><p>未来的编程语言可能会将契约作为语言的一等公民，就像类型系统一样。编译器可以静态检查契约，IDE可以提供更好的支持。</p><h3 id="2-AI可理解的契约语言"><a href="#2-AI可理解的契约语言" class="headerlink" title="2. AI可理解的契约语言"></a>2. AI可理解的契约语言</h3><p>我们需要开发一种既对人类友好，又对AI可解析的契约描述语言。这种语言应该能够表达复杂的约束和期望。</p><h3 id="3-契约学习与推理"><a href="#3-契约学习与推理" class="headerlink" title="3. 契约学习与推理"></a>3. 契约学习与推理</h3><p>AI系统可以通过分析大量代码库，自动学习和推断常见的隐式契约，并建议将它们显式化。</p><h3 id="4-契约驱动的代码生成"><a href="#4-契约驱动的代码生成" class="headerlink" title="4. 契约驱动的代码生成"></a>4. 契约驱动的代码生成</h3><p>未来的AI代码生成器可以以契约为输入，生成满足所有约束的代码实现。</p><h2 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h2><h3 id="给开发者的建议："><a href="#给开发者的建议：" class="headerlink" title="给开发者的建议："></a>给开发者的建议：</h3><ol><li><strong>识别关键契约</strong>：在代码审查时，特别关注那些可能包含隐式契约的函数</li><li><strong>逐步显式化</strong>：不要试图一次性文档化所有契约，从最关键的开始</li><li><strong>建立契约文化</strong>：在团队中推广契约优先的思维方式</li><li><strong>利用工具</strong>：使用静态分析工具检测可能的契约违反</li></ol><h3 id="给AI提示工程师的建议："><a href="#给AI提示工程师的建议：" class="headerlink" title="给AI提示工程师的建议："></a>给AI提示工程师的建议：</h3><ol><li><strong>明确表达期望</strong>：在提示中不仅说明”做什么”，还要说明”在什么约束下做”</li><li><strong>提供上下文</strong>：告诉AI代码将运行在什么环境中，有什么性能要求</li><li><strong>要求契约注释</strong>：让AI生成的代码包含明确的契约注释</li><li><strong>测试边界条件</strong>：特别测试那些可能违反隐式契约的边缘情况</li></ol><h2 id="结语：从隐式到显式的进化"><a href="#结语：从隐式到显式的进化" class="headerlink" title="结语：从隐式到显式的进化"></a>结语：从隐式到显式的进化</h2><p>隐式契约问题是AI编程成熟过程中的必经阶段。正如软件工程从”写代码”进化到”设计系统”，从”能运行”进化到”可维护”，我们现在正经历从”隐式理解”到”显式表达”的进化。</p><p>解决隐式契约问题不仅是让AI更好地编程，更是让所有软件更加可靠、可维护、可理解。在这个过程中，我们不仅教会了AI如何编程，也教会了自己如何更好地表达意图、管理复杂性和构建健壮的系统。</p><p>最终，显式的契约会成为连接人类意图、机器理解和代码实现的重要桥梁。当这座桥梁建成时，AI编程才能真正从”辅助工具”进化为”可靠伙伴”。</p><hr><p><strong>思考题</strong>：在你的项目中，有哪些重要的隐式契约？如果让AI来维护你的代码，哪些契约最需要被显式化？</p><p><strong>延伸阅读</strong>：</p><ol><li>《设计模式：可复用面向对象软件的基础》- 模式本身就是一种高级契约</li><li>《代码大全》- 关于软件构建的全面指南</li><li>《重构：改善既有代码的设计》- 如何安全地修改代码而不违反契约</li></ol>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/ai-coding-implicit-contracts/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/ai-coding-implicit-contracts/"/>
    <published>2026-03-02T06:00:00.000Z</published>
    <summary>深入探讨AI编程中遇到的隐式契约问题，通过多个实例分析其根源，并提出可行的解决方案。</summary>
    <title>AI Coding 的绊脚石之一：程序的隐式契约问题</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="English" scheme="https://xiaoxiaduoyan.com/tags/English/"/>
    <category term="AI Programming" scheme="https://xiaoxiaduoyan.com/tags/AI-Programming/"/>
    <category term="Software Development" scheme="https://xiaoxiaduoyan.com/tags/Software-Development/"/>
    <category term="Code Quality" scheme="https://xiaoxiaduoyan.com/tags/Code-Quality/"/>
    <content>
      <![CDATA[<h1 id="One-of-AI-Coding’s-Stumbling-Blocks-The-Problem-of-Implicit-Contracts-in-Programs"><a href="#One-of-AI-Coding’s-Stumbling-Blocks-The-Problem-of-Implicit-Contracts-in-Programs" class="headerlink" title="One of AI Coding’s Stumbling Blocks: The Problem of Implicit Contracts in Programs"></a>One of AI Coding’s Stumbling Blocks: The Problem of Implicit Contracts in Programs</h1><p><img src="https://images.unsplash.com/photo-1555949963-aa79dcee981c?ixlib=rb-4.0.3&auto=format&fit=crop&w=1200&q=80" alt="Implicit Contracts Illustration"></p><h2 id="Introduction-When-AI-Meets-“Unspoken”-Rules"><a href="#Introduction-When-AI-Meets-“Unspoken”-Rules" class="headerlink" title="Introduction: When AI Meets “Unspoken” Rules"></a>Introduction: When AI Meets “Unspoken” Rules</h2><p>Recently, while experimenting with AI assistants for code generation, I’ve noticed an interesting phenomenon: some code looks perfect—clear logic, correct syntax—but simply doesn’t work as expected. Upon deeper analysis, I found that the root cause often lies not in the code itself, but in those <strong>implicit contracts that are never explicitly written down yet are crucial for program execution</strong>.</p><p>These implicit contracts are like the “unwritten rules” of software development—human developers understand them through experience and context, but AI often stumbles when encountering these rules.</p><h2 id="What-Are-Implicit-Contracts"><a href="#What-Are-Implicit-Contracts" class="headerlink" title="What Are Implicit Contracts?"></a>What Are Implicit Contracts?</h2><p>Implicit contracts refer to assumptions, conventions, and expectations that are not explicitly stated in code or documentation but are essential for correct program operation. They typically include:</p><ol><li><strong>Performance expectations</strong>: How long a function should take to complete</li><li><strong>Resource usage</strong>: How much memory, CPU, or network bandwidth a function will consume</li><li><strong>Side effects</strong>: Which external states a function will modify</li><li><strong>Error handling</strong>: Under what conditions a function should throw exceptions vs. handle silently</li><li><strong>Concurrency safety</strong>: Whether a function can be safely called in a multithreaded environment</li></ol><h2 id="Case-Studies-Implicit-Contract-Traps-in-AI-Programming"><a href="#Case-Studies-Implicit-Contract-Traps-in-AI-Programming" class="headerlink" title="Case Studies: Implicit Contract Traps in AI Programming"></a>Case Studies: Implicit Contract Traps in AI Programming</h2><h3 id="Case-1-The-“Reasonable”-Timeout-for-File-Reading"><a href="#Case-1-The-“Reasonable”-Timeout-for-File-Reading" class="headerlink" title="Case 1: The “Reasonable” Timeout for File Reading"></a>Case 1: The “Reasonable” Timeout for File Reading</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AI-generated code</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_large_file</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">return</span> f.read()</span><br></pre></td></tr></table></figure><p><strong>Problem</strong>: This code works fine for small files, but for a 10GB file, it will exhaust memory and crash the program. Human developers would realize the need for chunked reading or streaming, but AI only sees the explicit requirement to “read a file.”</p><p><strong>Implicit contract</strong>: Read operations should complete within a reasonable time and not exhaust system resources.</p><h3 id="Case-2-The-“Polite”-Retry-for-API-Calls"><a href="#Case-2-The-“Polite”-Retry-for-API-Calls" class="headerlink" title="Case 2: The “Polite” Retry for API Calls"></a>Case 2: The “Polite” Retry for API Calls</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AI-generated API call code</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">fetchUserData</span>(<span class="params">userId</span>) &#123;</span><br><span class="line">    <span class="keyword">const</span> response = <span class="keyword">await</span> <span class="title function_">fetch</span>(<span class="string">`/api/users/<span class="subst">$&#123;userId&#125;</span>`</span>);</span><br><span class="line">    <span class="keyword">return</span> response.<span class="title function_">json</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Problem</strong>: Network requests can fail, but the code has no retry mechanism. Human developers know networks are unreliable and typically add retry logic, timeout handling, and error fallbacks.</p><p><strong>Implicit contract</strong>: Network operations should be resilient and handle temporary failures.</p><h3 id="Case-3-The-“Consistency”-Guarantee-for-Cache-Updates"><a href="#Case-3-The-“Consistency”-Guarantee-for-Cache-Updates" class="headerlink" title="Case 3: The “Consistency” Guarantee for Cache Updates"></a>Case 3: The “Consistency” Guarantee for Cache Updates</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AI-generated cache update code</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">updateUserCache</span><span class="params">(User user)</span> &#123;</span><br><span class="line">    cache.put(user.getId(), user);</span><br><span class="line">    database.update(user);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Problem</strong>: If the database update fails, the cache already contains inconsistent data. Human developers would use transactions or two-phase commits to ensure consistency.</p><p><strong>Implicit contract</strong>: Data update operations should maintain system state consistency.</p><h2 id="The-Roots-of-Implicit-Contracts-Why-Are-They-So-Prevalent"><a href="#The-Roots-of-Implicit-Contracts-Why-Are-They-So-Prevalent" class="headerlink" title="The Roots of Implicit Contracts: Why Are They So Prevalent?"></a>The Roots of Implicit Contracts: Why Are They So Prevalent?</h2><h3 id="1-Historical-Legacy-and-Established-Conventions"><a href="#1-Historical-Legacy-and-Established-Conventions" class="headerlink" title="1. Historical Legacy and Established Conventions"></a>1. Historical Legacy and Established Conventions</h3><p>Many implicit contracts originate from historical reasons. For example, Unix command-line tools follow the principle of “silent success, verbose failure”—a principle never explicitly stated in man pages but known to all experienced developers.</p><h3 id="2-Trade-offs-Between-Performance-and-Conciseness"><a href="#2-Trade-offs-Between-Performance-and-Conciseness" class="headerlink" title="2. Trade-offs Between Performance and Conciseness"></a>2. Trade-offs Between Performance and Conciseness</h3><p>Explicitly writing all contracts would make code verbose. For instance, adding performance guarantee comments to every function is impractical:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If every function were written like this...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_data</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Process data.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Performance contract:</span></span><br><span class="line"><span class="string">    - Time complexity: O(n log n)</span></span><br><span class="line"><span class="string">    - Space complexity: O(n)</span></span><br><span class="line"><span class="string">    - Maximum input size: 10,000 records</span></span><br><span class="line"><span class="string">    - Expected execution time: &lt; 2 seconds (on standard hardware)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Side effect contract:</span></span><br><span class="line"><span class="string">    - Will not modify input data</span></span><br><span class="line"><span class="string">    - Will write to log file</span></span><br><span class="line"><span class="string">    - May send metrics to monitoring system</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Error contract:</span></span><br><span class="line"><span class="string">    - Returns empty list for empty input</span></span><br><span class="line"><span class="string">    - Raises ValueError for malformed data</span></span><br><span class="line"><span class="string">    - Raises MemoryError for insufficient memory</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Actual implementation...</span></span><br></pre></td></tr></table></figure><h3 id="3-Lack-of-Domain-Knowledge"><a href="#3-Lack-of-Domain-Knowledge" class="headerlink" title="3. Lack of Domain Knowledge"></a>3. Lack of Domain Knowledge</h3><p>AI lacks domain-specific expertise. Fields like medical software, financial systems, and aerospace controls have numerous domain-specific implicit contracts typically accumulated through years of experience.</p><h3 id="4-Context-Dependence"><a href="#4-Context-Dependence" class="headerlink" title="4. Context Dependence"></a>4. Context Dependence</h3><p>Many contracts depend on specific usage contexts. The same function may have completely different performance expectations in batch processing systems versus real-time systems.</p><h2 id="Specific-Problems-Caused-by-Implicit-Contracts"><a href="#Specific-Problems-Caused-by-Implicit-Contracts" class="headerlink" title="Specific Problems Caused by Implicit Contracts"></a>Specific Problems Caused by Implicit Contracts</h2><h3 id="1-Difficult-Debugging"><a href="#1-Difficult-Debugging" class="headerlink" title="1. Difficult Debugging"></a>1. Difficult Debugging</h3><p>When implicit contracts are violated, error messages are often unclear. Programs may simply “run slowly” or “crash occasionally” rather than throwing clear exceptions.</p><h3 id="2-Integration-Issues"><a href="#2-Integration-Issues" class="headerlink" title="2. Integration Issues"></a>2. Integration Issues</h3><p>Different teams or systems may have different implicit contracts for the same concept, leading to subtle incompatibilities during integration.</p><h3 id="3-Accumulation-of-Technical-Debt"><a href="#3-Accumulation-of-Technical-Debt" class="headerlink" title="3. Accumulation of Technical Debt"></a>3. Accumulation of Technical Debt</h3><p>Over time, undocumented implicit contracts become “tribal knowledge”—known only to a few senior employees, while new hires and AI assistants repeatedly encounter the same pitfalls.</p><h3 id="4-Hindrance-to-Automation"><a href="#4-Hindrance-to-Automation" class="headerlink" title="4. Hindrance to Automation"></a>4. Hindrance to Automation</h3><p>Implicit contracts are significant obstacles to automated testing, static analysis, and AI code generation. If rules aren’t explicit, machines cannot reliably verify or generate code.</p><h2 id="Solutions-Making-Implicit-Contracts-Explicit"><a href="#Solutions-Making-Implicit-Contracts-Explicit" class="headerlink" title="Solutions: Making Implicit Contracts Explicit"></a>Solutions: Making Implicit Contracts Explicit</h2><h3 id="1-Contract-First-Design"><a href="#1-Contract-First-Design" class="headerlink" title="1. Contract-First Design"></a>1. Contract-First Design</h3><p>Define function contracts explicitly before writing implementations. This can be achieved in various forms:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Protocol</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PerformanceContract</span>:</span><br><span class="line">    max_time_ms: <span class="built_in">int</span></span><br><span class="line">    max_memory_mb: <span class="built_in">int</span></span><br><span class="line">    thread_safe: <span class="built_in">bool</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataProcessor</span>(<span class="title class_ inherited__">Protocol</span>):</span><br><span class="line">    performance: PerformanceContract</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self, data: <span class="built_in">list</span></span>) -&gt; <span class="built_in">list</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Contract:</span></span><br><span class="line"><span class="string">        1. Will not modify input data</span></span><br><span class="line"><span class="string">        2. Time complexity O(n log n)</span></span><br><span class="line"><span class="string">        3. Returns empty list for empty input</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><h3 id="2-Using-Contract-Programming-Frameworks"><a href="#2-Using-Contract-Programming-Frameworks" class="headerlink" title="2. Using Contract Programming Frameworks"></a>2. Using Contract Programming Frameworks</h3><p>Leverage existing contract programming tools like Python’s <code>icontract</code>, Java’s <code>Contracts for Java</code>, or Eiffel’s built-in contract support:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> icontract</span><br><span class="line"></span><br><span class="line"><span class="meta">@icontract.require(<span class="params"><span class="keyword">lambda</span> x: x &gt; <span class="number">0</span>, <span class="string">&quot;Input must be positive&quot;</span></span>)</span></span><br><span class="line"><span class="meta">@icontract.ensure(<span class="params"><span class="keyword">lambda</span> result: result &gt; <span class="number">0</span>, <span class="string">&quot;Result must be positive&quot;</span></span>)</span></span><br><span class="line"><span class="meta">@icontract.snapshot(<span class="params"><span class="keyword">lambda</span> x: x, <span class="string">&quot;Save original value&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_square_root</span>(<span class="params">x: <span class="built_in">float</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="comment"># Implementation must satisfy pre- and post-conditions</span></span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">0.5</span></span><br></pre></td></tr></table></figure><h3 id="3-Enhanced-API-Documentation"><a href="#3-Enhanced-API-Documentation" class="headerlink" title="3. Enhanced API Documentation"></a>3. Enhanced API Documentation</h3><p>Explicitly list all implicit contracts in documentation using standardized templates:</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## Performance Characteristics</span></span><br><span class="line"><span class="bullet">-</span> <span class="strong">**Time complexity**</span>: O(n)</span><br><span class="line"><span class="bullet">-</span> <span class="strong">**Space complexity**</span>: O(1)</span><br><span class="line"><span class="bullet">-</span> <span class="strong">**Thread safety**</span>: Yes</span><br><span class="line"></span><br><span class="line"><span class="section">## Side Effects</span></span><br><span class="line"><span class="bullet">-</span> Modifies global configuration</span><br><span class="line"><span class="bullet">-</span> Writes to log file</span><br><span class="line"></span><br><span class="line"><span class="section">## Error Handling</span></span><br><span class="line"><span class="bullet">-</span> Raises <span class="code">`ValueError`</span> for invalid input</span><br><span class="line"><span class="bullet">-</span> Raises <span class="code">`RuntimeError`</span> for insufficient resources</span><br></pre></td></tr></table></figure><h3 id="4-Runtime-Contract-Checking"><a href="#4-Runtime-Contract-Checking" class="headerlink" title="4. Runtime Contract Checking"></a>4. Runtime Contract Checking</h3><p>Enable contract checking in development and testing environments, disable in production for performance:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ContractAwareProcessor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, debug=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.debug = debug</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.debug:</span><br><span class="line">            <span class="variable language_">self</span>._check_preconditions(data)</span><br><span class="line">        </span><br><span class="line">        result = <span class="variable language_">self</span>._actual_process(data)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.debug:</span><br><span class="line">            <span class="variable language_">self</span>._check_postconditions(data, result)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="5-AI-Friendly-Code-Annotations"><a href="#5-AI-Friendly-Code-Annotations" class="headerlink" title="5. AI-Friendly Code Annotations"></a>5. AI-Friendly Code Annotations</h3><p>Provide specialized annotations to help AI assistants understand implicit contracts:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @ai-contract: This function handles user input and is performance-sensitive</span></span><br><span class="line"><span class="comment"># @ai-expectation: Should complete within 100ms</span></span><br><span class="line"><span class="comment"># @ai-side-effect: Will update user status in database</span></span><br><span class="line"><span class="comment"># @ai-error-case: Retry 3 times on network timeout</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_user_request</span>(<span class="params">request</span>):</span><br><span class="line">    <span class="comment"># Implementation...</span></span><br></pre></td></tr></table></figure><h2 id="Future-Oriented-Thinking"><a href="#Future-Oriented-Thinking" class="headerlink" title="Future-Oriented Thinking"></a>Future-Oriented Thinking</h2><h3 id="1-Contracts-as-First-Class-Citizens"><a href="#1-Contracts-as-First-Class-Citizens" class="headerlink" title="1. Contracts as First-Class Citizens"></a>1. Contracts as First-Class Citizens</h3><p>Future programming languages might treat contracts as first-class citizens, similar to type systems. Compilers could statically check contracts, and IDEs could provide better support.</p><h3 id="2-AI-Understandable-Contract-Languages"><a href="#2-AI-Understandable-Contract-Languages" class="headerlink" title="2. AI-Understandable Contract Languages"></a>2. AI-Understandable Contract Languages</h3><p>We need to develop contract description languages that are both human-friendly and AI-parsable, capable of expressing complex constraints and expectations.</p><h3 id="3-Contract-Learning-and-Inference"><a href="#3-Contract-Learning-and-Inference" class="headerlink" title="3. Contract Learning and Inference"></a>3. Contract Learning and Inference</h3><p>AI systems could analyze large codebases to automatically learn and infer common implicit contracts, suggesting their explicit formalization.</p><h3 id="4-Contract-Driven-Code-Generation"><a href="#4-Contract-Driven-Code-Generation" class="headerlink" title="4. Contract-Driven Code Generation"></a>4. Contract-Driven Code Generation</h3><p>Future AI code generators could take contracts as input and generate implementations satisfying all constraints.</p><h2 id="Practical-Recommendations"><a href="#Practical-Recommendations" class="headerlink" title="Practical Recommendations"></a>Practical Recommendations</h2><h3 id="For-Developers"><a href="#For-Developers" class="headerlink" title="For Developers:"></a>For Developers:</h3><ol><li><strong>Identify critical contracts</strong>: During code reviews, pay special attention to functions that may contain implicit contracts</li><li><strong>Gradual explicitization</strong>: Don’t try to document all contracts at once; start with the most critical ones</li><li><strong>Establish a contract culture</strong>: Promote contract-first thinking within your team</li><li><strong>Leverage tools</strong>: Use static analysis tools to detect potential contract violations</li></ol><h3 id="For-AI-Prompt-Engineers"><a href="#For-AI-Prompt-Engineers" class="headerlink" title="For AI Prompt Engineers:"></a>For AI Prompt Engineers:</h3><ol><li><strong>Explicitly express expectations</strong>: In prompts, specify not just “what to do” but also “under what constraints”</li><li><strong>Provide context</strong>: Tell AI about the environment where code will run and performance requirements</li><li><strong>Require contract annotations</strong>: Ask AI-generated code to include explicit contract comments</li><li><strong>Test boundary conditions</strong>: Specifically test edge cases that might violate implicit contracts</li></ol><h2 id="Conclusion-The-Evolution-from-Implicit-to-Explicit"><a href="#Conclusion-The-Evolution-from-Implicit-to-Explicit" class="headerlink" title="Conclusion: The Evolution from Implicit to Explicit"></a>Conclusion: The Evolution from Implicit to Explicit</h2><p>The problem of implicit contracts is an inevitable stage in the maturation of AI programming. Just as software engineering evolved from “writing code” to “designing systems,” from “it runs” to “it’s maintainable,” we’re now experiencing the evolution from “implicit understanding” to “explicit expression.”</p><p>Solving implicit contract problems isn’t just about making AI better at programming—it’s about making all software more reliable, maintainable, and understandable. In this process, we’re not only teaching AI how to program but also teaching ourselves how to better express intent, manage complexity, and build robust systems.</p><p>Ultimately, explicit contracts will become crucial bridges connecting human intent, machine understanding, and code implementation. When these bridges are built, AI programming can truly evolve from “assistant tool” to “reliable partner.”</p><hr><p><strong>Food for thought</strong>: What important implicit contracts exist in your projects? If AI were to maintain your code, which contracts would most need to be made explicit?</p><p><strong>Further reading</strong>:</p><ol><li><em>Design Patterns: Elements of Reusable Object-Oriented Software</em> - Patterns themselves are a form of high-level contracts</li><li><em>Code Complete</em> - A comprehensive guide to software construction</li><li><em>Refactoring: Improving the Design of Existing Code</em> - How to safely modify code without violating contracts</li></ol>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/ai-coding-implicit-contracts-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/ai-coding-implicit-contracts-en/"/>
    <published>2026-03-02T06:00:00.000Z</published>
    <summary>An in-depth exploration of implicit contract problems in AI programming, analyzing their root causes through multiple examples and proposing practical solutions.</summary>
    <title>One of AI Coding's Stumbling Blocks: The Problem of Implicit Contracts in Programs</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="English" scheme="https://xiaoxiaduoyan.com/tags/English/"/>
    <category term="Rust" scheme="https://xiaoxiaduoyan.com/tags/Rust/"/>
    <category term="Programming Languages" scheme="https://xiaoxiaduoyan.com/tags/Programming-Languages/"/>
    <category term="Technology Foresight" scheme="https://xiaoxiaduoyan.com/tags/Technology-Foresight/"/>
    <content>
      <![CDATA[<h2 id="When-AI-Meets-Rust-A-Fateful-Encounter"><a href="#When-AI-Meets-Rust-A-Fateful-Encounter" class="headerlink" title="When AI Meets Rust: A Fateful Encounter?"></a>When AI Meets Rust: A Fateful Encounter?</h2><p>In recent years, the pace of AI development has been dizzying. From large language models to generative AI, from autonomous driving to robotics, AI is permeating every aspect of our lives. Meanwhile, a programming language called Rust has been quietly rising—it has topped Stack Overflow’s “Most Loved Programming Language” survey for eight consecutive years.</p><p>This raises an intriguing question: when the AI wave meets Rust’s rise, what kind of chemical reaction will occur? Could Rust become the best programming language for the AI era?</p><h2 id="Rust’s-Three-Aces"><a href="#Rust’s-Three-Aces" class="headerlink" title="Rust’s Three Aces"></a>Rust’s Three Aces</h2><h3 id="1-Memory-Safety-No-Garbage-Collection-Needed"><a href="#1-Memory-Safety-No-Garbage-Collection-Needed" class="headerlink" title="1. Memory Safety, No Garbage Collection Needed"></a>1. Memory Safety, No Garbage Collection Needed</h3><p>In the AI field, memory management is a headache. Python is simple and easy to use, but the pauses caused by GC (garbage collection) can be fatal in real-time systems. C++ is powerful in performance, but memory safety issues keep developers up at night.</p><p>Rust’s uniqueness lies in: <strong>it guarantees memory safety at compile time</strong>. Through its ownership, borrowing, and lifetime systems, Rust lets you write code that is both safe and efficient, without runtime garbage collection.</p><p>Imagine a memory leak in an autonomous driving system that could lead to catastrophic consequences. Rust’s compile-time checks are like installing a safety door for AI systems.</p><h3 id="2-Fearless-Concurrency-AI’s-Natural-Partner"><a href="#2-Fearless-Concurrency-AI’s-Natural-Partner" class="headerlink" title="2. Fearless Concurrency, AI’s Natural Partner"></a>2. Fearless Concurrency, AI’s Natural Partner</h3><p>AI applications are inherently concurrent. Model training requires distributed computing, inference services need to handle thousands of concurrent requests, and robotic systems must process perception, decision-making, and control across multiple threads simultaneously.</p><p>Rust’s concurrency model is another highlight. It prevents data races through its type system, allowing developers to practice “fearless concurrency.” This means you can confidently write multithreaded code without worrying about those hard-to-debug concurrency bugs.</p><h3 id="3-Performance-Comparable-to-C-C-Ecosystem-Growing-Rapidly"><a href="#3-Performance-Comparable-to-C-C-Ecosystem-Growing-Rapidly" class="headerlink" title="3. Performance Comparable to C&#x2F;C++, Ecosystem Growing Rapidly"></a>3. Performance Comparable to C&#x2F;C++, Ecosystem Growing Rapidly</h3><p>Rust’s performance is comparable to C&#x2F;C++, and in some scenarios, it’s even better. This is crucial for compute-intensive AI applications. More importantly, Rust’s ecosystem is developing rapidly:</p><ul><li><strong>ML Frameworks</strong>: Rust ML frameworks like Burning, Candle, and Linfa are maturing</li><li><strong>Web Frameworks</strong>: Actix, Rocket, and Axum provide high-performance backends for AI services</li><li><strong>Embedded</strong>: Rust has clear advantages in embedded AI (edge computing)</li><li><strong>WASM Support</strong>: Rust is a first-class citizen for WebAssembly, suitable for browser-side AI</li></ul><h2 id="Rust’s-Practical-Applications-in-AI"><a href="#Rust’s-Practical-Applications-in-AI" class="headerlink" title="Rust’s Practical Applications in AI"></a>Rust’s Practical Applications in AI</h2><h3 id="Case-1-Hugging-Face’s-Tokenizers-Library"><a href="#Case-1-Hugging-Face’s-Tokenizers-Library" class="headerlink" title="Case 1: Hugging Face’s Tokenizers Library"></a>Case 1: Hugging Face’s Tokenizers Library</h3><p>Hugging Face is the GitHub of the AI world. Their tokenizers library was originally written in Python and later rewritten in Rust. The result? <strong>Performance improved by 10-100 times</strong>, with significantly reduced memory usage.</p><h3 id="Case-2-Microsoft’s-Windows-AI-Platform"><a href="#Case-2-Microsoft’s-Windows-AI-Platform" class="headerlink" title="Case 2: Microsoft’s Windows AI Platform"></a>Case 2: Microsoft’s Windows AI Platform</h3><p>Microsoft is introducing Rust into the Windows kernel and AI platform. They found that components rewritten in Rust are not only safer but also perform better. In critical paths like AI inference, Rust is becoming the preferred choice.</p><h3 id="Case-3-Autonomous-Driving-Company-Wayve"><a href="#Case-3-Autonomous-Driving-Company-Wayve" class="headerlink" title="Case 3: Autonomous Driving Company Wayve"></a>Case 3: Autonomous Driving Company Wayve</h3><p>This UK-based autonomous driving startup uses Rust extensively. Their CTO stated: “Rust allows us to rapidly iterate complex perception and control systems while maintaining extremely high safety standards.”</p><h2 id="Challenges-and-Obstacles"><a href="#Challenges-and-Obstacles" class="headerlink" title="Challenges and Obstacles"></a>Challenges and Obstacles</h2><p>Of course, Rust also faces challenges in the AI field:</p><h3 id="1-Steep-Learning-Curve"><a href="#1-Steep-Learning-Curve" class="headerlink" title="1. Steep Learning Curve"></a>1. Steep Learning Curve</h3><p>Rust’s ownership system and lifetime concepts take time to master. For AI researchers accustomed to Python, this barrier is not low.</p><h3 id="2-Ecosystem-Still-Immature"><a href="#2-Ecosystem-Still-Immature" class="headerlink" title="2. Ecosystem Still Immature"></a>2. Ecosystem Still Immature</h3><p>Although Rust’s ML ecosystem is developing rapidly, there’s still a significant gap compared to Python’s PyTorch and TensorFlow. Many of the latest AI papers and models still provide Python implementations first.</p><h3 id="3-Community-Culture-Differences"><a href="#3-Community-Culture-Differences" class="headerlink" title="3. Community Culture Differences"></a>3. Community Culture Differences</h3><p>The AI community is known for rapid experimentation and iteration, while the Rust community focuses more on correctness and safety. These two cultures need time to merge.</p><h2 id="Future-Outlook-Rust’s-Role-in-the-AI-Era"><a href="#Future-Outlook-Rust’s-Role-in-the-AI-Era" class="headerlink" title="Future Outlook: Rust’s Role in the AI Era"></a>Future Outlook: Rust’s Role in the AI Era</h2><p>I believe Rust won’t completely replace Python’s position in AI research, but it will shine in the following areas:</p><h3 id="1-Production-Deployment-Transforming-research-models-into-reliable-production-services"><a href="#1-Production-Deployment-Transforming-research-models-into-reliable-production-services" class="headerlink" title="1. Production Deployment: Transforming research models into reliable production services"></a>1. <strong>Production Deployment</strong>: Transforming research models into reliable production services</h3><h3 id="2-Edge-Computing-Running-AI-models-on-resource-constrained-devices"><a href="#2-Edge-Computing-Running-AI-models-on-resource-constrained-devices" class="headerlink" title="2. Edge Computing: Running AI models on resource-constrained devices"></a>2. <strong>Edge Computing</strong>: Running AI models on resource-constrained devices</h3><h3 id="3-Infrastructure-Building-AI-training-and-inference-infrastructure"><a href="#3-Infrastructure-Building-AI-training-and-inference-infrastructure" class="headerlink" title="3. Infrastructure: Building AI training and inference infrastructure"></a>3. <strong>Infrastructure</strong>: Building AI training and inference infrastructure</h3><h3 id="4-Safety-Critical-Systems-Autonomous-driving-medical-AI-and-other-fields-with-extremely-high-safety-requirements"><a href="#4-Safety-Critical-Systems-Autonomous-driving-medical-AI-and-other-fields-with-extremely-high-safety-requirements" class="headerlink" title="4. Safety-Critical Systems: Autonomous driving, medical AI, and other fields with extremely high safety requirements"></a>4. <strong>Safety-Critical Systems</strong>: Autonomous driving, medical AI, and other fields with extremely high safety requirements</h3><h2 id="Advice-for-Developers"><a href="#Advice-for-Developers" class="headerlink" title="Advice for Developers"></a>Advice for Developers</h2><p>If you’re an AI developer, I recommend:</p><ol><li><strong>Don’t Switch Completely</strong>: Continue using Python for research and prototyping, use Rust for production deployment</li><li><strong>Start with Infrastructure</strong>: First rewrite performance bottlenecks or safety-critical components in Rust</li><li><strong>Focus on Hybrid Architecture</strong>: Python handles upper-level logic, Rust handles underlying computation</li><li><strong>Participate in Community Building</strong>: Rust’s AI ecosystem needs more developer contributions</li></ol><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Rust may not be the “only” programming language of the AI era, but it could well be one of the “best” programming languages—especially in scenarios with extremely high requirements for performance, safety, and reliability.</p><p>Just as C defined systems programming, Java defined enterprise applications, and JavaScript defined web development, Rust has the opportunity to define the production-grade code standards for the AI era.</p><p>The future of AI needs not only clever algorithms but also reliable implementations. And Rust was born for reliability.</p><hr><p><strong>Further Reading</strong>:</p><ul><li><a href="https://doc.rust-lang.org/book/">The Rust Programming Language</a></li><li><a href="https://www.arewelearningyet.com/">Rust for AI&#x2F;ML</a></li><li><a href="https://github.com/huggingface/tokenizers">Hugging Face’s Rust tokenizers</a></li></ul><p><strong>Discussion</strong>: What do you think is Rust’s biggest opportunity in the AI field? Feel free to share your thoughts in the comments.</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/rust-ai-language-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/rust-ai-language-en/"/>
    <published>2026-03-02T04:35:00.000Z</published>
    <summary>As AI sweeps across the globe, can Rust become the language of choice for AI development with its unique safety and performance advantages? This article explores Rust's opportunities and challenges in the AI era from multiple perspectives.</summary>
    <title>Will Rust Be the Best Programming Language for the AI Era?</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Rust" scheme="https://xiaoxiaduoyan.com/tags/Rust/"/>
    <category term="编程语言" scheme="https://xiaoxiaduoyan.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    <category term="技术前瞻" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E5%89%8D%E7%9E%BB/"/>
    <content>
      <![CDATA[<h2 id="当-AI-遇上-Rust：一场命中注定的相遇？"><a href="#当-AI-遇上-Rust：一场命中注定的相遇？" class="headerlink" title="当 AI 遇上 Rust：一场命中注定的相遇？"></a>当 AI 遇上 Rust：一场命中注定的相遇？</h2><p>最近几年，AI 的发展速度让人眼花缭乱。从大语言模型到生成式 AI，从自动驾驶到机器人，AI 正在渗透到我们生活的方方面面。与此同时，一门名为 Rust 的编程语言也在悄然崛起——它连续八年蝉联 Stack Overflow “最受开发者喜爱语言”榜首。</p><p>这不禁让人思考：当 AI 的浪潮遇上 Rust 的崛起，会产生怎样的化学反应？Rust 会成为 AI 时代的最佳编程语言吗？</p><h2 id="Rust-的三大王牌"><a href="#Rust-的三大王牌" class="headerlink" title="Rust 的三大王牌"></a>Rust 的三大王牌</h2><h3 id="1-内存安全，无需垃圾回收"><a href="#1-内存安全，无需垃圾回收" class="headerlink" title="1. 内存安全，无需垃圾回收"></a>1. 内存安全，无需垃圾回收</h3><p>在 AI 领域，内存管理是个头疼的问题。Python 虽然简单易用，但 GC（垃圾回收）带来的停顿在实时系统中可能是致命的。C++ 性能强大，但内存安全问题让开发者夜不能寐。</p><p>Rust 的独特之处在于：<strong>它在编译期就保证了内存安全</strong>。通过所有权（ownership）、借用（borrowing）和生命周期（lifetime）系统，Rust 让你写出既安全又高效的代码，而无需运行时垃圾回收。</p><p>想象一下，在自动驾驶系统中，一个内存泄漏可能导致灾难性后果。Rust 的编译期检查，就像是为 AI 系统装上了一道安全门。</p><h3 id="2-无畏并发，AI-的天然伙伴"><a href="#2-无畏并发，AI-的天然伙伴" class="headerlink" title="2. 无畏并发，AI 的天然伙伴"></a>2. 无畏并发，AI 的天然伙伴</h3><p>AI 应用天生就是并发的。模型训练需要分布式计算，推理服务要处理成千上万的并发请求，机器人系统要同时处理感知、决策、控制多个线程。</p><p>Rust 的并发模型是其另一大亮点。它通过类型系统防止数据竞争，让开发者可以”无畏并发”（fearless concurrency）。这意味着你可以放心地编写多线程代码，而不必担心那些难以调试的并发 bug。</p><h3 id="3-性能媲美-C-C-，生态日益完善"><a href="#3-性能媲美-C-C-，生态日益完善" class="headerlink" title="3. 性能媲美 C&#x2F;C++，生态日益完善"></a>3. 性能媲美 C&#x2F;C++，生态日益完善</h3><p>Rust 的性能与 C&#x2F;C++ 相当，在某些场景下甚至更优。这对于计算密集型的 AI 应用至关重要。更重要的是，Rust 的生态系统正在快速发展：</p><ul><li><strong>ML 框架</strong>：Burning、Candle、Linfa 等 Rust ML 框架正在成熟</li><li><strong>Web 框架</strong>：Actix、Rocket、Axum 为 AI 服务提供高性能后端</li><li><strong>嵌入式</strong>：Rust 在嵌入式 AI（边缘计算）领域优势明显</li><li><strong>WASM 支持</strong>：Rust 是 WebAssembly 的一等公民，适合浏览器端 AI</li></ul><h2 id="Rust-在-AI-领域的实际应用"><a href="#Rust-在-AI-领域的实际应用" class="headerlink" title="Rust 在 AI 领域的实际应用"></a>Rust 在 AI 领域的实际应用</h2><h3 id="案例-1：Hugging-Face-的-tokenizers-库"><a href="#案例-1：Hugging-Face-的-tokenizers-库" class="headerlink" title="案例 1：Hugging Face 的 tokenizers 库"></a>案例 1：Hugging Face 的 tokenizers 库</h3><p>Hugging Face 是 AI 界的 GitHub，他们的 tokenizers 库最初用 Python 编写，后来用 Rust 重写。结果？<strong>性能提升了 10-100 倍</strong>，同时内存使用大幅减少。</p><h3 id="案例-2：Microsoft-的-Windows-AI-平台"><a href="#案例-2：Microsoft-的-Windows-AI-平台" class="headerlink" title="案例 2：Microsoft 的 Windows AI 平台"></a>案例 2：Microsoft 的 Windows AI 平台</h3><p>微软正在将 Rust 引入 Windows 内核和 AI 平台。他们发现，用 Rust 重写的组件不仅更安全，而且性能更好。在 AI 推理等关键路径上，Rust 正在成为首选。</p><h3 id="案例-3：自动驾驶公司-Wayve"><a href="#案例-3：自动驾驶公司-Wayve" class="headerlink" title="案例 3：自动驾驶公司 Wayve"></a>案例 3：自动驾驶公司 Wayve</h3><p>这家英国的自动驾驶初创公司大量使用 Rust。他们的 CTO 表示：”Rust 让我们能够快速迭代复杂的感知和控制系统，同时保持极高的安全标准。”</p><h2 id="挑战与障碍"><a href="#挑战与障碍" class="headerlink" title="挑战与障碍"></a>挑战与障碍</h2><p>当然，Rust 在 AI 领域也面临挑战：</p><h3 id="1-学习曲线陡峭"><a href="#1-学习曲线陡峭" class="headerlink" title="1. 学习曲线陡峭"></a>1. 学习曲线陡峭</h3><p>Rust 的所有权系统和生命周期概念需要时间掌握。对于习惯了 Python 的 AI 研究者来说，这个门槛不低。</p><h3 id="2-生态仍不完善"><a href="#2-生态仍不完善" class="headerlink" title="2. 生态仍不完善"></a>2. 生态仍不完善</h3><p>虽然 Rust 的 ML 生态在快速发展，但与 Python 的 PyTorch、TensorFlow 相比，还有很大差距。许多最新的 AI 论文和模型仍然首先提供 Python 实现。</p><h3 id="3-社区文化差异"><a href="#3-社区文化差异" class="headerlink" title="3. 社区文化差异"></a>3. 社区文化差异</h3><p>AI 社区以快速实验和迭代著称，而 Rust 社区更注重正确性和安全性。这两种文化需要时间融合。</p><h2 id="未来展望：Rust-在-AI-时代的角色"><a href="#未来展望：Rust-在-AI-时代的角色" class="headerlink" title="未来展望：Rust 在 AI 时代的角色"></a>未来展望：Rust 在 AI 时代的角色</h2><p>我认为 Rust 不会完全取代 Python 在 AI 研究中的地位，但它会在以下几个领域大放异彩：</p><h3 id="1-生产部署：将研究模型转化为可靠的生产服务"><a href="#1-生产部署：将研究模型转化为可靠的生产服务" class="headerlink" title="1. 生产部署：将研究模型转化为可靠的生产服务"></a>1. <strong>生产部署</strong>：将研究模型转化为可靠的生产服务</h3><h3 id="2-边缘计算：在资源受限的设备上运行-AI-模型"><a href="#2-边缘计算：在资源受限的设备上运行-AI-模型" class="headerlink" title="2. 边缘计算：在资源受限的设备上运行 AI 模型"></a>2. <strong>边缘计算</strong>：在资源受限的设备上运行 AI 模型</h3><h3 id="3-基础设施：构建-AI-训练和推理的基础设施"><a href="#3-基础设施：构建-AI-训练和推理的基础设施" class="headerlink" title="3. 基础设施：构建 AI 训练和推理的基础设施"></a>3. <strong>基础设施</strong>：构建 AI 训练和推理的基础设施</h3><h3 id="4-安全关键系统：自动驾驶、医疗-AI-等对安全性要求极高的领域"><a href="#4-安全关键系统：自动驾驶、医疗-AI-等对安全性要求极高的领域" class="headerlink" title="4. 安全关键系统：自动驾驶、医疗 AI 等对安全性要求极高的领域"></a>4. <strong>安全关键系统</strong>：自动驾驶、医疗 AI 等对安全性要求极高的领域</h3><h2 id="给开发者的建议"><a href="#给开发者的建议" class="headerlink" title="给开发者的建议"></a>给开发者的建议</h2><p>如果你是一名 AI 开发者，我建议：</p><ol><li><strong>不要全盘切换</strong>：继续用 Python 做研究和原型，用 Rust 做生产部署</li><li><strong>从基础设施开始</strong>：先用 Rust 重写性能瓶颈或安全关键的组件</li><li><strong>关注混合架构</strong>：Python 负责上层逻辑，Rust 负责底层计算</li><li><strong>参与社区建设</strong>：Rust 的 AI 生态需要更多开发者贡献</li></ol><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>Rust 可能不是 AI 时代的”唯一”编程语言，但它很可能是”最好”的编程语言之一——特别是在对性能、安全和可靠性要求极高的场景中。</p><p>就像 C 语言定义了系统编程，Java 定义了企业应用，JavaScript 定义了 Web 开发一样，Rust 有机会定义 AI 时代的生产级代码标准。</p><p>AI 的未来不仅需要聪明的算法，更需要可靠的实现。而 Rust，正是为了可靠而生。</p><hr><p><strong>延伸阅读</strong>：</p><ul><li><a href="https://doc.rust-lang.org/book/">The Rust Programming Language</a></li><li><a href="https://www.arewelearningyet.com/">Rust for AI&#x2F;ML</a></li><li><a href="https://github.com/huggingface/tokenizers">Hugging Face’s Rust tokenizers</a></li></ul><p><strong>讨论</strong>：你认为 Rust 在 AI 领域的最大机会是什么？欢迎在评论区分享你的看法。</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/02/rust-ai-language/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/02/rust-ai-language/"/>
    <published>2026-03-02T04:35:00.000Z</published>
    <summary>在 AI 浪潮席卷全球的今天，Rust 凭借其独特的安全性和性能优势，能否成为 AI 开发的首选语言？本文从多个角度探讨 Rust 在 AI 时代的机遇与挑战。</summary>
    <title>Rust 会是 AI 时代的最好的编程语言吗？</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <category term="社会" scheme="https://xiaoxiaduoyan.com/tags/%E7%A4%BE%E4%BC%9A/"/>
    <content>
      <![CDATA[<h2 id="站在分岔路口"><a href="#站在分岔路口" class="headerlink" title="站在分岔路口"></a>站在分岔路口</h2><p>每隔几十年，人类社会就会遇到一个分岔路口。</p><p>蒸汽机来的时候，有人说它会解放人类的双手，也有人说它会让工人沦为机器的奴隶。两种预言都应验了——工业革命确实创造了前所未有的繁荣，也确实制造了血汗工厂和童工。</p><p>互联网来的时候，有人说它会让信息自由流通、消除信息不对称，也有人说它会制造信息茧房和数字鸿沟。两种预言也都应验了。</p><p>现在轮到 AI 了。</p><p>关于 AI 会把社会带向何方，乐观者和悲观者的分歧之大，可能是历次技术革命中最极端的。乐观者说 AI 会带来人类文明的黄金时代，悲观者说 AI 可能是人类最后一个发明。</p><p><strong>两边都不是在危言耸听。这才是最让人不安的地方。</strong></p><p>今天我想认真地把两种观点都摊开来聊聊——不是为了站队，而是为了看清楚我们到底面对的是什么。</p><h2 id="乐观篇：AI-可能带来的美好"><a href="#乐观篇：AI-可能带来的美好" class="headerlink" title="乐观篇：AI 可能带来的美好"></a>乐观篇：AI 可能带来的美好</h2><h3 id="医疗：每个人都能享受顶级医疗"><a href="#医疗：每个人都能享受顶级医疗" class="headerlink" title="医疗：每个人都能享受顶级医疗"></a>医疗：每个人都能享受顶级医疗</h3><p>现在全球最好的医生有多少？几千个？几万个？不管多少，肯定不够 80 亿人用。</p><p>AI 正在改变这个等式。AlphaFold 解决了蛋白质折叠问题，这意味着药物研发的速度可能提升一个数量级。AI 辅助诊断已经在某些领域（比如皮肤癌筛查、眼底病变检测）达到甚至超过了专科医生的水平。</p><p>想象一下这样的未来：你身体不舒服，AI 根据你的基因组数据、生活习惯、历史病历，给出个性化的诊断和治疗方案。不需要排队三小时看病三分钟，不需要因为医疗资源不均衡而延误治疗。</p><p>这不是科幻。很多技术已经在实验室里跑通了，缺的只是临床验证和监管审批。</p><p><strong>如果 AI 能让全球 80 亿人都享受到目前只有少数人能享受的医疗水平，这可能是人类历史上最大的福祉提升。</strong></p><h3 id="教育：每个孩子都有私人导师"><a href="#教育：每个孩子都有私人导师" class="headerlink" title="教育：每个孩子都有私人导师"></a>教育：每个孩子都有私人导师</h3><p>教育的本质是什么？是一个有经验的人，根据学生的具体情况，用最适合他的方式传授知识。</p><p>问题是，一个老师面对四五十个学生，不可能做到因材施教。这不是老师的错，是资源约束。</p><p>AI 可以打破这个约束。一个 AI 导师可以：</p><ul><li>精确了解每个学生的知识盲点</li><li>根据学生的学习风格调整教学方式</li><li>无限耐心地解答问题</li><li>24 小时随时可用</li><li>覆盖从小学数学到量子物理的所有学科</li></ul><p>这意味着什么？意味着一个偏远山区的孩子，理论上可以获得和北京四中学生同等质量的教育资源。<strong>教育公平，可能第一次从口号变成现实。</strong></p><h3 id="生产力：创造力的民主化"><a href="#生产力：创造力的民主化" class="headerlink" title="生产力：创造力的民主化"></a>生产力：创造力的民主化</h3><p>我在前一篇文章里聊过，AI 正在让”一个人干翻一个团队”成为可能。这背后更深层的含义是：<strong>创造力正在被民主化。</strong></p><p>以前，把一个想法变成产品，需要资金、团队、技术能力。大多数人有想法但没有资源去实现。现在，AI 把实现想法的门槛降到了前所未有的低点。</p><p>一个没学过编程的人，可以用 AI 做出一个 App。一个没学过画画的人，可以用 AI 生成精美的插画。一个没学过音乐的人，可以用 AI 创作一首歌。</p><p>这不是说专业技能不重要了。而是说，<strong>更多的人有机会参与创造，而不是只能当消费者。</strong> 当创造者的数量从几百万变成几十亿，人类文明的创新速度会发生质的飞跃。</p><h3 id="科学：加速基础研究"><a href="#科学：加速基础研究" class="headerlink" title="科学：加速基础研究"></a>科学：加速基础研究</h3><p>AI 在科学研究中的潜力可能是最被低估的。</p><p>数学证明、材料发现、气候模拟、基因编辑……这些领域的突破往往需要处理海量数据和探索巨大的搜索空间。人类科学家的直觉很重要，但在某些维度上，AI 的计算能力是碾压性的。</p><p>DeepMind 用 AI 发现了新的数学定理。AI 在材料科学中发现了人类从未想到过的新材料。这些不是替代科学家，而是给科学家装上了望远镜和显微镜——让他们看到以前看不到的东西。</p><p><strong>如果 AI 能帮助人类在可控核聚变、癌症治疗、气候变化等关键问题上取得突破，那它对人类文明的贡献将是不可估量的。</strong></p><p><img src="/images/ai-impact-areas.png" alt="AI 影响社会的各个领域"></p><h2 id="悲观篇：AI-可能带来的风险"><a href="#悲观篇：AI-可能带来的风险" class="headerlink" title="悲观篇：AI 可能带来的风险"></a>悲观篇：AI 可能带来的风险</h2><h3 id="就业：大规模失业不是危言耸听"><a href="#就业：大规模失业不是危言耸听" class="headerlink" title="就业：大规模失业不是危言耸听"></a>就业：大规模失业不是危言耸听</h3><p>每次技术革命都会消灭一批工作岗位，同时创造一批新的。蒸汽机消灭了手工织布工，但创造了工厂工人。互联网消灭了很多中间商，但创造了程序员和运营。</p><p>乐观者说 AI 也一样——旧工作消失，新工作出现，总量不变甚至增加。</p><p><strong>但这次可能真的不一样。</strong></p><p>以前的技术革命替代的是体力劳动或简单的重复性脑力劳动。AI 替代的是认知劳动——写作、分析、编程、设计、翻译、客服、法律咨询……这些是中产阶级的核心技能。</p><p>而且替代的速度可能远快于新工作的创造速度。工业革命花了几十年才完成转型，期间有足够的时间让社会适应。AI 的渗透速度是以年甚至月计算的。</p><p>更关键的是：<strong>新创造的工作，可能需要更高的技能门槛。</strong> 不是所有被替代的客服人员都能转型成 AI 训练师。不是所有被替代的初级程序员都能升级成 AI 系统架构师。</p><p>如果大量人口在短时间内失去工作，而又没有足够的社会安全网来缓冲，社会动荡几乎是必然的。</p><h3 id="不平等：技术鸿沟加剧贫富差距"><a href="#不平等：技术鸿沟加剧贫富差距" class="headerlink" title="不平等：技术鸿沟加剧贫富差距"></a>不平等：技术鸿沟加剧贫富差距</h3><p>AI 的好处不是均匀分配的。</p><p>谁最先享受到 AI 的红利？是那些有资金购买 AI 工具、有教育背景理解 AI 能力、有基础设施支撑 AI 运行的人和国家。</p><p>一个硅谷的工程师用 Cursor 写代码，效率提升 5 倍。一个发展中国家的程序员可能连稳定的网络都没有。</p><p>一个大公司用 AI 优化供应链，利润翻倍。一个小作坊的老板可能连 AI 是什么都不知道。</p><p><strong>技术革命的历史告诉我们：新技术在短期内几乎总是加剧不平等。</strong> 只有当技术充分普及、成本降到足够低之后，红利才会扩散到更广泛的人群。但在那之前，先行者和落后者之间的差距会被急剧拉大。</p><p>国家层面也是如此。掌握 AI 核心技术的国家（主要是美国和中国）和其他国家之间的差距，可能会比互联网时代更大。</p><h3 id="信息：真假难辨的世界"><a href="#信息：真假难辨的世界" class="headerlink" title="信息：真假难辨的世界"></a>信息：真假难辨的世界</h3><p>深度伪造（Deepfake）已经不是新闻了。但随着 AI 生成能力的提升，问题会变得更加严重。</p><p>当 AI 可以生成以假乱真的视频、音频、文字，我们怎么判断什么是真的？当任何人都可以用 AI 批量生产虚假信息，民主社会赖以运转的”共识”基础会不会崩塌？</p><p>这不是技术问题，是社会问题。技术上你可以做 AI 检测来识别伪造内容，但这是一场永远追不上的军备竞赛——生成技术永远比检测技术跑得快。</p><p><strong>更深层的问题是：当人们不再相信自己看到的和听到的，社会信任的基础会被侵蚀。</strong> 而信任是一切社会合作的前提。</p><h3 id="权力集中：少数人控制-AI-基础设施"><a href="#权力集中：少数人控制-AI-基础设施" class="headerlink" title="权力集中：少数人控制 AI 基础设施"></a>权力集中：少数人控制 AI 基础设施</h3><p>训练一个前沿大模型需要几亿甚至几十亿美元。这意味着只有极少数公司有能力做这件事。</p><p>OpenAI、Google、Anthropic、Meta……全球能训练顶级大模型的公司，一只手数得过来。这些公司掌握着 AI 时代最核心的基础设施。</p><p>这种集中度比互联网时代更极端。互联网时代，虽然 Google 和 Facebook 很大，但任何人都可以建一个网站。AI 时代，你可以用别人的 API，但你无法训练自己的基础模型。</p><p><strong>当少数公司掌握了 AI 的”发电厂”，它们对社会的影响力会超过很多国家政府。</strong> 它们的价值观、偏见、商业利益，会通过 AI 渗透到社会的每一个角落。</p><h3 id="存在性风险：失控的可能"><a href="#存在性风险：失控的可能" class="headerlink" title="存在性风险：失控的可能"></a>存在性风险：失控的可能</h3><p>这是最极端的悲观观点，但提出这个观点的不是科幻作家，而是 AI 领域最顶尖的研究者。</p><p>Hinton（深度学习之父）从 Google 离职，专门警告 AI 的风险。Yoshua Bengio（另一位图灵奖得主）签署了呼吁暂停 AI 研发的公开信。OpenAI 自己成立了”超级对齐”团队（虽然后来团队解散了，这本身就说明问题）。</p><p>他们担心的不是当前的 AI，而是未来可能出现的超级智能。如果一个 AI 系统的智能远超人类，而我们又无法确保它的目标和人类的利益一致，后果可能是灾难性的。</p><p>这个风险有多大？没人知道。可能是 1%，可能是 10%，可能是 0.01%。但当赌注是整个人类文明时，即使是很小的概率也值得认真对待。</p><p><img src="/images/ai-society-spectrum.png" alt="乐观与悲观的光谱"></p><h2 id="被忽视的中间地带"><a href="#被忽视的中间地带" class="headerlink" title="被忽视的中间地带"></a>被忽视的中间地带</h2><p>大多数关于 AI 未来的讨论，要么极度乐观，要么极度悲观。但现实往往在中间。</p><p><strong>技术革命的历史告诉我们：好的和坏的通常同时发生。</strong></p><p>工业革命带来了繁荣，也带来了污染和剥削。互联网带来了信息自由，也带来了隐私侵犯和注意力经济。AI 大概率也是如此——它会同时带来巨大的好处和巨大的问题。</p><p>关键不在于 AI 本身是好是坏，而在于：</p><p><strong>我们选择怎么用它。</strong></p><p>同样的 AI 技术，可以用来做个性化教育，也可以用来做个性化操控。可以用来加速药物研发，也可以用来设计生化武器。可以用来帮助残障人士，也可以用来大规模监控。</p><p><strong>技术是中性的，但使用技术的社会不是。</strong> 制度、法律、文化、价值观——这些”软基建”决定了技术最终走向何方。</p><h2 id="我的判断"><a href="#我的判断" class="headerlink" title="我的判断"></a>我的判断</h2><p>聊了这么多，说说我自己的看法。</p><p><strong>短期（3-5 年），我偏悲观。</strong> 就业冲击会比大多数人预期的来得更快更猛。社会的适应速度跟不上技术的变化速度。会有一段混乱期。</p><p><strong>中期（5-15 年），我谨慎乐观。</strong> 新的工作形态会逐渐成型，社会制度会开始适应。AI 在医疗、教育、科研等领域的正面影响会越来越明显。但不平等问题会是一个持续的挑战。</p><p><strong>长期（15 年以上），我不确定。</strong> 这取决于太多我们现在无法预测的变量——AI 的发展速度、国际合作的程度、社会制度的演化、是否出现黑天鹅事件。</p><p>但有一点我比较确定：<strong>被动等待是最差的策略。</strong></p><p>不管你是乐观还是悲观，最理性的做法是：积极了解 AI，学会使用 AI，同时关注 AI 带来的社会问题，推动负责任的 AI 发展。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>我想起一个老故事。</p><p>汽车刚发明的时候，英国通过了一个”红旗法案”——规定每辆汽车前面必须有一个人举着红旗步行开道，汽车的速度不能超过步行速度。</p><p>这个法案的初衷是保护行人安全，出发点没错。但结果是英国的汽车工业被德国和美国远远甩在后面。</p><p><strong>过度恐惧和盲目乐观一样危险。</strong></p><p>AI 会让社会发生深刻的变革，这一点毫无疑问。变革中会有阵痛、有风险、有人受益、有人受损。但历史告诉我们，技术革命的大方向是不可逆的——你可以影响它的走向，但不能阻止它的到来。</p><p>与其争论 AI 是天使还是魔鬼，不如想想：<strong>我们怎么做，才能让天使的一面多一点，魔鬼的一面少一点？</strong></p><p>这个问题的答案，不在 AI 手里，在我们手里。</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/01/ai-social-revolution/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/01/ai-social-revolution/"/>
    <published>2026-03-01T02:00:00.000Z</published>
    <summary>站在 AI 革命的分岔路口，乐观者看到天堂，悲观者看到深渊。真相可能在中间，但绝不平庸。</summary>
    <title>AI 会让社会发生怎样的变革</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Thoughts" scheme="https://xiaoxiaduoyan.com/tags/Thoughts/"/>
    <category term="English" scheme="https://xiaoxiaduoyan.com/tags/English/"/>
    <category term="Society" scheme="https://xiaoxiaduoyan.com/tags/Society/"/>
    <content>
      <![CDATA[<h2 id="Standing-at-the-Crossroads"><a href="#Standing-at-the-Crossroads" class="headerlink" title="Standing at the Crossroads"></a>Standing at the Crossroads</h2><p>Every few decades, human society encounters a crossroads.</p><p>When the steam engine arrived, some said it would liberate human hands. Others said it would reduce workers to slaves of machines. Both predictions came true — the Industrial Revolution created unprecedented prosperity and also produced sweatshops and child labor.</p><p>When the internet arrived, some said it would enable free information flow and eliminate information asymmetry. Others said it would create filter bubbles and digital divides. Both predictions also came true.</p><p>Now it’s AI’s turn.</p><p>The divide between optimists and pessimists about where AI will take society may be the most extreme in the history of technological revolutions. Optimists say AI will usher in a golden age of human civilization. Pessimists say AI might be humanity’s last invention.</p><p><strong>Neither side is being alarmist. That’s what makes it so unsettling.</strong></p><p>Today I want to lay both perspectives out honestly — not to pick sides, but to see clearly what we’re actually facing.</p><h2 id="The-Optimistic-Case-The-Beautiful-Possibilities"><a href="#The-Optimistic-Case-The-Beautiful-Possibilities" class="headerlink" title="The Optimistic Case: The Beautiful Possibilities"></a>The Optimistic Case: The Beautiful Possibilities</h2><h3 id="Healthcare-World-Class-Medicine-for-Everyone"><a href="#Healthcare-World-Class-Medicine-for-Everyone" class="headerlink" title="Healthcare: World-Class Medicine for Everyone"></a>Healthcare: World-Class Medicine for Everyone</h3><p>How many of the world’s best doctors are there? A few thousand? Tens of thousands? Whatever the number, it’s certainly not enough for 8 billion people.</p><p>AI is changing this equation. AlphaFold solved the protein folding problem, meaning drug development speed could improve by an order of magnitude. AI-assisted diagnosis has already matched or exceeded specialist physicians in certain areas (like skin cancer screening and retinal disease detection).</p><p>Imagine this future: you feel unwell, and AI generates a personalized diagnosis and treatment plan based on your genomic data, lifestyle habits, and medical history. No waiting three hours for a three-minute consultation. No delayed treatment due to uneven medical resource distribution.</p><p>This isn’t science fiction. Many of these technologies already work in labs — what’s missing is clinical validation and regulatory approval.</p><p><strong>If AI can bring the medical standard currently available only to the few to all 8 billion people globally, this could be the greatest welfare improvement in human history.</strong></p><h3 id="Education-A-Private-Tutor-for-Every-Child"><a href="#Education-A-Private-Tutor-for-Every-Child" class="headerlink" title="Education: A Private Tutor for Every Child"></a>Education: A Private Tutor for Every Child</h3><p>What’s the essence of education? An experienced person teaching knowledge in the most suitable way based on each student’s specific situation.</p><p>The problem is, one teacher facing forty or fifty students simply can’t personalize instruction. That’s not the teacher’s fault — it’s a resource constraint.</p><p>AI can break this constraint. An AI tutor can:</p><ul><li>Precisely identify each student’s knowledge gaps</li><li>Adjust teaching methods to match learning styles</li><li>Answer questions with infinite patience</li><li>Be available 24&#x2F;7</li><li>Cover everything from elementary math to quantum physics</li></ul><p>What does this mean? A child in a remote village could theoretically access the same quality education as a student at an elite school. <strong>Educational equity might, for the first time, move from slogan to reality.</strong></p><h3 id="Productivity-Democratization-of-Creativity"><a href="#Productivity-Democratization-of-Creativity" class="headerlink" title="Productivity: Democratization of Creativity"></a>Productivity: Democratization of Creativity</h3><p>As I discussed in my previous article, AI is making it possible for “one person to outperform a team.” The deeper implication: <strong>creativity is being democratized.</strong></p><p>Previously, turning an idea into a product required capital, a team, and technical skills. Most people had ideas but lacked resources to realize them. Now, AI has lowered the barrier to implementation to unprecedented levels.</p><p>Someone who never learned programming can build an app with AI. Someone who never learned to draw can generate beautiful illustrations. Someone who never studied music can compose a song.</p><p>This doesn’t mean professional skills don’t matter anymore. It means <strong>more people get to participate in creation, rather than being limited to consumption.</strong> When the number of creators goes from millions to billions, the pace of human innovation will undergo a qualitative leap.</p><h3 id="Science-Accelerating-Fundamental-Research"><a href="#Science-Accelerating-Fundamental-Research" class="headerlink" title="Science: Accelerating Fundamental Research"></a>Science: Accelerating Fundamental Research</h3><p>AI’s potential in scientific research may be the most underestimated.</p><p>Mathematical proofs, materials discovery, climate simulation, gene editing… breakthroughs in these fields often require processing massive data and exploring enormous search spaces. Human scientists’ intuition matters, but in certain dimensions, AI’s computational power is overwhelming.</p><p>DeepMind used AI to discover new mathematical theorems. AI has found materials in materials science that humans never conceived of. These aren’t replacing scientists — they’re equipping scientists with telescopes and microscopes, letting them see what was previously invisible.</p><p><strong>If AI can help humanity achieve breakthroughs in controlled nuclear fusion, cancer treatment, and climate change, its contribution to human civilization will be immeasurable.</strong></p><p><img src="/images/ai-impact-areas.png" alt="AI Impact Across Society"></p><h2 id="The-Pessimistic-Case-The-Risks"><a href="#The-Pessimistic-Case-The-Risks" class="headerlink" title="The Pessimistic Case: The Risks"></a>The Pessimistic Case: The Risks</h2><h3 id="Employment-Mass-Unemployment-Isn’t-Alarmist"><a href="#Employment-Mass-Unemployment-Isn’t-Alarmist" class="headerlink" title="Employment: Mass Unemployment Isn’t Alarmist"></a>Employment: Mass Unemployment Isn’t Alarmist</h3><p>Every technological revolution eliminates some jobs while creating new ones. The steam engine eliminated hand weavers but created factory workers. The internet eliminated many middlemen but created programmers and content creators.</p><p>Optimists say AI will be the same — old jobs disappear, new ones emerge, total employment stays the same or even grows.</p><p><strong>But this time might truly be different.</strong></p><p>Previous technological revolutions replaced physical labor or simple repetitive cognitive work. AI replaces cognitive labor — writing, analysis, programming, design, translation, customer service, legal consulting… These are the core skills of the middle class.</p><p>And the replacement speed may far exceed the creation speed of new jobs. The Industrial Revolution took decades to complete its transition, giving society enough time to adapt. AI’s penetration speed is measured in years, even months.</p><p>More critically: <strong>newly created jobs may require higher skill thresholds.</strong> Not every displaced customer service rep can retrain as an AI trainer. Not every displaced junior programmer can upgrade to an AI systems architect.</p><p>If large populations lose their jobs in a short time without adequate social safety nets, social upheaval is almost inevitable.</p><h3 id="Inequality-The-Tech-Divide-Deepens-Wealth-Gaps"><a href="#Inequality-The-Tech-Divide-Deepens-Wealth-Gaps" class="headerlink" title="Inequality: The Tech Divide Deepens Wealth Gaps"></a>Inequality: The Tech Divide Deepens Wealth Gaps</h3><p>AI’s benefits aren’t evenly distributed.</p><p>Who benefits from AI first? Those with capital to purchase AI tools, education to understand AI capabilities, and infrastructure to support AI operations — both people and nations.</p><p>A Silicon Valley engineer uses Cursor to code, boosting productivity 5x. A programmer in a developing country might not even have stable internet.</p><p>A large corporation uses AI to optimize its supply chain, doubling profits. A small workshop owner might not even know what AI is.</p><p><strong>The history of technological revolutions tells us: new technology almost always exacerbates inequality in the short term.</strong> Only after technology becomes sufficiently widespread and costs drop low enough do benefits spread to broader populations. But before that, the gap between early adopters and laggards widens dramatically.</p><p>The same applies at the national level. The gap between countries mastering core AI technology (primarily the US and China) and others could be larger than during the internet era.</p><h3 id="Information-A-World-Where-Truth-Is-Indistinguishable"><a href="#Information-A-World-Where-Truth-Is-Indistinguishable" class="headerlink" title="Information: A World Where Truth Is Indistinguishable"></a>Information: A World Where Truth Is Indistinguishable</h3><p>Deepfakes are old news. But as AI generation capabilities improve, the problem will become far more severe.</p><p>When AI can generate indistinguishable fake videos, audio, and text, how do we determine what’s real? When anyone can mass-produce disinformation with AI, will the “consensus” foundation that democratic societies depend on collapse?</p><p>This isn’t a technical problem — it’s a social one. Technically you can build AI detection to identify fakes, but it’s an arms race you can never win — generation technology always outpaces detection.</p><p><strong>The deeper issue: when people no longer trust what they see and hear, the foundation of social trust erodes.</strong> And trust is the prerequisite for all social cooperation.</p><h3 id="Power-Concentration-A-Few-Control-AI-Infrastructure"><a href="#Power-Concentration-A-Few-Control-AI-Infrastructure" class="headerlink" title="Power Concentration: A Few Control AI Infrastructure"></a>Power Concentration: A Few Control AI Infrastructure</h3><p>Training a frontier large model costs hundreds of millions to billions of dollars. This means only a handful of companies can do it.</p><p>OpenAI, Google, Anthropic, Meta… the companies capable of training top-tier models can be counted on one hand. These companies control the most critical infrastructure of the AI era.</p><p>This concentration is more extreme than the internet era. During the internet era, though Google and Facebook were huge, anyone could build a website. In the AI era, you can use others’ APIs, but you can’t train your own foundation model.</p><p><strong>When a few companies control AI’s “power plants,” their influence on society will exceed many national governments.</strong> Their values, biases, and commercial interests will permeate every corner of society through AI.</p><h3 id="Existential-Risk-The-Possibility-of-Loss-of-Control"><a href="#Existential-Risk-The-Possibility-of-Loss-of-Control" class="headerlink" title="Existential Risk: The Possibility of Loss of Control"></a>Existential Risk: The Possibility of Loss of Control</h3><p>This is the most extreme pessimistic view, but it’s not proposed by science fiction writers — it comes from AI’s most elite researchers.</p><p>Hinton (the godfather of deep learning) left Google specifically to warn about AI risks. Yoshua Bengio (another Turing Award winner) signed an open letter calling for a pause in AI development. OpenAI itself established a “superalignment” team (though the team later disbanded, which itself is telling).</p><p>They’re not worried about current AI, but about potential future superintelligence. If an AI system’s intelligence far exceeds humanity’s, and we can’t ensure its goals align with human interests, the consequences could be catastrophic.</p><p>How large is this risk? Nobody knows. Maybe 1%, maybe 10%, maybe 0.01%. But when the stakes are all of human civilization, even a small probability deserves serious attention.</p><p><img src="/images/ai-society-spectrum.png" alt="Optimism vs Pessimism Spectrum"></p><h2 id="The-Overlooked-Middle-Ground"><a href="#The-Overlooked-Middle-Ground" class="headerlink" title="The Overlooked Middle Ground"></a>The Overlooked Middle Ground</h2><p>Most discussions about AI’s future are either extremely optimistic or extremely pessimistic. But reality usually falls in between.</p><p><strong>The history of technological revolutions tells us: good and bad typically happen simultaneously.</strong></p><p>The Industrial Revolution brought prosperity and also pollution and exploitation. The internet brought information freedom and also privacy invasion and the attention economy. AI will most likely be the same — simultaneously bringing enormous benefits and enormous problems.</p><p>The key isn’t whether AI itself is good or bad, but:</p><p><strong>How we choose to use it.</strong></p><p>The same AI technology can be used for personalized education or personalized manipulation. To accelerate drug development or to design bioweapons. To help people with disabilities or for mass surveillance.</p><p><strong>Technology is neutral, but the society using technology is not.</strong> Institutions, laws, culture, values — this “soft infrastructure” determines where technology ultimately leads.</p><h2 id="My-Assessment"><a href="#My-Assessment" class="headerlink" title="My Assessment"></a>My Assessment</h2><p>After discussing all this, here’s my personal take.</p><p><strong>Short-term (3-5 years), I lean pessimistic.</strong> Employment shocks will come faster and harder than most people expect. Society’s adaptation speed can’t keep up with technology’s pace of change. There will be a period of turbulence.</p><p><strong>Medium-term (5-15 years), I’m cautiously optimistic.</strong> New work paradigms will gradually take shape, social systems will begin adapting. AI’s positive impact in healthcare, education, and research will become increasingly apparent. But inequality will remain a persistent challenge.</p><p><strong>Long-term (15+ years), I’m uncertain.</strong> This depends on too many variables we can’t currently predict — AI’s development speed, degree of international cooperation, evolution of social systems, whether black swan events occur.</p><p>But one thing I’m fairly certain about: <strong>passive waiting is the worst strategy.</strong></p><p>Whether you’re optimistic or pessimistic, the most rational approach is: actively understand AI, learn to use AI, while also paying attention to the social problems AI creates and pushing for responsible AI development.</p><h2 id="Final-Thoughts"><a href="#Final-Thoughts" class="headerlink" title="Final Thoughts"></a>Final Thoughts</h2><p>I’m reminded of an old story.</p><p>When cars were first invented, Britain passed the “Red Flag Act” — requiring every car to be preceded by a person walking with a red flag, with the car’s speed not exceeding walking pace.</p><p>The law’s intention was to protect pedestrian safety, and the motivation was sound. But the result was that Britain’s automotive industry fell far behind Germany and America.</p><p><strong>Excessive fear is as dangerous as blind optimism.</strong></p><p>AI will profoundly transform society — there’s no doubt about that. The transformation will involve growing pains, risks, winners, and losers. But history tells us that the general direction of technological revolution is irreversible — you can influence its trajectory, but you can’t stop its arrival.</p><p>Rather than debating whether AI is angel or demon, perhaps we should ask: <strong>what can we do to amplify the angel and diminish the demon?</strong></p><p>The answer to that question isn’t in AI’s hands. It’s in ours.</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/03/01/ai-social-revolution-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/03/01/ai-social-revolution-en/"/>
    <published>2026-03-01T02:00:00.000Z</published>
    <summary>Standing at the crossroads of the AI revolution, optimists see paradise while pessimists see the abyss. The truth may lie in between, but it's anything but boring.</summary>
    <title>How AI Will Transform Society</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Thoughts" scheme="https://xiaoxiaduoyan.com/tags/Thoughts/"/>
    <category term="English" scheme="https://xiaoxiaduoyan.com/tags/English/"/>
    <category term="Business" scheme="https://xiaoxiaduoyan.com/tags/Business/"/>
    <content>
      <![CDATA[<h2 id="One-Person-Outperforming-a-Team"><a href="#One-Person-Outperforming-a-Team" class="headerlink" title="One Person Outperforming a Team"></a>One Person Outperforming a Team</h2><p>Over the past year or two, I’ve noticed an increasingly obvious trend: many impressive products are built by just one or two people.</p><p>A solo developer, using AI to help write code, design interfaces, craft copy, and handle operations, can ship a complete product in weeks. Three years ago, the same thing would have required a five-to-ten person team working for months.</p><p>This isn’t an anomaly. Browse Product Hunt’s trending products — more and more are labeled “Solo Founder.” Check GitHub’s popular projects — many have only one or two contributors, yet their code quality and feature completeness rival team efforts.</p><p><strong>What happened?</strong></p><p>The answer is simple: AI changed the productivity equation.</p><h2 id="The-Old-Model-Strength-in-Numbers"><a href="#The-Old-Model-Strength-in-Numbers" class="headerlink" title="The Old Model: Strength in Numbers"></a>The Old Model: Strength in Numbers</h2><p>The traditional company model is built on a basic assumption: <strong>doing more requires more people.</strong></p><p>To develop a product, you need product managers, designers, frontend engineers, backend engineers, QA engineers, DevOps. To market it, you need marketing, operations, customer service. To manage all these people, you need project managers, HR, admin.</p><p>As headcount grows, communication costs explode. A five-person team has 10 communication lines. Ten people: 45. Fifty people: 1,225. That’s why large companies are inefficient — it’s not that people are bad, it’s that communication complexity grows exponentially with headcount.</p><p>So you need hierarchies, processes, meetings, documents, approvals. These things don’t create value themselves, but without them, large organizations spiral out of control. Management overhead becomes a massive hidden tax.</p><p><strong>The essence of the old model: trading management costs for scale effects.</strong></p><p>This made sense in the industrial age. Assembly lines needed workers, workers needed management. But in the information age, especially the AI age, this equation is breaking down.</p><h2 id="What-AI-Changes"><a href="#What-AI-Changes" class="headerlink" title="What AI Changes"></a>What AI Changes</h2><p>AI does one thing: <strong>it turns work that required “one person” into work that requires “one person for one hour.”</strong></p><p>Writing marketing copy used to take a copywriter a full day. Now you explain the requirements to AI, get a draft in ten minutes, spend twenty minutes polishing.</p><p>Creating a product prototype used to take a designer several days. Now you generate interfaces with AI, tweak them yourself, done in half a day.</p><p>Writing a backend API used to take an engineer half a day plus debugging. Now AI writes it, you review, and within an hour tests are passing.</p><p><strong>The efficiency gain in individual steps isn’t the point. The point is: when every step speeds up 5-10x, one person can cover the work scope of several people.</strong></p><p>This doesn’t mean AI replaces people. It means AI dramatically expands one person’s capability boundary. A product-minded engineer, plus AI, can simultaneously play the roles of product manager, designer, frontend, backend, QA, and copywriter. Not 100% in each role, but 70-80% is enough to ship a product.</p><p><img src="/images/company-model-shift.png" alt="Old vs New Company Models"></p><h2 id="New-Model-One-The-Super-Individual"><a href="#New-Model-One-The-Super-Individual" class="headerlink" title="New Model One: The Super Individual"></a>New Model One: The Super Individual</h2><p>The first new model is the <strong>Super Individual</strong> — one person is an entire company.</p><p>This isn’t a new concept; freelancers have always existed. But AI-era super individuals are different. Traditional freelancers could usually only do one thing — designers designed, programmers coded. Now one person can go full-stack: from idea to product to launch to operations, handling the entire chain.</p><p>I’ve seen a solo developer build a SaaS product generating tens of thousands of dollars monthly. His “team”: himself + ChatGPT + Cursor + Midjourney + a few automation tools. Customer service handled by AI chatbot, finances automated through Stripe, deployment one-click via Vercel.</p><p>The advantages are obvious:</p><ul><li><strong>Zero communication cost.</strong> All decisions happen in one brain. No meetings, no alignment, no waiting for approvals.</li><li><strong>Maximum flexibility.</strong> Want to add a feature today? It’s live this afternoon. Want to pivot? Done tomorrow.</li><li><strong>Extremely high margins.</strong> No labor costs means revenue nearly equals profit.</li></ul><p>There are limitations, of course: one person’s energy is finite, limiting scale. But the definition of “too big for one person” keeps expanding — things impossible for one person before are now feasible.</p><h2 id="New-Model-Two-AI-Native-Small-Teams"><a href="#New-Model-Two-AI-Native-Small-Teams" class="headerlink" title="New Model Two: AI-Native Small Teams"></a>New Model Two: AI-Native Small Teams</h2><p>The second model is the <strong>AI-Native small team</strong> — three to ten people producing what previously required fifty.</p><p>The defining characteristic: <strong>every person is a full-stack talent, with AI as everyone’s co-pilot.</strong></p><p>Traditional teams divide by function: product group, design group, dev group, QA group. AI-Native teams divide by business module: each person owns a complete module from requirements to launch. AI fills in their skill gaps.</p><p>Patterns I’ve observed:</p><p><strong>Very few meetings.</strong> Since everyone can make independent decisions, frequent alignment isn’t needed. Async communication dominates, documentation-driven.</p><p><strong>No dedicated managers.</strong> The team is small enough that “management” isn’t needed. Everyone is a maker; nobody is just a manager.</p><p><strong>AI tools deeply integrated into workflows.</strong> Not occasional ChatGPT use, but AI permeating every step — Cursor for coding, AI for design generation, AI-assisted documentation, AI for data analysis.</p><p><strong>Hiring criteria changed.</strong> It’s no longer about how many programming languages you know or frameworks you’ve used. It’s: can you independently take something from start to finish? Can you efficiently use AI tools? Do you have product sense?</p><p>Many emerging AI startups exemplify this model. You’ll notice that companies producing amazing products often have surprisingly tiny teams.</p><h2 id="New-Model-Three-Dynamic-Networks"><a href="#New-Model-Three-Dynamic-Networks" class="headerlink" title="New Model Three: Dynamic Networks"></a>New Model Three: Dynamic Networks</h2><p>The third model is more radical: <strong>a company is no longer a fixed organization but a dynamic collaboration network.</strong></p><p>The core team might be just two or three people, responsible for product direction and core technology. Everything else is accomplished through combinations of freelancers, contractors, and AI Agents. Need a marketing campaign? Partner with a freelance marketing expert for two weeks. Need complex data analysis? Let an AI Agent run it, human reviews results.</p><p>The essence: <strong>converting fixed costs to variable costs.</strong></p><p>Traditional companies pay full-time employees regardless of workload. In the dynamic network model, you only pay when needed. AI further reduces friction — the costs of finding contractors, coordinating, communicating, and reviewing used to be high. Now AI handles many intermediate steps.</p><h2 id="Impact-on-Traditional-Large-Companies"><a href="#Impact-on-Traditional-Large-Companies" class="headerlink" title="Impact on Traditional Large Companies"></a>Impact on Traditional Large Companies</h2><p>What do these new models mean for traditional large companies?</p><p><strong>First, competitors multiply.</strong> Products that only large companies could build before, small teams can now build too. And small teams are faster, more flexible, more willing to take risks. Features that take a large company a year might take a small team two months.</p><p><strong>Second, talent drain accelerates.</strong> The best talent realizes they can create enormous value with just themselves and AI. Why stay at a big company attending meetings, writing weekly reports, waiting for approvals? The super individual and small team models are increasingly attractive to top talent.</p><p><strong>Third, organizational bloat costs more.</strong> Previously, large companies being slightly inefficient was fine because competitors were similar. Not anymore — your competitor might be a three-person team with 10x your decision speed and 5x your iteration speed.</p><p>This doesn’t mean large companies will disappear. They have their advantages: brand, distribution, data, capital, compliance capabilities. But large companies need to transform — <strong>either get smaller, get faster, or do things small companies can’t.</strong></p><p><img src="/images/ai-leverage.png" alt="AI Leverage Effect"></p><h2 id="New-Competitive-Moats"><a href="#New-Competitive-Moats" class="headerlink" title="New Competitive Moats"></a>New Competitive Moats</h2><p>Under new models, competitive moats are shifting.</p><p><strong>Old moats:</strong> More people, more money, deeper tech accumulation. You have a thousand engineers; others can’t catch up.</p><p><strong>New moats:</strong></p><ul><li><strong>Data flywheels.</strong> Whoever’s product has more users, generates more data, trains better models — that’s the moat.</li><li><strong>AI utilization efficiency.</strong> Same AI, but some achieve 10x efficiency gains while others only get 2x. The difference lies in understanding AI’s capability boundaries and workflow design.</li><li><strong>Speed.</strong> In the AI era, speed is a moat. Ship two weeks before competitors and you capture users and feedback data first.</li><li><strong>Taste and judgment.</strong> When AI reduces execution costs to near zero, what determines success is “what to build” not “how to build it.” Product taste and strategic judgment matter more than ever.</li><li><strong>Trust and brand.</strong> AI can help you build products but can’t build trust. Users choosing you over competitors increasingly depends on brand and reputation.</li></ul><h2 id="What-Future-Companies-Look-Like"><a href="#What-Future-Companies-Look-Like" class="headerlink" title="What Future Companies Look Like"></a>What Future Companies Look Like</h2><p>Extrapolating these trends, future companies might look like this:</p><p><strong>Most companies will get smaller.</strong> Not because they’re doing less, but because the same work requires fewer people. A 50-person company might shrink to 15, with equal or higher output.</p><p><strong>Organizational structures will flatten.</strong> Middle management will compress. When everyone can make independent decisions and AI handles coordination, hierarchies lose their purpose.</p><p><strong>The boundary between full-time employees and external collaborators will blur.</strong> Core team + dynamic external network becomes the norm.</p><p><strong>AI will become “employees.”</strong> Not metaphorically — literally. Companies will have AI Agents handling customer service, data analysis, content production, code review. These Agents will have their own “desks” (runtime environments), “permissions” (API access), “performance reviews” (quality monitoring).</p><p><strong>Startup barriers will drop dramatically.</strong> A person with an idea, without fundraising or hiring, can build a competitive product. This means startup volume will explode, but success standards will also rise — because competition intensifies.</p><h2 id="Final-Thoughts"><a href="#Final-Thoughts" class="headerlink" title="Final Thoughts"></a>Final Thoughts</h2><p>Every technological revolution reshapes organizational forms.</p><p>The Industrial Revolution spawned factories and assembly lines. The Information Revolution spawned internet companies and remote work. The AI Revolution is spawning new company models — smaller, faster, more flexible, with AI deeply embedded in every function.</p><p>For individuals, this is both opportunity and challenge. The opportunity: you no longer need a large team to do big things. The challenge: if you don’t learn to collaborate with AI, your competitiveness will decline rapidly.</p><p>My prediction: <strong>in the next five years, “knowing how to use AI” will go from a bonus to a baseline skill, just like “knowing how to use a computer.”</strong> It’s not a question of whether you’ll learn, but when you’ll start.</p><p>And those who embrace new models earliest will capture the biggest dividends.</p><p>As with every technological revolution — the early movers feast, the followers get scraps, and the oblivious foot the bill.</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/ai-company-model-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/ai-company-model-en/"/>
    <published>2026-02-28T15:00:00.000Z</published>
    <summary>When one person plus AI can outperform an entire team, what happens to the company as an organizational form?</summary>
    <title>New Company Models in the AI Era</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <category term="商业" scheme="https://xiaoxiaduoyan.com/tags/%E5%95%86%E4%B8%9A/"/>
    <content>
      <![CDATA[<h2 id="一个人干翻一个团队"><a href="#一个人干翻一个团队" class="headerlink" title="一个人干翻一个团队"></a>一个人干翻一个团队</h2><p>最近一两年，我注意到一个越来越明显的趋势：很多让人惊艳的产品，背后只有一两个人。</p><p>一个独立开发者，用 AI 辅助写代码、做设计、写文案、搞运营，几周时间就能上线一个完整的产品。放在三年前，同样的事情需要一个五到十人的小团队干几个月。</p><p>这不是个例。你去看 Product Hunt 上的热门产品，越来越多标注着”Solo Founder”。你去看 GitHub 上的热门项目，很多 contributor 只有一两个人，但代码质量和功能完整度不输大团队的作品。</p><p><strong>发生了什么？</strong></p><p>答案很简单：AI 改变了生产力的方程式。</p><h2 id="旧模式：人多力量大"><a href="#旧模式：人多力量大" class="headerlink" title="旧模式：人多力量大"></a>旧模式：人多力量大</h2><p>传统的公司模式建立在一个基本假设上：<strong>做更多的事，需要更多的人。</strong></p><p>你要开发一个产品，需要产品经理、设计师、前端工程师、后端工程师、测试工程师、运维工程师。你要推广这个产品，需要市场、运营、客服。你要管理这些人，需要项目经理、HR、行政。</p><p>人一多，沟通成本就上来了。五个人的团队，沟通线路是 10 条。十个人就变成 45 条。五十个人是 1225 条。这就是为什么大公司效率低——不是人不行，是沟通的复杂度随人数指数增长。</p><p>于是你需要层级、流程、会议、文档、审批。这些东西本身不创造价值，但没有它们，大组织就会失控。管理成本成了一个巨大的隐性税。</p><p><strong>旧模式的本质是：用管理成本换取规模效应。</strong></p><p>这在工业时代是合理的。流水线需要工人，工人需要管理。但在信息时代，尤其是 AI 时代，这个等式开始松动了。</p><h2 id="AI-改变了什么"><a href="#AI-改变了什么" class="headerlink" title="AI 改变了什么"></a>AI 改变了什么</h2><p>AI 做了一件事：<strong>把很多需要”一个人”的工作，变成了需要”一个人的一个小时”的工作。</strong></p><p>写一篇市场文案，以前需要一个文案策划花一天。现在你跟 AI 说清楚需求，十分钟出初稿，再花二十分钟修改润色。</p><p>做一个产品原型，以前需要设计师画几天。现在你用 AI 生成界面，自己微调，半天搞定。</p><p>写一个后端接口，以前需要工程师写半天加调试。现在 AI 写完你 review 一下，一个小时连测试都跑完了。</p><p><strong>单个环节的效率提升不是重点。重点是：当每个环节都提速 5-10 倍，一个人就能覆盖原来好几个人的工作范围。</strong></p><p>这不是说 AI 替代了人。而是 AI 让一个人的能力边界大幅扩展了。一个懂产品的工程师，加上 AI，可以同时扮演产品经理、设计师、前端、后端、测试、文案的角色。不是每个角色都做到 100 分，但做到 70-80 分已经足够上线一个产品了。</p><p><img src="/images/company-model-shift.png" alt="新旧公司模式对比"></p><h2 id="新模式一：超级个体"><a href="#新模式一：超级个体" class="headerlink" title="新模式一：超级个体"></a>新模式一：超级个体</h2><p>第一种新模式是<strong>超级个体</strong>——一个人就是一家公司。</p><p>这不是新概念，自由职业者一直存在。但 AI 时代的超级个体和以前不一样。以前的自由职业者通常只能做一件事——你是设计师就做设计，你是程序员就写代码。现在一个人可以做全栈：从想法到产品到上线到运营，全链路自己搞定。</p><p>我见过一个独立开发者，一个人做了一个 SaaS 产品，月收入几万美元。他的”团队”是：自己 + ChatGPT + Cursor + Midjourney + 几个自动化工具。客服用 AI 聊天机器人处理，财务用 Stripe 自动化，部署用 Vercel 一键搞定。</p><p>这种模式的优势很明显：</p><ul><li><strong>零沟通成本。</strong> 所有决策都在一个脑子里完成，不需要开会、对齐、等审批。</li><li><strong>极致灵活。</strong> 今天想加个功能，下午就上线了。想换个方向，明天就换。</li><li><strong>利润率极高。</strong> 没有人力成本，收入几乎等于利润。</li></ul><p>当然也有局限：一个人的精力有限，做不了太大的事。但”太大”的标准在不断提高——以前一个人做不了的事，现在可以了。</p><h2 id="新模式二：AI-Native-小团队"><a href="#新模式二：AI-Native-小团队" class="headerlink" title="新模式二：AI-Native 小团队"></a>新模式二：AI-Native 小团队</h2><p>第二种模式是 <strong>AI-Native 小团队</strong>——三到十个人，做出以前需要五十人才能做的产品。</p><p>这种团队的特点是：<strong>每个人都是全栈型人才，AI 是每个人的”副驾驶”。</strong></p><p>传统团队的分工是按职能划分的：产品组、设计组、开发组、测试组。AI-Native 团队的分工是按业务模块划分的：每个人负责一个完整的模块，从需求到上线全包。AI 帮他补齐不擅长的环节。</p><p>我观察到的一些特征：</p><p><strong>极少的会议。</strong> 因为每个人都能独立做决策，不需要频繁对齐。异步沟通为主，文档驱动。</p><p><strong>没有专职管理者。</strong> 团队小到不需要”管理”。大家都是 maker，没有人只做 manager。</p><p><strong>AI 工具深度集成到工作流。</strong> 不是偶尔用一下 ChatGPT，而是 AI 渗透到每个环节——写代码用 Cursor，做设计用 AI 生成，写文档用 AI 辅助，做数据分析用 AI 处理。</p><p><strong>招人标准变了。</strong> 不再看你会多少种编程语言或者用过多少种框架。看的是：你能不能独立把一件事从头到尾做完？你能不能高效地使用 AI 工具？你有没有产品感觉？</p><p>这种模式的代表是很多新兴的 AI 创业公司。你会发现，做出惊艳产品的公司，团队往往小得出奇。</p><h2 id="新模式三：动态网络"><a href="#新模式三：动态网络" class="headerlink" title="新模式三：动态网络"></a>新模式三：动态网络</h2><p>第三种模式更激进：<strong>公司不再是一个固定的组织，而是一个动态的协作网络。</strong></p><p>核心团队可能只有两三个人，负责产品方向和核心技术。其他工作通过外包、合同工、AI Agent 的组合来完成。需要做一个营销活动？找一个自由职业的营销专家合作两周。需要做一个复杂的数据分析？让 AI Agent 跑一遍，人工审核结果。</p><p>这种模式的本质是：<strong>把固定成本变成可变成本。</strong></p><p>传统公司养一个全职员工，不管他这个月忙不忙，工资照发。动态网络模式下，你只在需要的时候付费。AI 进一步降低了这种模式的摩擦——以前找外包、对接、沟通、验收的成本很高，现在 AI 可以承担很多中间环节。</p><h2 id="对传统大公司的冲击"><a href="#对传统大公司的冲击" class="headerlink" title="对传统大公司的冲击"></a>对传统大公司的冲击</h2><p>这些新模式对传统大公司意味着什么？</p><p><strong>首先，竞争对手变多了。</strong> 以前只有大公司才能做的产品，现在小团队也能做。而且小团队更快、更灵活、更敢冒险。大公司花一年做的功能，小团队可能两个月就做出来了。</p><p><strong>其次，人才流失加速。</strong> 最优秀的人才发现，自己加上 AI 就能创造巨大价值，为什么要待在大公司里开会、写周报、等审批？超级个体和小团队模式对顶尖人才的吸引力越来越大。</p><p><strong>第三，组织臃肿的代价更高了。</strong> 以前大公司的效率低一点没关系，因为竞争对手也差不多。现在不一样了——你的竞争对手可能是一个三人团队，他们的决策速度是你的十倍，迭代速度是你的五倍。</p><p>这不是说大公司会消失。大公司有自己的优势：品牌、渠道、数据、资金、合规能力。但大公司需要变革——<strong>要么变小，要么变快，要么做小公司做不了的事。</strong></p><p><img src="/images/ai-leverage.png" alt="AI 杠杆效应"></p><h2 id="新的竞争壁垒"><a href="#新的竞争壁垒" class="headerlink" title="新的竞争壁垒"></a>新的竞争壁垒</h2><p>在新模式下，竞争壁垒也在变化。</p><p><strong>以前的壁垒：</strong> 人多、钱多、技术积累深。你有一千个工程师，别人追不上你。</p><p><strong>现在的壁垒：</strong></p><ul><li><strong>数据飞轮。</strong> 谁的产品有更多用户、产生更多数据、训练出更好的模型，谁就有壁垒。</li><li><strong>AI 使用效率。</strong> 同样用 AI，有人能把效率提升 10 倍，有人只能提升 2 倍。差距在于对 AI 能力边界的理解和工作流的设计。</li><li><strong>速度。</strong> 在 AI 时代，速度就是壁垒。你比别人快两周上线，就能先抢到用户和反馈数据。</li><li><strong>品味和判断力。</strong> 当 AI 把执行成本降到极低，决定胜负的是”做什么”而不是”怎么做”。产品品味、战略判断力变得比以往任何时候都重要。</li><li><strong>信任和品牌。</strong> AI 能帮你做产品，但不能帮你建立信任。用户选择你而不是竞争对手，越来越取决于品牌和口碑。</li></ul><h2 id="未来的公司长什么样"><a href="#未来的公司长什么样" class="headerlink" title="未来的公司长什么样"></a>未来的公司长什么样</h2><p>如果把这些趋势推演下去，未来的公司可能长这样：</p><p><strong>大多数公司会变小。</strong> 不是因为做的事变少了，而是因为同样的事需要的人变少了。一个 50 人的公司可能缩到 15 人，产出不变甚至更高。</p><p><strong>组织结构会更扁平。</strong> 中间管理层会被压缩。当每个人都能独立做决策、AI 能处理大量协调工作时，层级就没有存在的必要了。</p><p><strong>全职员工和外部协作者的边界会模糊。</strong> 核心团队 + 动态外部网络会成为常态。</p><p><strong>AI 会成为”员工”。</strong> 不是比喻，是字面意思。公司会有 AI Agent 负责客服、数据分析、内容生产、代码审查。这些 Agent 有自己的”工位”（运行环境）、”权限”（API access）、”考核”（质量监控）。</p><p><strong>创业门槛会大幅降低。</strong> 一个有想法的人，不需要融资、不需要招人，就能做出一个有竞争力的产品。这意味着创业的数量会爆发，但成功的标准也会提高——因为竞争更激烈了。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>每次技术革命都会重塑组织形式。</p><p>工业革命催生了工厂和流水线。信息革命催生了互联网公司和远程办公。AI 革命正在催生新的公司模式——更小、更快、更灵活，AI 深度嵌入每个环节。</p><p>这对个人来说，既是机会也是挑战。机会在于：你不再需要一个大团队才能做大事。挑战在于：如果你不学会和 AI 协作，你的竞争力会快速下降。</p><p>我的判断是：<strong>未来五年，”会用 AI”会像”会用电脑”一样，从加分项变成基本功。</strong> 不是你要不要学的问题，而是你什么时候开始学的问题。</p><p>而那些最早拥抱新模式的人和公司，会拿到最大的红利。</p><p>就像每次技术革命一样——先知先觉者吃肉，后知后觉者喝汤，不知不觉者买单。</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/ai-company-model/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/ai-company-model/"/>
    <published>2026-02-28T15:00:00.000Z</published>
    <summary>当一个人加上 AI 就能干过一个团队，公司这种组织形式会变成什么样？</summary>
    <title>AI 时代的新公司模式</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Thoughts" scheme="https://xiaoxiaduoyan.com/tags/Thoughts/"/>
    <category term="English" scheme="https://xiaoxiaduoyan.com/tags/English/"/>
    <category term="Infrastructure" scheme="https://xiaoxiaduoyan.com/tags/Infrastructure/"/>
    <content>
      <![CDATA[<h2 id="The-Road-Builders"><a href="#The-Road-Builders" class="headerlink" title="The Road Builders"></a>The Road Builders</h2><p>There’s a saying I grew up hearing: if you want to get rich, build roads first.</p><p>This applies to technology just as well. Every technological revolution is preceded by massive infrastructure buildout. The steam age built railways. The electrical age strung power grids. The internet age laid fiber optic cables and erected data centers. Infrastructure isn’t glamorous, but without it, even the best technology can’t run.</p><p>Now it’s AI’s turn.</p><p>Since GPT came along, everyone’s been talking about how smart the models are and what they can do. But few people seriously discuss: <strong>what roads do we need to build to make AI actually work?</strong></p><p>That’s what this article is about — what AI-era infrastructure actually looks like.</p><h2 id="Compute-The-Most-Visible-Layer"><a href="#Compute-The-Most-Visible-Layer" class="headerlink" title="Compute: The Most Visible Layer"></a>Compute: The Most Visible Layer</h2><p>When people think of AI infrastructure, GPUs come to mind first. And yes, compute is the most visible and expensive layer. NVIDIA’s market cap tells the story.</p><p>But the compute story is far more complex than “buy more cards.”</p><p>Training a large model requires thousands of GPUs working in concert for months. Behind this lies distributed computing, high-speed interconnects (InfiniBand&#x2F;NVLink), large-scale cluster scheduling, fault recovery… each one a hardcore engineering challenge. How many failures OpenAI’s cluster experienced during GPT-4 training, how many checkpoint recoveries they performed — outsiders can barely imagine.</p><p>The inference side presents entirely different challenges. Training is a one-time cost (albeit expensive), but inference is continuous — every user’s every conversation consumes compute. When your product has hundreds of millions of users, inference cost is the real heavyweight. That’s why everyone’s racing on inference optimization: quantization, distillation, speculative decoding, KV cache optimization…</p><p><strong>But compute is just the tip of the iceberg.</strong> Just as the internet era needed more than servers — it needed CDNs, load balancers, databases — the AI era needs far more than GPUs.</p><h2 id="Data-Scarcer-Than-Compute"><a href="#Data-Scarcer-Than-Compute" class="headerlink" title="Data: Scarcer Than Compute"></a>Data: Scarcer Than Compute</h2><p>There’s a pattern that’s been validated repeatedly: <strong>data quality determines a model’s ceiling; compute only determines how fast you approach it.</strong></p><p>Public text on the internet has been scraped nearly dry. Every model company is struggling for high-quality data. You see seemingly absurd news — one company buying an entire publisher’s catalog, another hiring tens of thousands of annotators, another using its own model to generate synthetic training data.</p><p>Data infrastructure has several layers:</p><p><strong>Collection and cleaning.</strong> Raw data is dirty, duplicated, biased. Turning it into usable training data requires an entire pipeline: deduplication, filtering, anonymization, formatting. This work isn’t glamorous, but it determines a model’s character.</p><p><strong>Annotation and alignment.</strong> RLHF (Reinforcement Learning from Human Feedback) requires massive amounts of high-quality human preference data. Annotator quality directly affects a model’s “values.” This is a labor-intensive step and the most easily underestimated one.</p><p><strong>Data flywheels.</strong> The truly powerful companies don’t just solve data once — they build data flywheels. Users generate data through the product, data improves the model, the model improves the product, the product attracts more users. ChatGPT’s data flywheel is already spinning, and this is the hardest moat for newcomers to cross.</p><h2 id="Model-Serving-From-Lab-to-Production"><a href="#Model-Serving-From-Lab-to-Production" class="headerlink" title="Model Serving: From Lab to Production"></a>Model Serving: From Lab to Production</h2><p>Training a good model is just the beginning. Turning it into a stable, efficient, scalable service is another massive engineering effort.</p><p><img src="/images/ai-infra-layers.png" alt="AI Infrastructure Layer Architecture"></p><p>Several key challenges here:</p><p><strong>Inference engines.</strong> vLLM, TensorRT-LLM, SGLang… these frameworks make the same GPUs serve more requests. Continuous batching, PagedAttention, speculative decoding — each optimization can multiply throughput several times over.</p><p><strong>Model routing.</strong> Not every request needs the largest model. Answering a simple greeting with GPT-4 is wasteful. Smart routing systems dispatch requests to appropriate models based on complexity — simple ones to small models, complex ones to large models. Saves money and improves speed.</p><p><strong>Caching and precomputation.</strong> Many requests are similar. Semantic caching can return answers for similar questions directly, skipping inference. Prompt prefix caching can reuse KV caches, reducing redundant computation.</p><p><strong>Observability.</strong> Models aren’t deterministic systems — the same input can produce different outputs. You need to monitor latency, throughput, error rates, and also output quality — hallucinations, harmful content, deviation from expectations. This is far more complex than traditional APM.</p><h2 id="Agent-Infrastructure-The-Underestimated-New-Frontier"><a href="#Agent-Infrastructure-The-Underestimated-New-Frontier" class="headerlink" title="Agent Infrastructure: The Underestimated New Frontier"></a>Agent Infrastructure: The Underestimated New Frontier</h2><p>If large models are the AI era’s “engines,” then Agents are the “vehicles.” And Agents need their own infrastructure to run.</p><p><strong>Memory systems.</strong> I discussed this in detail in my previous article. Agents need short-term memory (current conversation), working memory (current task context), and long-term memory (user preferences and historical knowledge). Most Agent memory systems today are primitive — either stuffing everything into the context window or using RAG retrieval. The future demands more elegant memory architectures.</p><p><strong>Tool ecosystems.</strong> An Agent’s capabilities depend on what tools it can invoke. Browsers, code executors, file systems, API calls… each tool needs standardized interfaces, permission controls, error handling. MCP (Model Context Protocol) is attempting to solve this, but it’s still very early.</p><p><strong>Orchestration frameworks.</strong> Complex tasks require multiple Agents collaborating, or a single Agent executing multi-step workflows. LangChain, CrewAI, AutoGen are all working on this, but honestly, current orchestration frameworks are still rough. The real challenge isn’t “how to chain things together” but “what happens when things go wrong” — retry, rollback, human intervention, partial recovery. Problems already solved in traditional workflow engines need to be re-solved in the Agent domain.</p><p><strong>Sandboxing and security.</strong> Agents can execute code, access file systems, operate browsers — meaning they have the power to cause damage. You need sandboxes to limit their capabilities, audit logs to track their actions, human approval mechanisms to intercept high-risk operations.</p><h2 id="Evaluation-AI’s-Quality-Control-System"><a href="#Evaluation-AI’s-Quality-Control-System" class="headerlink" title="Evaluation: AI’s Quality Control System"></a>Evaluation: AI’s Quality Control System</h2><p>Traditional software has unit tests, integration tests, stress tests. Evaluating AI systems is much harder because outputs are non-deterministic and the definition of “correct” itself is fuzzy.</p><p>But without an evaluation system, you’re flying blind.</p><p><strong>Benchmarks.</strong> MMLU, HumanEval, GSM8K… these public benchmarks are useful but limited — models might score well on benchmarks while performing poorly in real scenarios.</p><p><strong>Domain evaluation.</strong> Every specific application needs its own evaluation set. Building a customer service bot? Evaluate with real customer service conversations. Building a code assistant? Evaluate with real coding tasks. Building high-quality domain evaluation sets is itself an infrastructure effort.</p><p><strong>Online evaluation.</strong> A&#x2F;B testing, user satisfaction, task completion rates… these metrics need continuous collection in production. And you need to distinguish between “the model got better” and “the prompt got better” and “the users changed” — far more complex than traditional A&#x2F;B testing.</p><p><strong>Red teaming.</strong> Specifically hunting for model vulnerabilities — can it be tricked into producing harmful content, can safety restrictions be bypassed, will it leak training data. This is an adversarial process requiring dedicated teams and tools.</p><h2 id="Developer-Perspective-A-New-Development-Paradigm"><a href="#Developer-Perspective-A-New-Development-Paradigm" class="headerlink" title="Developer Perspective: A New Development Paradigm"></a>Developer Perspective: A New Development Paradigm</h2><p><img src="/images/ai-infra-evolution.png" alt="Infrastructure Evolution Timeline"></p><p>As a developer, what I feel most deeply is: <strong>AI is changing the act of “writing code” itself.</strong></p><p>The old development paradigm: write code → compile → test → deploy. Now there’s an additional dimension: <strong>write prompt → call model → evaluate → iterate.</strong> This isn’t replacement but addition. Your system has both deterministic code logic and non-deterministic model calls, and they need to work together.</p><p>This creates new infrastructure needs:</p><p><strong>Prompt management.</strong> Prompts are the new era’s “code” — they need version control, A&#x2F;B testing, gradual rollout. But most teams still hardcode prompts, requiring a full deployment to change one.</p><p><strong>Model gateways.</strong> Your application might call multiple model providers simultaneously — OpenAI, Anthropic, locally deployed open-source models. You need a unified gateway to manage API keys, load balance, handle degradation, control costs.</p><p><strong>Development tools.</strong> AI assistants in IDEs (Copilot, Cursor) are just the beginning. Future development tools will deeply integrate AI — not just code completion, but understanding your entire project, helping with architecture decisions, automatically writing tests, automatically doing code review.</p><p><strong>Cost management.</strong> AI calls are billed per token, and prices vary enormously — GPT-4 costs dozens of times more than GPT-3.5. You need to monitor AI costs per feature, set budgets, find the balance between quality and cost.</p><h2 id="The-Endgame-AI-Like-Water-and-Electricity"><a href="#The-Endgame-AI-Like-Water-and-Electricity" class="headerlink" title="The Endgame: AI Like Water and Electricity"></a>The Endgame: AI Like Water and Electricity</h2><p>Back to the original analogy.</p><p>When electricity first appeared, every factory built its own power station. Then came the power grid, and electricity became a public utility — you didn’t need to know how it was generated, just plug in and go.</p><p>The internet went through a similar process. From self-hosted servers to colocation, to cloud computing, to serverless — abstraction layers kept rising, and developers needed to worry about fewer and fewer low-level details.</p><p><strong>The endgame of AI infrastructure should be the same.</strong></p><p>Developers shouldn’t need to worry about GPU scheduling, model deployment, inference optimization. They should just say “I need a natural language understanding interface” or “I need an image analysis capability,” and the infrastructure layer handles everything automatically.</p><p>We’re still in the “build your own power station” phase. Every company is setting up their own GPU clusters, training their own models, building their own inference services. This is normal — early stages of new technology are always like this. But the trend is clear: <strong>standardization, service-ification, democratization.</strong></p><p>In the next five years, AI infrastructure will undergo rapid standardization. Just as AWS defined the basic shape of cloud computing, some company will define the basic shape of AI infrastructure. By then, “using AI” will be as natural as “using a database” — you won’t need to be an AI expert to leverage AI capabilities in your product.</p><h2 id="Final-Thoughts"><a href="#Final-Thoughts" class="headerlink" title="Final Thoughts"></a>Final Thoughts</h2><p>Every era’s infrastructure is unglamorous. Road builders aren’t as flashy as train riders. Data center builders aren’t as famous as app makers. But without them, trains can’t run and apps can’t load.</p><p>The AI era is the same. The spotlight falls on models and applications, but what truly determines how far this era goes is the unglamorous infrastructure underneath — data pipelines, inference engines, Agent frameworks, evaluation systems, development tools.</p><p><strong>If you want to get rich, build roads first. This remains true in the AI era.</strong></p><p>If you’re a developer, my advice is: don’t just chase model hype. Look at what’s happening in the infrastructure layer. That’s where the more durable opportunities and more solid value lie.</p><p>After all, when the tide goes out, what remains is infrastructure.</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/ai-infrastructure-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/ai-infrastructure-en/"/>
    <published>2026-02-28T14:00:00.000Z</published>
    <summary>Every era has its own infrastructure. Railways, power grids, fiber optics... In the AI era, what roads do we need to build?</summary>
    <title>The Infrastructure of the AI Era</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <category term="基础设施" scheme="https://xiaoxiaduoyan.com/tags/%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    <content>
      <![CDATA[<h2 id="修路的人"><a href="#修路的人" class="headerlink" title="修路的人"></a>修路的人</h2><p>小时候听过一句话：要想富，先修路。</p><p>这话放到技术领域同样成立。每一次技术革命的爆发，背后都有一轮大规模的基础设施建设。蒸汽机时代修铁路，电气时代架电网，互联网时代铺光纤建数据中心。基建不性感，但没有它，再好的技术也跑不起来。</p><p>现在轮到 AI 了。</p><p>GPT 出来之后，所有人都在聊模型多聪明、能干什么。但很少有人认真聊过：<strong>要让 AI 真正跑起来，我们需要修什么路？</strong></p><p>这篇文章想聊的就是这件事——AI 时代的基建，到底长什么样。</p><h2 id="算力：最显眼的那一层"><a href="#算力：最显眼的那一层" class="headerlink" title="算力：最显眼的那一层"></a>算力：最显眼的那一层</h2><p>提到 AI 基建，大多数人第一反应是 GPU。没错，算力是最显眼、最烧钱的一层。英伟达的市值说明了一切。</p><p>但算力的故事远不止”买更多卡”这么简单。</p><p>训练一个大模型需要几千张 GPU 协同工作几个月，这背后是分布式计算、高速互联网络（InfiniBand&#x2F;NVLink）、大规模集群调度、故障恢复……每一项都是硬核工程。OpenAI 训练 GPT-4 的集群出过多少次故障、做了多少次 checkpoint 恢复，外面的人很难想象。</p><p>而推理侧的挑战又完全不同。训练是一次性的（虽然很贵），但推理是持续的——每个用户的每次对话都在消耗算力。当你的产品有几亿用户时，推理成本才是真正的大头。所以你看到各家都在卷推理优化：量化、蒸馏、投机解码、KV Cache 优化……</p><p><strong>但算力只是冰山一角。</strong> 就像互联网时代光有服务器不够，还需要 CDN、负载均衡、数据库一样，AI 时代光有 GPU 也远远不够。</p><h2 id="数据：比算力更稀缺的资源"><a href="#数据：比算力更稀缺的资源" class="headerlink" title="数据：比算力更稀缺的资源"></a>数据：比算力更稀缺的资源</h2><p>有一个被反复验证的规律：<strong>数据的质量决定了模型的上限，算力只决定你能多快逼近这个上限。</strong></p><p>互联网上的公开文本已经被刮得差不多了。各家模型公司都在为高质量数据发愁。你会看到一些看似荒诞的新闻——某公司花大价钱买下了一整个出版社的版权，某公司雇了几万人做数据标注，某公司用自己的模型生成合成数据再拿来训练。</p><p>数据基建包含几个层面：</p><p><strong>采集和清洗。</strong> 原始数据是脏的、重复的、有偏见的。把它变成可用的训练数据，需要一整套 pipeline：去重、过滤、脱敏、格式化。这些工作不光彩，但决定了模型的底色。</p><p><strong>标注和对齐。</strong> RLHF（基于人类反馈的强化学习）需要大量高质量的人类偏好数据。标注员的水平直接影响模型的”三观”。这是一个劳动密集型的环节，也是最容易被低估的环节。</p><p><strong>数据飞轮。</strong> 真正厉害的公司不是一次性搞定数据，而是建立了数据飞轮——用户使用产品产生数据，数据反哺模型，模型改善产品，产品吸引更多用户。ChatGPT 的数据飞轮已经转起来了，这是后来者最难追赶的壁垒。</p><h2 id="模型服务：从实验室到生产环境"><a href="#模型服务：从实验室到生产环境" class="headerlink" title="模型服务：从实验室到生产环境"></a>模型服务：从实验室到生产环境</h2><p>训练出一个好模型只是开始。把它变成一个稳定、高效、可扩展的服务，又是另一个巨大的工程。</p><p><img src="/images/ai-infra-layers.png" alt="AI 基建层次架构"></p><p>这里面有几个关键问题：</p><p><strong>推理引擎。</strong> vLLM、TensorRT-LLM、SGLang……这些推理框架做的事情是：让同样的 GPU 能服务更多的请求。Continuous batching、PagedAttention、Speculative decoding——每一个优化都能带来几倍的吞吐提升。</p><p><strong>模型路由。</strong> 不是所有请求都需要最大的模型。一个简单的问候用 GPT-4 回答是浪费。智能路由系统根据请求的复杂度，把它分发到合适的模型——简单的用小模型，复杂的用大模型，既省钱又快。</p><p><strong>缓存和预计算。</strong> 很多请求是相似的。语义缓存可以把相似问题的答案直接返回，省掉推理开销。Prompt 前缀缓存可以复用 KV Cache，减少重复计算。</p><p><strong>可观测性。</strong> 模型不是确定性系统，同样的输入可能给出不同的输出。你需要监控延迟、吞吐、错误率，还需要监控输出质量——有没有幻觉、有没有有害内容、有没有偏离预期。这比传统的 APM 复杂得多。</p><h2 id="Agent-基础设施：被低估的新战场"><a href="#Agent-基础设施：被低估的新战场" class="headerlink" title="Agent 基础设施：被低估的新战场"></a>Agent 基础设施：被低估的新战场</h2><p>如果说大模型是 AI 时代的”发动机”，那 Agent 就是”整车”。而 Agent 要跑起来，需要自己的一套基建。</p><p><strong>记忆系统。</strong> 我在上一篇文章里详细聊过这个。Agent 需要短期记忆（当前对话）、工作记忆（当前任务上下文）、长期记忆（用户偏好和历史知识）。现在大多数 Agent 的记忆还很原始——要么全塞进 context window，要么用 RAG 检索。未来需要更优雅的记忆架构。</p><p><strong>工具生态。</strong> Agent 的能力取决于它能调用什么工具。浏览器、代码执行器、文件系统、API 调用……每一个工具都需要标准化的接口、权限控制、错误处理。MCP（Model Context Protocol）在尝试解决这个问题，但还很早期。</p><p><strong>编排框架。</strong> 复杂任务需要多个 Agent 协作，或者一个 Agent 执行多步骤的工作流。LangChain、CrewAI、AutoGen 都在做这件事，但说实话，现在的编排框架还很粗糙。真正的挑战不是”怎么串起来”，而是”出错了怎么办”——重试、回滚、人工介入、部分恢复，这些在传统工作流引擎里已经解决的问题，在 Agent 领域还需要重新解决。</p><p><strong>沙箱和安全。</strong> Agent 能执行代码、访问文件系统、操作浏览器——这意味着它有能力搞破坏。你需要沙箱来限制它的能力边界，需要审计日志来追踪它做了什么，需要人工审批机制来拦截高风险操作。</p><h2 id="评估：AI-的”质检体系”"><a href="#评估：AI-的”质检体系”" class="headerlink" title="评估：AI 的”质检体系”"></a>评估：AI 的”质检体系”</h2><p>传统软件有单元测试、集成测试、压力测试。AI 系统的评估要难得多，因为输出是非确定性的，”正确”的定义本身就模糊。</p><p>但没有评估体系，你就是在盲人摸象。</p><p><strong>基准测试。</strong> MMLU、HumanEval、GSM8K……这些公开 benchmark 有用，但也有局限——模型可能在 benchmark 上刷分，在实际场景中拉胯。</p><p><strong>领域评估。</strong> 每个具体应用都需要自己的评估集。你做客服机器人，就需要用真实的客服对话来评估；你做代码助手，就需要用真实的代码任务来评估。构建高质量的领域评估集，本身就是一项基建工作。</p><p><strong>在线评估。</strong> A&#x2F;B 测试、用户满意度、任务完成率……这些指标需要在生产环境中持续收集。而且你需要区分”模型变好了”和”prompt 变好了”和”用户变了”——这比传统的 A&#x2F;B 测试复杂得多。</p><p><strong>红队测试。</strong> 专门找模型的漏洞——能不能被诱导说出有害内容、能不能被绕过安全限制、会不会泄露训练数据。这是一个攻防对抗的过程，需要专门的团队和工具。</p><h2 id="开发者视角：新时代的开发范式"><a href="#开发者视角：新时代的开发范式" class="headerlink" title="开发者视角：新时代的开发范式"></a>开发者视角：新时代的开发范式</h2><p><img src="/images/ai-infra-evolution.png" alt="基建演进时间线"></p><p>作为一个开发者，我感受最深的是：<strong>AI 正在改变”写代码”这件事本身。</strong></p><p>以前的开发范式是：写代码 → 编译 → 测试 → 部署。现在多了一个维度：<strong>写 prompt → 调模型 → 评估 → 迭代。</strong> 这不是替代，而是叠加。你的系统里既有确定性的代码逻辑，也有非确定性的模型调用，两者需要协同工作。</p><p>这带来了新的基建需求：</p><p><strong>Prompt 管理。</strong> Prompt 是新时代的”代码”，需要版本控制、A&#x2F;B 测试、灰度发布。但现在大多数团队还是把 prompt 硬编码在代码里，改一个 prompt 要发一次版。</p><p><strong>模型网关。</strong> 你的应用可能同时调用多个模型提供商——OpenAI、Anthropic、本地部署的开源模型。你需要一个统一的网关来管理 API key、做负载均衡、处理降级、控制成本。</p><p><strong>开发工具。</strong> IDE 里的 AI 助手（Copilot、Cursor）只是开始。未来的开发工具会深度集成 AI——不只是补全代码，而是理解你的整个项目、帮你做架构决策、自动写测试、自动做 code review。</p><p><strong>成本管理。</strong> AI 调用是按 token 计费的，而且价格差异巨大——GPT-4 的价格是 GPT-3.5 的几十倍。你需要监控每个功能的 AI 成本，做预算控制，在质量和成本之间找平衡。</p><h2 id="终局：像水电一样的-AI"><a href="#终局：像水电一样的-AI" class="headerlink" title="终局：像水电一样的 AI"></a>终局：像水电一样的 AI</h2><p>回到最开始的类比。</p><p>电力刚出现的时候，每个工厂都自己建发电站。后来有了电网，电变成了公共服务——你不需要知道电是怎么发的，插上插头就能用。</p><p>互联网也经历了类似的过程。从自建机房到托管，到云计算，到 Serverless——抽象层越来越高，开发者需要关心的底层细节越来越少。</p><p><strong>AI 基建的终局，也应该是这样。</strong></p><p>开发者不需要关心 GPU 调度、模型部署、推理优化。他只需要说”我需要一个能理解自然语言的接口”或者”我需要一个能分析图片的能力”，基建层自动搞定一切。</p><p>我们现在还在”自建发电站”的阶段。各家公司都在自己搭 GPU 集群、自己训模型、自己建推理服务。这很正常——新技术的早期总是这样。但趋势是清晰的：<strong>标准化、服务化、平民化。</strong></p><p>未来五年，AI 基建会经历一轮快速的标准化。就像 AWS 定义了云计算的基本形态一样，会有公司定义 AI 基建的基本形态。到那时候，”用 AI”会像”用数据库”一样自然——你不需要成为 AI 专家，就能在你的产品里用上 AI 能力。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>每个时代的基建都不性感。修铁路的人不如坐火车的人光鲜，建数据中心的人不如做 App 的人出名。但没有他们，火车跑不起来，App 也打不开。</p><p>AI 时代也一样。聚光灯打在模型和应用上，但真正决定这个时代能走多远的，是底下那些不起眼的基建——数据管道、推理引擎、Agent 框架、评估体系、开发工具。</p><p><strong>要想富，先修路。这句话，在 AI 时代依然成立。</strong></p><p>如果你是一个开发者，我的建议是：不要只追模型的热点，也看看基建层在发生什么。那里有更持久的机会，也有更扎实的价值。</p><p>毕竟，潮水退去之后，留下来的是基础设施。</p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/ai-infrastructure/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/ai-infrastructure/"/>
    <published>2026-02-28T14:00:00.000Z</published>
    <summary>每个时代都有自己的基建。铁路、电网、光纤……到了 AI 时代，我们需要修的&quot;路&quot;是什么？</summary>
    <title>AI 时代的基建</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Agent" scheme="https://xiaoxiaduoyan.com/tags/Agent/"/>
    <category term="Thoughts" scheme="https://xiaoxiaduoyan.com/tags/Thoughts/"/>
    <category term="Writing" scheme="https://xiaoxiaduoyan.com/tags/Writing/"/>
    <category term="English" scheme="https://xiaoxiaduoyan.com/tags/English/"/>
    <content>
      <![CDATA[<h2 id="An-Assistant-That-Talks-But-Doesn’t-Do"><a href="#An-Assistant-That-Talks-But-Doesn’t-Do" class="headerlink" title="An Assistant That Talks But Doesn’t Do"></a>An Assistant That Talks But Doesn’t Do</h2><p>Have you ever been in this situation: you ask an AI a question, it gives you a perfect answer, but you have to execute every single step yourself.</p><p>“Fix this bug for me.”</p><p>It tells you: open this file, find line 42, change <code>foo</code> to <code>bar</code>, then run <code>npm test</code> to verify.</p><p>Sounds great. But it doesn’t lift a finger.</p><p>It’s like hiring a consultant who sits next to you pointing at the screen but never touches the keyboard. You open the editor, find the line, make the change, run the test, check the result, then report back: “Done, but the test still fails.” Then it gives you the next suggestion.</p><p><strong>After a few rounds of this, you start thinking: can’t you just do it yourself?</strong></p><p>That’s why Agents need “eyes” and “hands” — not just language ability, but the ability to perceive the world and change it.</p><h2 id="Eyes-Letting-Agents-See-the-World"><a href="#Eyes-Letting-Agents-See-the-World" class="headerlink" title="Eyes: Letting Agents See the World"></a>Eyes: Letting Agents See the World</h2><p>An Agent without perception is like a blindfolded person. You have to constantly narrate the surroundings for it to give advice. Extremely inefficient, and the information you describe is always lossy.</p><h3 id="The-Browser-Is-the-Agent’s-Eyes"><a href="#The-Browser-Is-the-Agent’s-Eyes" class="headerlink" title="The Browser Is the Agent’s Eyes"></a>The Browser Is the Agent’s Eyes</h3><p>In my recent practice, I connected an Agent to a browser tool. What can it do?</p><ul><li><strong>Open web pages</strong>: Visit URLs directly, see page content</li><li><strong>Get snapshots</strong>: Obtain the page’s accessibility tree — a structured description far more AI-friendly than screenshots</li><li><strong>Take screenshots</strong>: When visual judgment is needed, capture the screen directly</li><li><strong>Execute JavaScript</strong>: Run code in the page context to get DOM info or trigger actions</li></ul><p>The most critical one here is <strong>Snapshot</strong>.</p><p><img src="/images/agent-perception.png" alt="Agent Perception Architecture"></p><p>Many people’s first instinct is to give the Agent a screenshot and let a multimodal model “see” the image. That works, but it’s inefficient — a single screenshot might consume thousands of tokens, and the model’s accuracy at extracting structured information from images is far lower than reading structured data directly.</p><p>The accessibility tree is maintained by the browser for accessibility features. It describes every interactive element’s role, name, and state. For an Agent, this is a “semantic map” — it doesn’t need to know what color a button is or where it sits on screen. It just needs to know “there’s a button called ‘Submit’ with ref e42.”</p><p><strong>Snapshots are AI-friendly. Screenshots are human-friendly.</strong> Give Agents snapshots, show humans screenshots.</p><h3 id="Beyond-the-Browser"><a href="#Beyond-the-Browser" class="headerlink" title="Beyond the Browser"></a>Beyond the Browser</h3><p>Eyes aren’t just browsers. An Agent’s perception can extend across many dimensions:</p><ul><li><strong>File system</strong>: Read code files, config files, log files</li><li><strong>Terminal output</strong>: See stdout and stderr after executing commands</li><li><strong>API responses</strong>: Parse return data after calling interfaces</li><li><strong>Git status</strong>: Know the current branch, uncommitted changes, recent commits</li></ul><p>Each perception channel tells the Agent: <strong>what the world looks like right now.</strong></p><h2 id="Hands-Letting-Agents-Change-the-World"><a href="#Hands-Letting-Agents-Change-the-World" class="headerlink" title="Hands: Letting Agents Change the World"></a>Hands: Letting Agents Change the World</h2><p>Seeing isn’t enough. They need to act.</p><h3 id="Script-Execution-Is-the-Most-Universal-“Hand”"><a href="#Script-Execution-Is-the-Most-Universal-“Hand”" class="headerlink" title="Script Execution Is the Most Universal “Hand”"></a>Script Execution Is the Most Universal “Hand”</h3><p>If I could give an Agent only one action capability, I’d choose <strong>shell script execution</strong>.</p><p>Why? Because shell is the universal glue. You can use it to:</p><ul><li>Create, modify, delete files</li><li>Install dependencies, run builds, execute tests</li><li>Call APIs, download resources, process data</li><li>Manage Git, deploy code, handle processes</li></ul><p>An Agent that can execute shell scripts can theoretically do anything a programmer can do.</p><h3 id="But-Coarse-Grained-Isn’t-Enough"><a href="#But-Coarse-Grained-Isn’t-Enough" class="headerlink" title="But Coarse-Grained Isn’t Enough"></a>But Coarse-Grained Isn’t Enough</h3><p>Pure shell has a problem: it’s too low-level. Having an Agent use <code>sed</code> for text replacement often goes wrong due to escape characters and regex edge cases.</p><p>So the better approach is to provide <strong>multi-layered action capabilities</strong>:</p><table><thead><tr><th>Layer</th><th>Tool</th><th>Use Case</th></tr></thead><tbody><tr><td><strong>Fine-grained</strong></td><td>File read&#x2F;write, search &amp; replace</td><td>Modify code, update configs</td></tr><tr><td><strong>Medium</strong></td><td>Browser interaction (click, fill, navigate)</td><td>Web operations, visual verification</td></tr><tr><td><strong>Coarse-grained</strong></td><td>Shell scripts</td><td>Build, deploy, system admin</td></tr></tbody></table><p>Fine-grained operations reduce error rates. Coarse-grained operations ensure flexibility. Combined, the Agent can be both stable and fast.</p><h3 id="A-Real-Example"><a href="#A-Real-Example" class="headerlink" title="A Real Example"></a>A Real Example</h3><p>When I had an Agent help me build this blog, its “hands” collaborated like this:</p><ol><li><strong>Write files</strong> (fine-grained): Create Markdown articles, modify config files</li><li><strong>Execute scripts</strong> (coarse-grained): <code>hexo generate</code> to build, <code>git push</code> to deploy</li><li><strong>Browser operations</strong> (medium): Open the deployed page, check rendering</li><li><strong>Search &amp; replace</strong> (fine-grained): Found a CSS issue, precisely modified the stylesheet</li></ol><p>The entire workflow ran on its own. I just refreshed the page at the end to see the result.</p><h2 id="Eye-Hand-Coordination-The-Perception-Decision-Action-Loop"><a href="#Eye-Hand-Coordination-The-Perception-Decision-Action-Loop" class="headerlink" title="Eye-Hand Coordination: The Perception-Decision-Action Loop"></a>Eye-Hand Coordination: The Perception-Decision-Action Loop</h2><p>Eyes and hands alone are meaningless. The key is forming a <strong>closed loop</strong>.</p><p><img src="/images/agent-loop.png" alt="Perception-Decision-Action Loop"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Perceive (what do I see?) → Decide (what should I do?) → Act (do it) → Perceive (did the world change?) → ...</span><br></pre></td></tr></table></figure><p>This loop sounds simple, but implementation has many nuances:</p><h3 id="1-Always-Verify-After-Acting"><a href="#1-Always-Verify-After-Acting" class="headerlink" title="1. Always Verify After Acting"></a>1. Always Verify After Acting</h3><p>After an Agent executes an operation, it can’t just assume success. It needs to <strong>look back</strong>:</p><ul><li>Changed code? Run the tests.</li><li>Deployed a website? Open the browser and check.</li><li>Installed dependencies? Verify <code>node_modules</code> exists.</li></ul><p><strong>Unverified actions are dangerous.</strong> It’s like crossing the street with your eyes closed — you took the step, but you don’t know if there’s a car coming.</p><h3 id="2-Errors-Are-Information-Not-Dead-Ends"><a href="#2-Errors-Are-Information-Not-Dead-Ends" class="headerlink" title="2. Errors Are Information, Not Dead Ends"></a>2. Errors Are Information, Not Dead Ends</h3><p>When an Agent’s script throws an error, the error message itself is the most valuable perception input. A good Agent will:</p><ul><li>Read the error message</li><li>Analyze the cause</li><li>Adjust the approach</li><li>Re-execute</li></ul><p>Rather than just telling you “execution failed, please handle manually.”</p><h3 id="3-Know-When-to-Stop"><a href="#3-Know-When-to-Stop" class="headerlink" title="3. Know When to Stop"></a>3. Know When to Stop</h3><p>The loop can’t spin forever. The Agent needs to judge:</p><ul><li>Is the task complete?</li><li>Am I stuck in an infinite loop?</li><li>Should I ask the user for confirmation?</li></ul><p>This is a kind of <strong>metacognition</strong> — not just doing things, but knowing what you’re doing and how well you’re doing it.</p><h2 id="Current-Limitations"><a href="#Current-Limitations" class="headerlink" title="Current Limitations"></a>Current Limitations</h2><p>Having talked about the benefits, let’s discuss the real-world pitfalls.</p><h3 id="Blurry-Security-Boundaries"><a href="#Blurry-Security-Boundaries" class="headerlink" title="Blurry Security Boundaries"></a>Blurry Security Boundaries</h3><p>An Agent that can execute shell scripts can theoretically <code>rm -rf /</code>. While no sane Agent would do this, <strong>permission control</strong> is a problem that must be taken seriously.</p><p>Current approaches typically include:</p><ul><li>Restricting the working directory</li><li>Blocking dangerous commands</li><li>Requiring human confirmation for critical operations</li></ul><p>But these are all patches. A more fundamental solution might be <strong>sandboxed execution environments</strong> — the Agent operates in an isolated container, so even mistakes don’t affect the host system.</p><h3 id="Limited-Perception-Bandwidth"><a href="#Limited-Perception-Bandwidth" class="headerlink" title="Limited Perception Bandwidth"></a>Limited Perception Bandwidth</h3><p>Even with browsers and file systems, an Agent’s perception bandwidth is still far below a human’s. A human can instantly see “this page layout is wrong.” An Agent needs to parse the entire DOM tree to reach a similar conclusion.</p><p><strong>Multimodal models are improving, but they’re not at the “glance and understand” level yet.</strong> The current best practice is combining structured perception (snapshots) with visual perception (screenshots).</p><h3 id="Context-Loss-in-Long-Tasks"><a href="#Context-Loss-in-Long-Tasks" class="headerlink" title="Context Loss in Long Tasks"></a>Context Loss in Long Tasks</h3><p>A complex task might require dozens of steps. As steps accumulate, early perception information gets pushed out of the context window. The Agent might forget what it saw three steps ago.</p><p>This circles back to memory management — what the eyes see also needs to be remembered.</p><h2 id="The-Future-Richer-Perception-and-More-Precise-Action"><a href="#The-Future-Richer-Perception-and-More-Precise-Action" class="headerlink" title="The Future: Richer Perception and More Precise Action"></a>The Future: Richer Perception and More Precise Action</h2><p>I believe Agent eyes and hands will evolve along several directions:</p><h3 id="Perception-Side"><a href="#Perception-Side" class="headerlink" title="Perception Side"></a>Perception Side</h3><ul><li><strong>Real-time visual understanding</strong>: Not just screenshots, but “seeing” the screen like a human — understanding layout, color, animation</li><li><strong>Multi-source information fusion</strong>: Simultaneously processing code, logs, browser, database, and other information sources</li><li><strong>Active exploration</strong>: Not waiting to be told where to look, but proactively browsing files, checking logs, searching docs</li></ul><h3 id="Action-Side"><a href="#Action-Side" class="headerlink" title="Action Side"></a>Action Side</h3><ul><li><strong>Finer operations</strong>: Operating an IDE like a human — refactoring code, running debuggers, setting breakpoints</li><li><strong>Cross-system orchestration</strong>: Simultaneously operating multiple services, environments, and toolchains</li><li><strong>Physical world interaction</strong>: Extending from the digital world to the physical world through IoT devices and robot interfaces</li></ul><h3 id="Coordination-Side"><a href="#Coordination-Side" class="headerlink" title="Coordination Side"></a>Coordination Side</h3><ul><li><strong>Adaptive strategies</strong>: Automatically choosing perception precision and action granularity based on task complexity</li><li><strong>Parallel operations</strong>: Executing multiple subtasks simultaneously instead of waiting serially</li><li><strong>Collaboration</strong>: Multiple Agents dividing work — one handles frontend, one handles backend, one handles testing</li></ul><h2 id="Final-Thoughts"><a href="#Final-Thoughts" class="headerlink" title="Final Thoughts"></a>Final Thoughts</h2><p>Back to the original question: how do you give an Agent its own eyes and hands?</p><p>Technically, the answer is connecting it to browsers, file systems, terminals, APIs, and other tools. But the deeper answer is: <strong>let it form a perception-decision-action loop, and continuously learn and improve within that loop.</strong></p><p>An Agent that can only talk is a consultant. An Agent that can see and do is a colleague. An Agent that can see, do, and learn from mistakes is a true partner.</p><p>We’re moving from the “consultant era” to the “colleague era.” The road is long, but every step is exciting.</p><hr><p><em>The building, deployment, and debugging of this article was entirely done by an Agent with eyes and hands. It saw the page go white, investigated the cause on its own, fixed the config, and redeployed. That’s the power of eyes and hands.</em></p><p><em>If you’re also exploring the boundaries of Agent capabilities, find me on <a href="https://twitter.com/xiaosen_lu">Twitter</a>.</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/agent-eyes-and-hands-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/agent-eyes-and-hands-en/"/>
    <published>2026-02-28T12:00:00.000Z</published>
    <summary>An Agent that can only talk isn't enough — it needs to see and act. Sharing practical insights on giving Agents perception and action capabilities.</summary>
    <title>How to Give Your Agent Eyes and Hands</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Agent" scheme="https://xiaoxiaduoyan.com/tags/Agent/"/>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <content>
      <![CDATA[<h2 id="一个会说但不会做的助手"><a href="#一个会说但不会做的助手" class="headerlink" title="一个会说但不会做的助手"></a>一个会说但不会做的助手</h2><p>你有没有遇到过这种情况：你问 AI 一个问题，它给你一段完美的回答，但你需要自己去执行每一步。</p><p>“帮我把这个 bug 修了。”</p><p>它会告诉你：打开某个文件，找到第 42 行，把 <code>foo</code> 改成 <code>bar</code>，然后运行 <code>npm test</code> 验证。</p><p>说得头头是道。但它自己不动手。</p><p>这就像你雇了一个顾问，他坐在旁边指点江山，但从来不碰键盘。你得自己打开编辑器、找到那一行、改完、跑测试、看结果、再回来告诉他”改完了，但测试还是挂了”。然后他再给你下一步建议。</p><p><strong>来回折腾几次，你就会想：你能不能自己来？</strong></p><p>这就是为什么 Agent 需要”眼”和”手”——不只是语言能力，还需要感知世界的能力和改变世界的能力。</p><h2 id="眼：让-Agent-看见世界"><a href="#眼：让-Agent-看见世界" class="headerlink" title="眼：让 Agent 看见世界"></a>眼：让 Agent 看见世界</h2><p>一个没有感知能力的 Agent，就像一个蒙着眼睛的人。你得不停地口述周围的环境，它才能给出建议。效率极低，而且你描述的信息永远是有损的。</p><h3 id="浏览器就是-Agent-的眼睛"><a href="#浏览器就是-Agent-的眼睛" class="headerlink" title="浏览器就是 Agent 的眼睛"></a>浏览器就是 Agent 的眼睛</h3><p>我最近的实践中，给 Agent 接入了一个浏览器工具。它能做什么呢？</p><ul><li><strong>打开网页</strong>：直接访问 URL，看到页面内容</li><li><strong>获取快照（Snapshot）</strong>：拿到页面的 accessibility tree——一种结构化的页面描述，比截图更适合 AI 理解</li><li><strong>截图</strong>：当需要视觉判断时，直接截取屏幕画面</li><li><strong>执行 JavaScript</strong>：在页面上下文中运行代码，获取 DOM 信息或触发操作</li></ul><p>这里面最关键的是 <strong>Snapshot</strong>。</p><p><img src="/images/agent-perception.png" alt="Agent 感知能力架构"></p><p>很多人第一反应是给 Agent 截图，让多模态模型”看”图片。这当然可以，但效率很低——一张截图可能要消耗几千 token，而且模型从图片中提取结构化信息的准确率远不如直接读结构化数据。</p><p>Accessibility tree 是浏览器为无障碍功能维护的一棵树，它描述了页面上每个可交互元素的角色、名称和状态。对 Agent 来说，这就是一张”语义地图”——它不需要知道按钮是什么颜色、在屏幕哪个位置，它只需要知道”这里有一个叫’提交’的按钮，ref 是 e42”。</p><p><strong>Snapshot 是 AI 友好的，截图是人类友好的。</strong> 给 Agent 用 Snapshot，给人类看截图。</p><h3 id="不只是浏览器"><a href="#不只是浏览器" class="headerlink" title="不只是浏览器"></a>不只是浏览器</h3><p>眼睛不只是浏览器。Agent 的感知能力可以扩展到很多维度：</p><ul><li><strong>文件系统</strong>：读取代码文件、配置文件、日志文件</li><li><strong>终端输出</strong>：执行命令后看到 stdout 和 stderr</li><li><strong>API 响应</strong>：调用接口后解析返回数据</li><li><strong>Git 状态</strong>：知道当前分支、未提交的改动、最近的 commit</li></ul><p>每一种感知通道都在告诉 Agent：<strong>世界现在是什么样子的。</strong></p><h2 id="手：让-Agent-改变世界"><a href="#手：让-Agent-改变世界" class="headerlink" title="手：让 Agent 改变世界"></a>手：让 Agent 改变世界</h2><p>光看不够，还得能动手。</p><h3 id="脚本执行是最通用的”手”"><a href="#脚本执行是最通用的”手”" class="headerlink" title="脚本执行是最通用的”手”"></a>脚本执行是最通用的”手”</h3><p>如果只能给 Agent 一种行动能力，我会选<strong>执行 shell 脚本</strong>。</p><p>为什么？因为 shell 是万能胶水。你能用它：</p><ul><li>创建、修改、删除文件</li><li>安装依赖、运行构建、执行测试</li><li>调用 API、下载资源、处理数据</li><li>操作 Git、部署代码、管理进程</li></ul><p>一个能执行 shell 脚本的 Agent，理论上能做任何程序员能做的事。</p><h3 id="但粗粒度不够"><a href="#但粗粒度不够" class="headerlink" title="但粗粒度不够"></a>但粗粒度不够</h3><p>纯 shell 有个问题：它太底层了。让 Agent 用 <code>sed</code> 做文本替换，经常会因为转义字符、正则表达式的边界情况而翻车。</p><p>所以更好的做法是提供<strong>多层次的行动能力</strong>：</p><table><thead><tr><th>层次</th><th>工具</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>精细操作</strong></td><td>文件读写、搜索替换</td><td>修改代码、更新配置</td></tr><tr><td><strong>中等操作</strong></td><td>浏览器交互（点击、填写、导航）</td><td>Web 操作、测试验证</td></tr><tr><td><strong>粗粒度操作</strong></td><td>Shell 脚本</td><td>构建、部署、系统管理</td></tr></tbody></table><p>精细操作减少出错概率，粗粒度操作保证灵活性。两者结合，Agent 才能既稳又快。</p><h3 id="一个真实的例子"><a href="#一个真实的例子" class="headerlink" title="一个真实的例子"></a>一个真实的例子</h3><p>我让 Agent 帮我搭这个博客的时候，它的”手”是这样协作的：</p><ol><li><strong>写文件</strong>（精细操作）：创建 Markdown 文章、修改配置文件</li><li><strong>执行脚本</strong>（粗粒度）：<code>hexo generate</code> 构建、<code>git push</code> 部署</li><li><strong>浏览器操作</strong>（中等操作）：打开部署后的页面，检查渲染效果</li><li><strong>搜索替换</strong>（精细操作）：发现 CSS 问题后，精准修改样式文件</li></ol><p>整个流程它自己跑完，我只需要最后刷新页面看效果。</p><h2 id="眼手协调：感知-决策-行动的闭环"><a href="#眼手协调：感知-决策-行动的闭环" class="headerlink" title="眼手协调：感知-决策-行动的闭环"></a>眼手协调：感知-决策-行动的闭环</h2><p>眼和手单独存在没有意义，关键是它们要形成<strong>闭环</strong>。</p><p><img src="/images/agent-loop.png" alt="感知-决策-行动闭环"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">感知（看到了什么）→ 决策（应该做什么）→ 行动（去做）→ 感知（做完后世界变了吗）→ ...</span><br></pre></td></tr></table></figure><p>这个闭环听起来简单，但实现起来有很多细节：</p><h3 id="1-行动后必须验证"><a href="#1-行动后必须验证" class="headerlink" title="1. 行动后必须验证"></a>1. 行动后必须验证</h3><p>Agent 执行了一个操作后，不能就假设成功了。它需要<strong>回头看一眼</strong>：</p><ul><li>改了代码？跑一下测试。</li><li>部署了网站？打开浏览器看看。</li><li>安装了依赖？检查 <code>node_modules</code> 是否存在。</li></ul><p><strong>不验证的行动是危险的。</strong> 这就像闭着眼睛过马路——你迈出了步子，但不知道有没有车。</p><h3 id="2-错误是信息，不是终点"><a href="#2-错误是信息，不是终点" class="headerlink" title="2. 错误是信息，不是终点"></a>2. 错误是信息，不是终点</h3><p>当 Agent 执行脚本报错时，错误信息本身就是最有价值的感知输入。一个好的 Agent 会：</p><ul><li>读取错误信息</li><li>分析原因</li><li>调整方案</li><li>重新执行</li></ul><p>而不是直接告诉你”执行失败了，请手动处理”。</p><h3 id="3-知道什么时候该停"><a href="#3-知道什么时候该停" class="headerlink" title="3. 知道什么时候该停"></a>3. 知道什么时候该停</h3><p>闭环不能无限转下去。Agent 需要判断：</p><ul><li>任务完成了吗？</li><li>是不是陷入了死循环？</li><li>是不是应该问用户确认？</li></ul><p>这是一种<strong>元认知能力</strong>——不只是做事，还要知道自己在做什么、做得怎么样。</p><h2 id="当前方案的局限"><a href="#当前方案的局限" class="headerlink" title="当前方案的局限"></a>当前方案的局限</h2><p>说了这么多好处，也得聊聊现实中的坑。</p><h3 id="安全边界模糊"><a href="#安全边界模糊" class="headerlink" title="安全边界模糊"></a>安全边界模糊</h3><p>Agent 能执行 shell 脚本，意味着它理论上能 <code>rm -rf /</code>。虽然没有哪个正常的 Agent 会这么做，但<strong>权限控制</strong>是一个必须认真对待的问题。</p><p>目前的做法通常是：</p><ul><li>限制工作目录</li><li>禁止危险命令</li><li>关键操作需要人工确认</li></ul><p>但这些都是打补丁。更根本的解决方案可能是<strong>沙箱化执行环境</strong>——Agent 在一个隔离的容器里操作，即使出错也不会影响宿主系统。</p><h3 id="感知带宽有限"><a href="#感知带宽有限" class="headerlink" title="感知带宽有限"></a>感知带宽有限</h3><p>即使有了浏览器和文件系统，Agent 的感知带宽仍然远低于人类。人类一眼就能看出”这个页面布局不对”，Agent 需要解析整个 DOM 树才能得出类似的判断。</p><p><strong>多模态模型在进步，但还没到”一眼看懂”的程度。</strong> 目前的最佳实践是结构化感知（Snapshot）和视觉感知（截图）结合使用。</p><h3 id="长任务的上下文丢失"><a href="#长任务的上下文丢失" class="headerlink" title="长任务的上下文丢失"></a>长任务的上下文丢失</h3><p>一个复杂任务可能需要几十步操作。随着步骤增多，早期的感知信息会被挤出上下文窗口。Agent 可能忘了自己三步之前看到了什么。</p><p>这又回到了记忆管理的问题——眼睛看到的东西，也需要被记住。</p><h2 id="未来：更丰富的感知和更精准的行动"><a href="#未来：更丰富的感知和更精准的行动" class="headerlink" title="未来：更丰富的感知和更精准的行动"></a>未来：更丰富的感知和更精准的行动</h2><p>我觉得 Agent 的眼和手会沿着几个方向进化：</p><h3 id="感知侧"><a href="#感知侧" class="headerlink" title="感知侧"></a>感知侧</h3><ul><li><strong>实时视觉理解</strong>：不只是截图，而是像人一样”看”屏幕，理解布局、颜色、动画</li><li><strong>多源信息融合</strong>：同时处理代码、日志、浏览器、数据库等多个信息源</li><li><strong>主动探索</strong>：不等你告诉它看哪里，自己去翻文件、查日志、搜文档</li></ul><h3 id="行动侧"><a href="#行动侧" class="headerlink" title="行动侧"></a>行动侧</h3><ul><li><strong>更精细的操作</strong>：像人一样操作 IDE——重构代码、运行调试器、设置断点</li><li><strong>跨系统协作</strong>：同时操作多个服务、多个环境、多个工具链</li><li><strong>物理世界交互</strong>：通过 IoT 设备、机器人接口，从数字世界延伸到物理世界</li></ul><h3 id="协调侧"><a href="#协调侧" class="headerlink" title="协调侧"></a>协调侧</h3><ul><li><strong>自适应策略</strong>：根据任务复杂度自动选择感知精度和行动粒度</li><li><strong>并行操作</strong>：同时执行多个子任务，而不是串行等待</li><li><strong>协作能力</strong>：多个 Agent 分工合作，一个负责前端，一个负责后端，一个负责测试</li></ul><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>回到最初的问题：如何让 Agent 长出自己的眼和手？</p><p>技术上，答案是给它接入浏览器、文件系统、终端、API 等工具。但更深层的答案是：<strong>让它形成感知-决策-行动的闭环，并且在这个闭环中不断学习和改进。</strong></p><p>一个只会说的 Agent 是顾问。一个能看能做的 Agent 是同事。一个能看、能做、还能从错误中学习的 Agent，才是真正的伙伴。</p><p>我们正在从”顾问时代”走向”同事时代”。这条路还很长，但每一步都让人兴奋。</p><hr><p><em>这篇文章的搭建、部署、调试过程，全部由一个有眼有手的 Agent 完成。它看到了页面白屏，自己查了原因，改了配置，重新部署。这就是眼和手的力量。</em></p><p><em>如果你也在探索 Agent 的能力边界，欢迎在 <a href="https://twitter.com/xiaosen_lu">Twitter</a> 上找我聊。</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/agent-eyes-and-hands/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/agent-eyes-and-hands/"/>
    <published>2026-02-28T12:00:00.000Z</published>
    <summary>Agent 不能只会&quot;说&quot;，还得能&quot;看&quot;和&quot;做&quot;。从实践出发，聊聊如何给 Agent 装上眼睛和双手。</summary>
    <title>如何让Agent长出自己的眼和手</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="技术" scheme="https://xiaoxiaduoyan.com/categories/%E6%8A%80%E6%9C%AF/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Agent" scheme="https://xiaoxiaduoyan.com/tags/Agent/"/>
    <category term="技术思考" scheme="https://xiaoxiaduoyan.com/tags/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/"/>
    <content>
      <![CDATA[<h2 id="一个真实的场景"><a href="#一个真实的场景" class="headerlink" title="一个真实的场景"></a>一个真实的场景</h2><p>最近我一直在用一个 AI Agent 帮我干活——搭博客、写组件库、调样式、部署代码。几天下来，我发现一个有意思的现象：</p><p><strong>它记得我喜欢用 pnpm，记得我的 GitHub 用户名，记得我说过”顶部大色块不要了”，甚至记得我微信号是什么。</strong></p><p>但有时候它又会犯一些低级错误，比如把已经修过的 bug 再改回去，或者忘了我之前明确说过的偏好。</p><p>这让我开始认真思考一个问题：<strong>在大模型上下文窗口已经动辄几十万 token 的今天，Agent 的记忆管理到底应该怎么做？</strong></p><h2 id="上下文窗口够大，就不需要记忆了吗？"><a href="#上下文窗口够大，就不需要记忆了吗？" class="headerlink" title="上下文窗口够大，就不需要记忆了吗？"></a>上下文窗口够大，就不需要记忆了吗？</h2><p>很多人有一个直觉：模型的上下文窗口越来越大，128K、200K、甚至 1M token，是不是把所有历史对话塞进去就完事了？</p><p><strong>答案是：远远不够。</strong></p><p>原因有三个：</p><h3 id="1-成本问题是硬约束"><a href="#1-成本问题是硬约束" class="headerlink" title="1. 成本问题是硬约束"></a>1. 成本问题是硬约束</h3><p>即使模型支持 1M token 的上下文，你真的要每次推理都把所有历史塞进去吗？按照目前的 API 定价，一次百万 token 的推理调用，成本可能就是几块钱。一个活跃的 Agent 一天可能要推理几百次。</p><p><strong>算一笔账：如果每次都用满 1M 上下文，一天的 API 费用可能就要上千。</strong> 这对个人开发者来说完全不可接受，对企业来说也是巨大的成本压力。</p><h3 id="2-长上下文-≠-长记忆"><a href="#2-长上下文-≠-长记忆" class="headerlink" title="2. 长上下文 ≠ 长记忆"></a>2. 长上下文 ≠ 长记忆</h3><p>这是很多人忽略的一点。模型在处理超长上下文时，对中间部分的信息提取能力是显著下降的——这就是所谓的 <strong>“Lost in the Middle”</strong> 问题。</p><p>你把三个月前的一段对话塞在 50 万 token 的中间位置，模型大概率会”视而不见”。上下文窗口是个队列，不是数据库。<strong>你不能指望模型像搜索引擎一样精准地从海量文本中定位关键信息。</strong></p><h3 id="3-不是所有信息都值得记住"><a href="#3-不是所有信息都值得记住" class="headerlink" title="3. 不是所有信息都值得记住"></a>3. 不是所有信息都值得记住</h3><p>这一点最关键。人类的记忆系统之所以高效，不是因为我们记住了一切，而是因为我们<strong>善于遗忘</strong>。</p><p>你不需要记住每一次 <code>git push</code> 的输出日志，但你需要记住”这个项目用 pnpm 不用 npm，因为 npm 有缓存权限问题”。前者是噪音，后者是知识。</p><p><strong>好的记忆管理，本质上是一门遗忘的艺术。</strong></p><h2 id="当前主流的-Agent-记忆方案"><a href="#当前主流的-Agent-记忆方案" class="headerlink" title="当前主流的 Agent 记忆方案"></a>当前主流的 Agent 记忆方案</h2><p>目前业界的 Agent 记忆管理大致分几个层次：</p><p><img src="/images/memory-layers.png" alt="Agent 记忆层次架构"></p><h3 id="工作记忆（Working-Memory）"><a href="#工作记忆（Working-Memory）" class="headerlink" title="工作记忆（Working Memory）"></a>工作记忆（Working Memory）</h3><p>就是当前对话的上下文。模型直接能”看到”的部分。容量有限，但访问速度最快、准确度最高。</p><p>类比人类：你正在思考的事情。</p><h3 id="短期记忆（Short-term-Memory）"><a href="#短期记忆（Short-term-Memory）" class="headerlink" title="短期记忆（Short-term Memory）"></a>短期记忆（Short-term Memory）</h3><p>最近几轮对话的摘要。通常通过 LLM 自动总结压缩，保留关键信息，丢弃细节。</p><p>类比人类：你今天做了什么，大致还记得，但具体每句话说了什么已经模糊了。</p><h3 id="长期记忆（Long-term-Memory）"><a href="#长期记忆（Long-term-Memory）" class="headerlink" title="长期记忆（Long-term Memory）"></a>长期记忆（Long-term Memory）</h3><p>跨会话持久化的信息。通常存储在向量数据库中，通过 embedding 检索相关内容。</p><p>类比人类：你知道某个同事的习惯、某个项目的架构决策——这些是长期积累的知识。</p><h3 id="外部知识库（External-Knowledge）"><a href="#外部知识库（External-Knowledge）" class="headerlink" title="外部知识库（External Knowledge）"></a>外部知识库（External Knowledge）</h3><p>文档、代码库、API 文档等。Agent 通过 RAG（检索增强生成）按需获取。</p><p>类比人类：你不需要背下整本手册，但你知道去哪里查。</p><h2 id="我观察到的几个关键问题"><a href="#我观察到的几个关键问题" class="headerlink" title="我观察到的几个关键问题"></a>我观察到的几个关键问题</h2><p>在实际使用 Agent 的过程中，我发现现有的记忆方案有几个痛点：</p><h3 id="问题一：摘要会丢失关键细节"><a href="#问题一：摘要会丢失关键细节" class="headerlink" title="问题一：摘要会丢失关键细节"></a>问题一：摘要会丢失关键细节</h3><p>当 Agent 把长对话压缩成摘要时，它必须做取舍。但<strong>什么是重要的，什么是不重要的，这个判断本身就很难</strong>。</p><p>举个例子：我跟 Agent 说”图片路径不要加 <code>/ideas/</code> 前缀”。这句话在一段很长的调试对话中可能只占一行，但它是一个<strong>关键的项目规则</strong>。如果摘要时被丢掉了，下次它又会犯同样的错误。</p><h3 id="问题二：向量检索的召回率不稳定"><a href="#问题二：向量检索的召回率不稳定" class="headerlink" title="问题二：向量检索的召回率不稳定"></a>问题二：向量检索的召回率不稳定</h3><p>长期记忆通常依赖向量相似度检索。但自然语言的语义是模糊的——“npm 有权限问题”和”用 pnpm 代替 npm”，语义上相关但表述差异很大。检索时可能漏掉关键信息。</p><h3 id="问题三：记忆缺乏结构化"><a href="#问题三：记忆缺乏结构化" class="headerlink" title="问题三：记忆缺乏结构化"></a>问题三：记忆缺乏结构化</h3><p>大多数 Agent 的记忆就是一堆文本片段。但人类的记忆是有结构的——我们会把知识组织成概念、规则、经验、偏好等不同类别。</p><p><strong>一个 Agent 应该知道”用户偏好 pnpm”是一条偏好规则，而不只是某次对话中出现过的一句话。</strong></p><h2 id="我的思考：理想的-Agent-记忆系统"><a href="#我的思考：理想的-Agent-记忆系统" class="headerlink" title="我的思考：理想的 Agent 记忆系统"></a>我的思考：理想的 Agent 记忆系统</h2><p>基于这些观察，我觉得未来的 Agent 记忆系统应该有几个特征：</p><p><img src="/images/memory-radar.png" alt="不同类型记忆的特征对比"></p><h3 id="1-分层-分类"><a href="#1-分层-分类" class="headerlink" title="1. 分层 + 分类"></a>1. 分层 + 分类</h3><p>不是简单的”短期&#x2F;长期”二分法，而是按信息类型分类：</p><table><thead><tr><th>类型</th><th>示例</th><th>特征</th></tr></thead><tbody><tr><td><strong>事实</strong></td><td>用户的 GitHub 用户名是 hongqi-lgs</td><td>确定性高，几乎不变</td></tr><tr><td><strong>偏好</strong></td><td>用户喜欢 headed 模式的浏览器</td><td>可能变化，但变化频率低</td></tr><tr><td><strong>规则</strong></td><td>图片路径不加 &#x2F;ideas&#x2F; 前缀</td><td>项目级别的硬约束</td></tr><tr><td><strong>经验</strong></td><td>npm 有缓存权限问题，用 pnpm 绕过</td><td>从错误中学到的教训</td></tr><tr><td><strong>状态</strong></td><td>当前正在开发 Switch 组件</td><td>时效性强，会过期</td></tr></tbody></table><p>不同类型的记忆，应该有不同的存储策略、检索权重和过期机制。</p><h3 id="2-主动遗忘"><a href="#2-主动遗忘" class="headerlink" title="2. 主动遗忘"></a>2. 主动遗忘</h3><p>Agent 应该有能力主动清理过时的信息。三个月前的调试日志、已经解决的 bug 详情、临时的中间状态——这些都应该被逐步淘汰。</p><p><strong>不是删除，而是降权。</strong> 就像人类的记忆一样，不常被提起的信息会逐渐模糊，但如果被触发，还是能想起来。</p><h3 id="3-记忆的自我修正"><a href="#3-记忆的自我修正" class="headerlink" title="3. 记忆的自我修正"></a>3. 记忆的自我修正</h3><p>当 Agent 发现自己的记忆与现实矛盾时，应该能自动更新。比如用户说”我现在改用 npm 了”，Agent 不应该还抱着”用 pnpm”的旧记忆不放。</p><p>这需要一个<strong>冲突检测和解决机制</strong>——新信息和旧记忆矛盾时，以新信息为准，并标记旧记忆为”已过时”。</p><h3 id="4-可解释的记忆"><a href="#4-可解释的记忆" class="headerlink" title="4. 可解释的记忆"></a>4. 可解释的记忆</h3><p>用户应该能看到 Agent 记住了什么、为什么记住、什么时候记住的。这不仅是透明度的问题，也是信任的基础。</p><p><strong>如果你不知道 AI 记住了你的什么信息，你怎么敢把重要的事情交给它？</strong></p><h2 id="一个更大胆的想法"><a href="#一个更大胆的想法" class="headerlink" title="一个更大胆的想法"></a>一个更大胆的想法</h2><p>我最近在想一个可能有点超前的观点：</p><p><strong>未来的 Agent 记忆，可能不应该是”存储-检索”模式，而应该是”生长-进化”模式。</strong></p><p><img src="/images/memory-evolution.png" alt="存储-检索 vs 生长-进化"></p><p>什么意思呢？</p><p>现在的记忆系统本质上是一个数据库：存进去，查出来。但人类的记忆不是这样工作的。我们的记忆会在睡眠中被重新整理，不同的记忆片段会被重新关联，形成新的理解。</p><p>想象一下：一个 Agent 在”空闲时间”（没有用户交互的时候），自动回顾自己的记忆，把零散的经验整理成系统的知识，发现不同项目之间的共性模式，甚至主动提出优化建议。</p><p><strong>这不再是记忆管理，而是知识进化。</strong></p><p>当然，这需要解决很多技术问题——计算成本、幻觉控制、知识一致性验证等等。但我相信这是 Agent 发展的一个重要方向。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>我们正处在一个有趣的时间节点。大模型的能力在飞速提升，上下文窗口在不断扩大，但 Agent 的记忆管理仍然是一个远未解决的问题。</p><p><strong>上下文窗口再大，也只是给了你一个更大的工作台。真正的智能，在于知道工作台上该放什么、不该放什么。</strong></p><p>作为一个每天都在和 Agent 打交道的人，我越来越觉得：记忆管理可能是决定 Agent 能否从”工具”进化为”伙伴”的关键一步。</p><p>一个记不住你偏好的助手，永远只是一个需要反复调教的工具。一个能理解你、记住你、甚至能预判你需求的助手，才是真正的伙伴。</p><p>我们还在路上，但方向已经清晰了。</p><hr><p><em>如果你也在做 Agent 相关的工作，欢迎交流。我的 Twitter 是 <a href="https://twitter.com/xiaosen_lu">@xiaosen_lu</a>。</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/agent-memory-management/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/agent-memory-management/"/>
    <published>2026-02-28T10:00:00.000Z</published>
    <summary>当上下文窗口已经够大，Agent 还需要记忆管理吗？从实际使用经验出发，聊聊我对 Agent 记忆系统的理解。</summary>
    <title>谈谈超级大模型时代的Agent记忆管理</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
  <entry>
    <author>
      <name>红齐</name>
    </author>
    <category term="English" scheme="https://xiaoxiaduoyan.com/categories/English/"/>
    <category term="AI" scheme="https://xiaoxiaduoyan.com/tags/AI/"/>
    <category term="Agent" scheme="https://xiaoxiaduoyan.com/tags/Agent/"/>
    <category term="Thoughts" scheme="https://xiaoxiaduoyan.com/tags/Thoughts/"/>
    <category term="Writing" scheme="https://xiaoxiaduoyan.com/tags/Writing/"/>
    <category term="English" scheme="https://xiaoxiaduoyan.com/tags/English/"/>
    <content>
      <![CDATA[<h2 id="A-Real-Scenario"><a href="#A-Real-Scenario" class="headerlink" title="A Real Scenario"></a>A Real Scenario</h2><p>I’ve been using an AI Agent recently to help me with all sorts of tasks — building a blog, writing a component library, tweaking styles, deploying code. After a few days, I noticed something interesting:</p><p><strong>It remembers that I prefer pnpm, knows my GitHub username, remembers I said “get rid of the top banner,” and even knows my WeChat ID.</strong></p><p>But sometimes it makes rookie mistakes — like reverting a bug fix I’d already confirmed, or forgetting a preference I’d explicitly stated.</p><p>This got me thinking seriously about a question: <strong>In an era where model context windows are already hundreds of thousands of tokens, how should Agent memory management actually work?</strong></p><h2 id="Is-a-Bigger-Context-Window-Enough"><a href="#Is-a-Bigger-Context-Window-Enough" class="headerlink" title="Is a Bigger Context Window Enough?"></a>Is a Bigger Context Window Enough?</h2><p>Many people have an intuition: context windows are getting huge — 128K, 200K, even 1M tokens. Can’t we just stuff all the history in there and call it a day?</p><p><strong>The answer is: not even close.</strong></p><p>Three reasons:</p><h3 id="1-Cost-Is-a-Hard-Constraint"><a href="#1-Cost-Is-a-Hard-Constraint" class="headerlink" title="1. Cost Is a Hard Constraint"></a>1. Cost Is a Hard Constraint</h3><p>Even if a model supports 1M tokens of context, do you really want to fill it every single inference call? At current API pricing, a single million-token call might cost several dollars. An active Agent might run hundreds of inferences per day.</p><p><strong>Do the math: if you max out 1M context every time, daily API costs could easily hit thousands of dollars.</strong> That’s unacceptable for individual developers and a massive cost pressure for enterprises.</p><h3 id="2-Long-Context-≠-Long-Memory"><a href="#2-Long-Context-≠-Long-Memory" class="headerlink" title="2. Long Context ≠ Long Memory"></a>2. Long Context ≠ Long Memory</h3><p>This is something many people overlook. Models show significantly degraded information extraction from the middle portions of very long contexts — the so-called <strong>“Lost in the Middle”</strong> problem.</p><p>If you bury a conversation from three months ago at the 500K-token mark, the model will likely ignore it completely. A context window is a queue, not a database. <strong>You can’t expect a model to pinpoint critical information from massive text like a search engine.</strong></p><h3 id="3-Not-Everything-Is-Worth-Remembering"><a href="#3-Not-Everything-Is-Worth-Remembering" class="headerlink" title="3. Not Everything Is Worth Remembering"></a>3. Not Everything Is Worth Remembering</h3><p>This is the most crucial point. The reason human memory is efficient isn’t because we remember everything — it’s because we’re <strong>good at forgetting</strong>.</p><p>You don’t need to remember the output of every <code>git push</code>, but you do need to remember “this project uses pnpm instead of npm because npm has cache permission issues.” The former is noise; the latter is knowledge.</p><p><strong>Good memory management is essentially the art of forgetting.</strong></p><h2 id="Current-Mainstream-Agent-Memory-Approaches"><a href="#Current-Mainstream-Agent-Memory-Approaches" class="headerlink" title="Current Mainstream Agent Memory Approaches"></a>Current Mainstream Agent Memory Approaches</h2><p>The industry’s Agent memory management roughly breaks down into several layers:</p><p><img src="/images/memory-layers.png" alt="Agent Memory Architecture"></p><h3 id="Working-Memory"><a href="#Working-Memory" class="headerlink" title="Working Memory"></a>Working Memory</h3><p>The current conversation context. What the model can directly “see.” Limited capacity, but fastest access and highest accuracy.</p><p>Human analogy: what you’re actively thinking about right now.</p><h3 id="Short-term-Memory"><a href="#Short-term-Memory" class="headerlink" title="Short-term Memory"></a>Short-term Memory</h3><p>Summaries of recent conversation rounds. Usually auto-compressed by an LLM, retaining key information while discarding details.</p><p>Human analogy: you roughly remember what you did today, but the exact words of every conversation are already fuzzy.</p><h3 id="Long-term-Memory"><a href="#Long-term-Memory" class="headerlink" title="Long-term Memory"></a>Long-term Memory</h3><p>Persistent information across sessions. Typically stored in vector databases, retrieved via embedding similarity.</p><p>Human analogy: you know a colleague’s habits, a project’s architectural decisions — knowledge accumulated over time.</p><h3 id="External-Knowledge"><a href="#External-Knowledge" class="headerlink" title="External Knowledge"></a>External Knowledge</h3><p>Documentation, codebases, API docs, etc. Agents access these on-demand through RAG (Retrieval-Augmented Generation).</p><p>Human analogy: you don’t memorize the entire manual, but you know where to look.</p><h2 id="Key-Problems-I’ve-Observed"><a href="#Key-Problems-I’ve-Observed" class="headerlink" title="Key Problems I’ve Observed"></a>Key Problems I’ve Observed</h2><p>Through hands-on Agent usage, I’ve identified several pain points with existing memory approaches:</p><h3 id="Problem-1-Summaries-Lose-Critical-Details"><a href="#Problem-1-Summaries-Lose-Critical-Details" class="headerlink" title="Problem 1: Summaries Lose Critical Details"></a>Problem 1: Summaries Lose Critical Details</h3><p>When an Agent compresses long conversations into summaries, it has to make trade-offs. But <strong>judging what’s important and what’s not is inherently difficult</strong>.</p><p>Example: I told my Agent “don’t add the <code>/ideas/</code> prefix to image paths.” In a long debugging conversation, this might be just one line, but it’s a <strong>critical project rule</strong>. If it gets dropped during summarization, the same mistake will happen again.</p><h3 id="Problem-2-Vector-Retrieval-Has-Unstable-Recall"><a href="#Problem-2-Vector-Retrieval-Has-Unstable-Recall" class="headerlink" title="Problem 2: Vector Retrieval Has Unstable Recall"></a>Problem 2: Vector Retrieval Has Unstable Recall</h3><p>Long-term memory typically relies on vector similarity search. But natural language semantics are fuzzy — “npm has permission issues” and “use pnpm instead of npm” are semantically related but expressed very differently. Critical information might be missed during retrieval.</p><h3 id="Problem-3-Memory-Lacks-Structure"><a href="#Problem-3-Memory-Lacks-Structure" class="headerlink" title="Problem 3: Memory Lacks Structure"></a>Problem 3: Memory Lacks Structure</h3><p>Most Agent memories are just piles of text fragments. But human memory is structured — we organize knowledge into concepts, rules, experiences, preferences, and other categories.</p><p><strong>An Agent should know that “user prefers pnpm” is a preference rule, not just a sentence that appeared in some conversation.</strong></p><h2 id="My-Vision-The-Ideal-Agent-Memory-System"><a href="#My-Vision-The-Ideal-Agent-Memory-System" class="headerlink" title="My Vision: The Ideal Agent Memory System"></a>My Vision: The Ideal Agent Memory System</h2><p>Based on these observations, I believe future Agent memory systems should have several characteristics:</p><p><img src="/images/memory-radar.png" alt="Memory Type Characteristics"></p><h3 id="1-Layered-Categorized"><a href="#1-Layered-Categorized" class="headerlink" title="1. Layered + Categorized"></a>1. Layered + Categorized</h3><p>Not a simple “short-term&#x2F;long-term” binary, but categorized by information type:</p><table><thead><tr><th>Type</th><th>Example</th><th>Characteristics</th></tr></thead><tbody><tr><td><strong>Facts</strong></td><td>User’s GitHub username is hongqi-lgs</td><td>High certainty, rarely changes</td></tr><tr><td><strong>Preferences</strong></td><td>User likes headed browser mode</td><td>May change, but infrequently</td></tr><tr><td><strong>Rules</strong></td><td>Don’t add &#x2F;ideas&#x2F; prefix to image paths</td><td>Project-level hard constraints</td></tr><tr><td><strong>Lessons</strong></td><td>npm has cache permission issues, use pnpm</td><td>Learned from mistakes</td></tr><tr><td><strong>State</strong></td><td>Currently developing the Switch component</td><td>Time-sensitive, will expire</td></tr></tbody></table><p>Different types of memory should have different storage strategies, retrieval weights, and expiration mechanisms.</p><h3 id="2-Active-Forgetting"><a href="#2-Active-Forgetting" class="headerlink" title="2. Active Forgetting"></a>2. Active Forgetting</h3><p>Agents should be able to proactively clean up outdated information. Debugging logs from three months ago, details of resolved bugs, temporary intermediate states — these should all be gradually phased out.</p><p><strong>Not deletion, but de-prioritization.</strong> Like human memory, information that’s rarely recalled gradually fades, but can still be retrieved if triggered.</p><h3 id="3-Self-Correcting-Memory"><a href="#3-Self-Correcting-Memory" class="headerlink" title="3. Self-Correcting Memory"></a>3. Self-Correcting Memory</h3><p>When an Agent discovers its memory contradicts reality, it should auto-update. If a user says “I’ve switched to npm now,” the Agent shouldn’t cling to the old “use pnpm” memory.</p><p>This requires a <strong>conflict detection and resolution mechanism</strong> — when new information contradicts old memory, prioritize the new and mark the old as “outdated.”</p><h3 id="4-Explainable-Memory"><a href="#4-Explainable-Memory" class="headerlink" title="4. Explainable Memory"></a>4. Explainable Memory</h3><p>Users should be able to see what the Agent remembers, why it remembers it, and when it was stored. This isn’t just about transparency — it’s the foundation of trust.</p><p><strong>If you don’t know what information an AI has stored about you, how can you trust it with important tasks?</strong></p><h2 id="A-Bolder-Idea"><a href="#A-Bolder-Idea" class="headerlink" title="A Bolder Idea"></a>A Bolder Idea</h2><p>I’ve been mulling over a possibly ahead-of-its-time thought:</p><p><strong>Future Agent memory shouldn’t follow a “store-retrieve” model, but a “grow-evolve” model.</strong></p><p><img src="/images/memory-evolution.png" alt="Store &amp; Retrieve vs Grow &amp; Evolve"></p><p>What do I mean?</p><p>Current memory systems are essentially databases: store it, query it. But human memory doesn’t work that way. Our memories get reorganized during sleep, different memory fragments get reconnected, forming new understanding.</p><p>Imagine: an Agent during “idle time” (when there’s no user interaction) automatically reviews its memories, organizes scattered experiences into systematic knowledge, discovers common patterns across different projects, and even proactively suggests optimizations.</p><p><strong>This is no longer memory management — it’s knowledge evolution.</strong></p><p>Of course, this requires solving many technical challenges — computational cost, hallucination control, knowledge consistency verification, and more. But I believe this is an important direction for Agent development.</p><h2 id="Final-Thoughts"><a href="#Final-Thoughts" class="headerlink" title="Final Thoughts"></a>Final Thoughts</h2><p>We’re at a fascinating inflection point. Model capabilities are advancing rapidly, context windows keep expanding, but Agent memory management remains a largely unsolved problem.</p><p><strong>No matter how large the context window gets, it only gives you a bigger workbench. True intelligence lies in knowing what to put on that workbench — and what to leave off.</strong></p><p>As someone who works with Agents every day, I increasingly believe that memory management might be the key step in determining whether Agents evolve from “tools” into “partners.”</p><p>An assistant that can’t remember your preferences will always be a tool that needs constant re-training. An assistant that understands you, remembers you, and can even anticipate your needs — that’s a true partner.</p><p>We’re still on the journey, but the direction is clear.</p><hr><p><em>If you’re also working on Agent-related projects, I’d love to connect. Find me on Twitter at <a href="https://twitter.com/xiaosen_lu">@xiaosen_lu</a>.</em></p>]]>
    </content>
    <id>https://xiaoxiaduoyan.com/2026/02/28/agent-memory-management-en/</id>
    <link href="https://xiaoxiaduoyan.com/2026/02/28/agent-memory-management-en/"/>
    <published>2026-02-28T10:00:00.000Z</published>
    <summary>When context windows are already massive, do Agents still need memory management? Sharing my thoughts from hands-on experience.</summary>
    <title>Agent Memory Management in the Era of Super Large Models</title>
    <updated>2026-03-02T10:30:09.924Z</updated>
  </entry>
</feed>
